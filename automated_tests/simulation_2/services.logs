simulation_2-blueprint-service-1  | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
simulation_2-blueprint-service-1  | 20:09:10,805 |-WARN in net.logstash.logback.appender.LogstashTcpSocketAppender[LOGSTASH] - Log destination logstash/<unresolved>:5001: connection failed. java.net.ConnectException: Connection refused
simulation_2-blueprint-service-1  | 	at java.net.ConnectException: Connection refused
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)
simulation_2-blueprint-service-1  | 	at 	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
simulation_2-blueprint-service-1  | 	at 	at java.base/java.net.Socket.connect(Socket.java:633)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.appender.AbstractLogstashTcpSocketAppender$TcpSendingEventHandler.openSocket(AbstractLogstashTcpSocketAppender.java:765)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.appender.AbstractLogstashTcpSocketAppender$TcpSendingEventHandler.onStart(AbstractLogstashTcpSocketAppender.java:691)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.appender.AsyncDisruptorAppender$EventClearingEventHandler.onStart(AsyncDisruptorAppender.java:382)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.encoder.com.lmax.disruptor.BatchEventProcessor.notifyStart(BatchEventProcessor.java:224)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.encoder.com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:120)
simulation_2-blueprint-service-1  | 	at 	at java.base/java.lang.Thread.run(Thread.java:833)
simulation_2-blueprint-service-1  | 20:09:10,806 |-WARN in net.logstash.logback.appender.LogstashTcpSocketAppender[LOGSTASH] - Log destination logstash/<unresolved>:5001: Waiting 29890ms before attempting reconnection.
simulation_2-blueprint-service-1  | 
simulation_2-blueprint-service-1  |   .   ____          _            __ _ _
simulation_2-blueprint-service-1  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
simulation_2-blueprint-service-1  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
simulation_2-blueprint-service-1  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
simulation_2-blueprint-service-1  |   '  |____| .__|_| |_|_| |_\__, | / / / /
simulation_2-blueprint-service-1  |  =========|_|==============|___/=/_/_/_/
simulation_2-blueprint-service-1  |  :: Spring Boot ::                (v3.2.0)
simulation_2-blueprint-service-1  | 
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:11 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.1.Final
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:12 [main] c.w.a.b.BlueprintServiceApplication - Starting BlueprintServiceApplication v0.0.1-SNAPSHOT using Java 17.0.2 with PID 1 (/app.jar started by root in /)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:12 [main] c.w.a.b.BlueprintServiceApplication - No active profile set, falling back to 1 default profile: "default"
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:18 [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:18 [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 294 ms. Found 1 MongoDB repository interface.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:20 [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:20 [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 103 ms. Found 0 Reactive MongoDB repository interfaces.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:22 [main] o.s.cloud.context.scope.GenericScope - BeanFactory id=d36cf96f-b91b-364c-92cc-e2cf13fd9573
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:23 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$RetryInterceptorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$RetryInterceptorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [lbRestClientPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:23 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration' of type [org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:23 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration' of type [org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:23 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:23 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:23 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$679/0x000000080108c800] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:23 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:23 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.cloud.loadbalancer-org.springframework.cloud.client.loadbalancer.LoadBalancerClientsProperties' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerClientsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:23 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'default.org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:23 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'default.org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:23 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'default.org.springframework.cloud.netflix.eureka.loadbalancer.LoadBalancerEurekaAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:23 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerClientFactory' of type [org.springframework.cloud.loadbalancer.support.LoadBalancerClientFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:23 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'blockingLoadBalancerClient' of type [org.springframework.cloud.loadbalancer.blocking.client.BlockingLoadBalancerClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:24 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerServiceInstanceCookieTransformer' of type [org.springframework.cloud.loadbalancer.core.LoadBalancerServiceInstanceCookieTransformer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:24 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'xForwarderHeadersTransformer' of type [org.springframework.cloud.loadbalancer.blocking.XForwardedHeadersTransformer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:24 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:24 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerRequestFactory' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerRequestFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:24 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration$BlockingLoadBalancerRetryConfig' of type [org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration$BlockingLoadBalancerRetryConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:24 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancedRetryFactory' of type [org.springframework.cloud.loadbalancer.blocking.retry.BlockingLoadBalancedRetryFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:24 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerInterceptor' of type [org.springframework.cloud.client.loadbalancer.RetryLoadBalancerInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:25 [main] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8100 (http)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:25 [main] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8100"]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:25 [main] o.a.catalina.core.StandardService - Starting service [Tomcat]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:25 [main] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.16]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:25 [main] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:25 [main] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 12462 ms
simulation_2-blueprint-service-1  | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
simulation_2-database-restoration-service-1  | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
simulation_2-database-restoration-service-1  | 
simulation_2-database-restoration-service-1  |   .   ____          _            __ _ _
simulation_2-database-restoration-service-1  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
simulation_2-database-restoration-service-1  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
simulation_2-database-restoration-service-1  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
simulation_2-database-restoration-service-1  |   '  |____| .__|_| |_|_| |_\__, | / / / /
simulation_2-database-restoration-service-1  |  =========|_|==============|___/=/_/_/_/
simulation_2-database-restoration-service-1  |  :: Spring Boot ::                (v3.2.0)
simulation_2-database-restoration-service-1  | 
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:10.648Z  INFO 1 --- [database-restoration-service] [           main] .d.DatabaseRestorationServiceApplication : Starting DatabaseRestorationServiceApplication v0.0.1-SNAPSHOT using Java 17.0.2 with PID 1 (/app.jar started by root in /)
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:10.677Z  INFO 1 --- [database-restoration-service] [           main] .d.DatabaseRestorationServiceApplication : No active profile set, falling back to 1 default profile: "default"
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:19.356Z  INFO 1 --- [database-restoration-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:19.890Z  INFO 1 --- [database-restoration-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 506 ms. Found 0 Reactive MongoDB repository interfaces.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:19.948Z  INFO 1 --- [database-restoration-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:20.000Z  INFO 1 --- [database-restoration-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 52 ms. Found 2 MongoDB repository interfaces.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:21.608Z  INFO 1 --- [database-restoration-service] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=2d0e14d5-d1a0-3417-a8bd-63dbf509f98d
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.242Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$RetryInterceptorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$RetryInterceptorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [lbRestClientPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.267Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration' of type [org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.279Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration' of type [org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.334Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.359Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.360Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$579/0x000000080101a4b0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.369Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.418Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'spring.cloud.loadbalancer-org.springframework.cloud.client.loadbalancer.LoadBalancerClientsProperties' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerClientsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.450Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'default.org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.473Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'default.org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.484Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'default.org.springframework.cloud.netflix.eureka.loadbalancer.LoadBalancerEurekaAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.487Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerClientFactory' of type [org.springframework.cloud.loadbalancer.support.LoadBalancerClientFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.492Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'blockingLoadBalancerClient' of type [org.springframework.cloud.loadbalancer.blocking.client.BlockingLoadBalancerClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.589Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerServiceInstanceCookieTransformer' of type [org.springframework.cloud.loadbalancer.core.LoadBalancerServiceInstanceCookieTransformer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.594Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'xForwarderHeadersTransformer' of type [org.springframework.cloud.loadbalancer.blocking.XForwardedHeadersTransformer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.607Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.611Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerRequestFactory' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerRequestFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.627Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration$BlockingLoadBalancerRetryConfig' of type [org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration$BlockingLoadBalancerRetryConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.635Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancedRetryFactory' of type [org.springframework.cloud.loadbalancer.blocking.retry.BlockingLoadBalancedRetryFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:22.661Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerInterceptor' of type [org.springframework.cloud.client.loadbalancer.RetryLoadBalancerInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:23.835Z  INFO 1 --- [database-restoration-service] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port 8200 (http)
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:23.864Z  INFO 1 --- [database-restoration-service] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:23.876Z  INFO 1 --- [database-restoration-service] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.16]
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:24.034Z  INFO 1 --- [database-restoration-service] [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:24.035Z  INFO 1 --- [database-restoration-service] [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 12736 ms
simulation_2-database-restoration-service-1  | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:28.019Z  INFO 1 --- [database-restoration-service] [           main] org.mongodb.driver.client                : MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.11.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "aarch64", "version": "5.15.49-linuxkit"}, "platform": "Java/Oracle Corporation/17.0.2+8-86"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='RESTORATIONS_USER', source='RESTORATIONS_DB', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=NettyTransportSettings{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@38d42ab7, socketChannelClass=null, allocator=null, sslContext=null}, streamFactoryFactory=null, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@6ace919c], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@4005e485, com.mongodb.Jep395RecordCodecProvider@5f5c187d, com.mongodb.KotlinCodecProvider@464400b3]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@58182b96], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:29.218Z  INFO 1 --- [database-restoration-service] [}-mongodb:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=713598042}
simulation_2-metadata-extraction-service-1  | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
simulation_2-metadata-extraction-service-1  | 
simulation_2-metadata-extraction-service-1  |   .   ____          _            __ _ _
simulation_2-metadata-extraction-service-1  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
simulation_2-metadata-extraction-service-1  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
simulation_2-metadata-extraction-service-1  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
simulation_2-metadata-extraction-service-1  |   '  |____| .__|_| |_|_| |_\__, | / / / /
simulation_2-metadata-extraction-service-1  |  =========|_|==============|___/=/_/_/_/
simulation_2-metadata-extraction-service-1  |  :: Spring Boot ::                (v3.2.0)
simulation_2-metadata-extraction-service-1  | 
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:09.974Z  INFO 1 --- [metadata-extraction-service] [           main] a.m.MetadataExtractionServiceApplication : Starting MetadataExtractionServiceApplication vsimulation-case-1 using Java 17.0.2 with PID 1 (/app.jar started by root in /)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:09.976Z  INFO 1 --- [metadata-extraction-service] [           main] a.m.MetadataExtractionServiceApplication : No active profile set, falling back to 1 default profile: "default"
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:18.543Z  INFO 1 --- [metadata-extraction-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:19.116Z  INFO 1 --- [metadata-extraction-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 527 ms. Found 0 Reactive MongoDB repository interfaces.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:19.123Z  INFO 1 --- [metadata-extraction-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:19.188Z  INFO 1 --- [metadata-extraction-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 55 ms. Found 1 MongoDB repository interface.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:20.797Z  INFO 1 --- [metadata-extraction-service] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=6df4e22d-46ea-3356-8046-7693b04c62fa
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.540Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$RetryInterceptorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$RetryInterceptorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [lbRestClientPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.565Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration' of type [org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.578Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration' of type [org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.625Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.666Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.666Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$579/0x0000000801022e40] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.667Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.710Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'spring.cloud.loadbalancer-org.springframework.cloud.client.loadbalancer.LoadBalancerClientsProperties' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerClientsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.756Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'default.org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.761Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'default.org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.762Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'default.org.springframework.cloud.netflix.eureka.loadbalancer.LoadBalancerEurekaAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.770Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerClientFactory' of type [org.springframework.cloud.loadbalancer.support.LoadBalancerClientFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.791Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'blockingLoadBalancerClient' of type [org.springframework.cloud.loadbalancer.blocking.client.BlockingLoadBalancerClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.875Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerServiceInstanceCookieTransformer' of type [org.springframework.cloud.loadbalancer.core.LoadBalancerServiceInstanceCookieTransformer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.876Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'xForwarderHeadersTransformer' of type [org.springframework.cloud.loadbalancer.blocking.XForwardedHeadersTransformer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.877Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.887Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerRequestFactory' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerRequestFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.894Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration$BlockingLoadBalancerRetryConfig' of type [org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration$BlockingLoadBalancerRetryConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.896Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancedRetryFactory' of type [org.springframework.cloud.loadbalancer.blocking.retry.BlockingLoadBalancedRetryFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:21.936Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerInterceptor' of type [org.springframework.cloud.client.loadbalancer.RetryLoadBalancerInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:23.112Z  INFO 1 --- [metadata-extraction-service] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port 8300 (http)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:23.179Z  INFO 1 --- [metadata-extraction-service] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:23.180Z  INFO 1 --- [metadata-extraction-service] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.16]
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:23.314Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:23.315Z  INFO 1 --- [metadata-extraction-service] [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 12958 ms
simulation_2-metadata-extraction-service-1  | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:26.155Z  INFO 1 --- [metadata-extraction-service] [}-mongodb:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=61726500}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:26.182Z  INFO 1 --- [metadata-extraction-service] [           main] org.mongodb.driver.client                : MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.11.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "aarch64", "version": "5.15.49-linuxkit"}, "platform": "Java/Oracle Corporation/17.0.2+8-86"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='METADATA_USER', source='METADATA_DB', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@14ed7ddf], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@892af0e, com.mongodb.Jep395RecordCodecProvider@446c8c72, com.mongodb.KotlinCodecProvider@6e2eead5]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@11d2714a], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:30 [main] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.11.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "aarch64", "version": "5.15.49-linuxkit"}, "platform": "Java/Oracle Corporation/17.0.2+8-86"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='BLUEPRINTS_USER', source='BLUEPRINTS_DB', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=NettyTransportSettings{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@2295566b, socketChannelClass=null, allocator=null, sslContext=null}, streamFactoryFactory=null, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@6a2badb1], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@174e1b99, com.mongodb.Jep395RecordCodecProvider@53a09566, com.mongodb.KotlinCodecProvider@1c815814]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@6f68756d], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:31 [cluster-ClusterId{value='65b6b4797f5cc474efd7d126', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=440117459}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.052Z  INFO 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaRetryConfig          : Retrying in Kafka Consumer is disabled, backoff will not be used...
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.157Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: dead-letter
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.231Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: created-blueprint
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.232Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: anonymization-execution
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.233Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: anonymization-execution-success
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.245Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: anonymization-execution-failure
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.246Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: restore-success
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.247Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: restore-failure
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.247Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: operations
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.248Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: load-success
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.259Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: load-failure
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.266Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: extraction-success
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.272Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: extraction-failure
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.273Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-anonymize-success
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.289Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-anonymize-failure
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.289Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-script-success
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.290Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-script-failure
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:33.293Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: created-worksheet
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:34.246Z  INFO 1 --- [metadata-extraction-service] [           main] org.mongodb.driver.client                : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.11.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "aarch64", "version": "5.15.49-linuxkit"}, "platform": "Java/Oracle Corporation/17.0.2+8-86"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='METADATA_USER', source='METADATA_DB', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@14ed7ddf], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@892af0e, com.mongodb.Jep395RecordCodecProvider@446c8c72, com.mongodb.KotlinCodecProvider@6e2eead5]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@11d2714a], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:34.500Z  INFO 1 --- [metadata-extraction-service] [}-mongodb:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=135678500}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:36.126Z  INFO 1 --- [metadata-extraction-service] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:36.289Z  WARN 1 --- [metadata-extraction-service] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:36.320Z  INFO 1 --- [metadata-extraction-service] [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 2 endpoint(s) beneath base path '/actuator'
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:37.106Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
simulation_2-metadata-extraction-service-1  | 	auto.include.jmx.reporter = true
simulation_2-metadata-extraction-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-metadata-extraction-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-metadata-extraction-service-1  | 	client.id = 
simulation_2-metadata-extraction-service-1  | 	connections.max.idle.ms = 300000
simulation_2-metadata-extraction-service-1  | 	default.api.timeout.ms = 60000
simulation_2-metadata-extraction-service-1  | 	metadata.max.age.ms = 300000
simulation_2-metadata-extraction-service-1  | 	metric.reporters = []
simulation_2-metadata-extraction-service-1  | 	metrics.num.samples = 2
simulation_2-metadata-extraction-service-1  | 	metrics.recording.level = INFO
simulation_2-metadata-extraction-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-metadata-extraction-service-1  | 	receive.buffer.bytes = 65536
simulation_2-metadata-extraction-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-metadata-extraction-service-1  | 	reconnect.backoff.ms = 50
simulation_2-metadata-extraction-service-1  | 	request.timeout.ms = 30000
simulation_2-metadata-extraction-service-1  | 	retries = 2147483647
simulation_2-metadata-extraction-service-1  | 	retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.jaas.config = null
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.service.name = null
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-metadata-extraction-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-metadata-extraction-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-metadata-extraction-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-metadata-extraction-service-1  | 	security.protocol = PLAINTEXT
simulation_2-metadata-extraction-service-1  | 	security.providers = null
simulation_2-metadata-extraction-service-1  | 	send.buffer.bytes = 131072
simulation_2-metadata-extraction-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-metadata-extraction-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-metadata-extraction-service-1  | 	ssl.cipher.suites = null
simulation_2-metadata-extraction-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-metadata-extraction-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-metadata-extraction-service-1  | 	ssl.engine.factory.class = null
simulation_2-metadata-extraction-service-1  | 	ssl.key.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.key = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.location = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.type = JKS
simulation_2-metadata-extraction-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-metadata-extraction-service-1  | 	ssl.provider = null
simulation_2-metadata-extraction-service-1  | 	ssl.secure.random.implementation = null
simulation_2-metadata-extraction-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.certificates = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.location = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.type = JKS
simulation_2-metadata-extraction-service-1  | 
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:37.534Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:37.535Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:37.535Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472577533
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.795Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: dead-letter
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.831Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: created-blueprint
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.838Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: anonymization-execution
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.870Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: anonymization-execution-success
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.895Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: anonymization-execution-failure
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.897Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: restore-success
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.900Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: restore-failure
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.903Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: operations
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.911Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: load-success
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.913Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: load-failure
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.925Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: extraction-success
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.934Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: extraction-failure
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.942Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-anonymize-success
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.942Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-anonymize-failure
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.943Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-script-success
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.943Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-script-failure
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:39.958Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: created-worksheet
simulation_2-blueprint-service-1  | 20:09:40,701 |-WARN in net.logstash.logback.appender.LogstashTcpSocketAppender[LOGSTASH] - Log destination logstash/<unresolved>:5001: connection failed. java.net.ConnectException: Connection refused
simulation_2-blueprint-service-1  | 	at java.net.ConnectException: Connection refused
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)
simulation_2-blueprint-service-1  | 	at 	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
simulation_2-blueprint-service-1  | 	at 	at java.base/java.net.Socket.connect(Socket.java:633)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.appender.AbstractLogstashTcpSocketAppender$TcpSendingEventHandler.openSocket(AbstractLogstashTcpSocketAppender.java:765)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.appender.AbstractLogstashTcpSocketAppender$TcpSendingEventHandler.onStart(AbstractLogstashTcpSocketAppender.java:691)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.appender.AsyncDisruptorAppender$EventClearingEventHandler.onStart(AsyncDisruptorAppender.java:382)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.encoder.com.lmax.disruptor.BatchEventProcessor.notifyStart(BatchEventProcessor.java:224)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.encoder.com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:120)
simulation_2-blueprint-service-1  | 	at 	at java.base/java.lang.Thread.run(Thread.java:833)
simulation_2-blueprint-service-1  | 20:09:40,721 |-WARN in net.logstash.logback.appender.LogstashTcpSocketAppender[LOGSTASH] - Log destination logstash/<unresolved>:5001: Waiting 29978ms before attempting reconnection.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:40.809Z  INFO 1 --- [database-restoration-service] [}-mongodb:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=84145542}
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: dead-letter
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: created-blueprint
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: anonymization-execution
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: anonymization-execution-success
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: anonymization-execution-failure
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: restore-success
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: restore-failure
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: operations
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: load-success
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: load-failure
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: extraction-success
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: extraction-failure
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: transformation-anonymize-success
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: transformation-anonymize-failure
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: transformation-script-success
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: transformation-script-failure
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:40 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: created-worksheet
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:40.909Z  INFO 1 --- [database-restoration-service] [           main] org.mongodb.driver.client                : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.11.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "aarch64", "version": "5.15.49-linuxkit"}, "platform": "Java/Oracle Corporation/17.0.2+8-86"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='RESTORATIONS_USER', source='RESTORATIONS_DB', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=NettyTransportSettings{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@5a45c218, socketChannelClass=null, allocator=null, sslContext=null}, streamFactoryFactory=null, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@6ace919c], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@4005e485, com.mongodb.Jep395RecordCodecProvider@5f5c187d, com.mongodb.KotlinCodecProvider@464400b3]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@58182b96], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:41.120Z  INFO 1 --- [metadata-extraction-service] [| adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:41.166Z  INFO 1 --- [metadata-extraction-service] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:41.166Z  INFO 1 --- [metadata-extraction-service] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:41.166Z  INFO 1 --- [metadata-extraction-service] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:41.284Z  INFO 1 --- [metadata-extraction-service] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:41.472Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:41 [main] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.11.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "aarch64", "version": "5.15.49-linuxkit"}, "platform": "Java/Oracle Corporation/17.0.2+8-86"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='BLUEPRINTS_USER', source='BLUEPRINTS_DB', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=NettyTransportSettings{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@43f5b014, socketChannelClass=null, allocator=null, sslContext=null}, streamFactoryFactory=null, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@6a2badb1], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@174e1b99, com.mongodb.Jep395RecordCodecProvider@53a09566, com.mongodb.KotlinCodecProvider@1c815814]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@6f68756d], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:41.496Z  INFO 1 --- [metadata-extraction-service] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:41 [cluster-ClusterId{value='65b6b4857f5cc474efd7d127', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=44877542}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:41.617Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:41.622Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:41.623Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:41.624Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:41.624Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:41.624Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:41.625Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:44.285Z  INFO 1 --- [database-restoration-service] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:44.491Z  WARN 1 --- [database-restoration-service] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:44.524Z  INFO 1 --- [database-restoration-service] [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 2 endpoint(s) beneath base path '/actuator'
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:44 [main] o.s.c.n.e.c.DiscoveryClientOptionalArgsConfiguration - Eureka HTTP Client uses RestTemplate.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:45 [main] o.s.c.l.c.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger - Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:45 [main] o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:45.374Z  INFO 1 --- [database-restoration-service] [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
simulation_2-database-restoration-service-1  | 	auto.include.jmx.reporter = true
simulation_2-database-restoration-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-database-restoration-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-database-restoration-service-1  | 	client.id = 
simulation_2-database-restoration-service-1  | 	connections.max.idle.ms = 300000
simulation_2-database-restoration-service-1  | 	default.api.timeout.ms = 60000
simulation_2-database-restoration-service-1  | 	metadata.max.age.ms = 300000
simulation_2-database-restoration-service-1  | 	metric.reporters = []
simulation_2-database-restoration-service-1  | 	metrics.num.samples = 2
simulation_2-database-restoration-service-1  | 	metrics.recording.level = INFO
simulation_2-database-restoration-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-database-restoration-service-1  | 	receive.buffer.bytes = 65536
simulation_2-database-restoration-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-database-restoration-service-1  | 	reconnect.backoff.ms = 50
simulation_2-database-restoration-service-1  | 	request.timeout.ms = 30000
simulation_2-database-restoration-service-1  | 	retries = 2147483647
simulation_2-database-restoration-service-1  | 	retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.jaas.config = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-database-restoration-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-database-restoration-service-1  | 	sasl.kerberos.service.name = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-database-restoration-service-1  | 	security.protocol = PLAINTEXT
simulation_2-database-restoration-service-1  | 	security.providers = null
simulation_2-database-restoration-service-1  | 	send.buffer.bytes = 131072
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-database-restoration-service-1  | 	ssl.cipher.suites = null
simulation_2-database-restoration-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-database-restoration-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-database-restoration-service-1  | 	ssl.engine.factory.class = null
simulation_2-database-restoration-service-1  | 	ssl.key.password = null
simulation_2-database-restoration-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-database-restoration-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.key = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.location = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.password = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.type = JKS
simulation_2-database-restoration-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-database-restoration-service-1  | 	ssl.provider = null
simulation_2-database-restoration-service-1  | 	ssl.secure.random.implementation = null
simulation_2-database-restoration-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-database-restoration-service-1  | 	ssl.truststore.certificates = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.location = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.password = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.type = JKS
simulation_2-database-restoration-service-1  | 
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:45.837Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:45.837Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:45.838Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472585835
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:45.890Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:45.903Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:45.911Z  INFO 1 --- [metadata-extraction-service] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:45.958Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1706472585939 with initial instances count: 0
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:45.994Z  INFO 1 --- [metadata-extraction-service] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application METADATA-EXTRACTION-SERVICE with eureka with status UP
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:46.003Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1706472586003, current=UP, previous=STARTING]
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:46.006Z  INFO 1 --- [metadata-extraction-service] [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_METADATA-EXTRACTION-SERVICE/020eac73fef5:metadata-extraction-service:8300: registering service...
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:46.299Z  INFO 1 --- [metadata-extraction-service] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port 8300 (http) with context path ''
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:46.304Z  INFO 1 --- [metadata-extraction-service] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8300
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:46.512Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
simulation_2-metadata-extraction-service-1  | 	allow.auto.create.topics = true
simulation_2-metadata-extraction-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-metadata-extraction-service-1  | 	auto.include.jmx.reporter = true
simulation_2-metadata-extraction-service-1  | 	auto.offset.reset = latest
simulation_2-metadata-extraction-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-metadata-extraction-service-1  | 	check.crcs = true
simulation_2-metadata-extraction-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-metadata-extraction-service-1  | 	client.id = consumer-metadata-extraction-service-group-1
simulation_2-metadata-extraction-service-1  | 	client.rack = 
simulation_2-metadata-extraction-service-1  | 	connections.max.idle.ms = 540000
simulation_2-metadata-extraction-service-1  | 	default.api.timeout.ms = 60000
simulation_2-metadata-extraction-service-1  | 	enable.auto.commit = false
simulation_2-metadata-extraction-service-1  | 	exclude.internal.topics = true
simulation_2-metadata-extraction-service-1  | 	fetch.max.bytes = 52428800
simulation_2-metadata-extraction-service-1  | 	fetch.max.wait.ms = 500
simulation_2-metadata-extraction-service-1  | 	fetch.min.bytes = 1
simulation_2-metadata-extraction-service-1  | 	group.id = metadata-extraction-service-group
simulation_2-metadata-extraction-service-1  | 	group.instance.id = null
simulation_2-metadata-extraction-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-metadata-extraction-service-1  | 	interceptor.classes = []
simulation_2-metadata-extraction-service-1  | 	internal.leave.group.on.close = true
simulation_2-metadata-extraction-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-metadata-extraction-service-1  | 	isolation.level = read_uncommitted
simulation_2-metadata-extraction-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-metadata-extraction-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-metadata-extraction-service-1  | 	max.poll.interval.ms = 90000
simulation_2-metadata-extraction-service-1  | 	max.poll.records = 500
simulation_2-metadata-extraction-service-1  | 	metadata.max.age.ms = 300000
simulation_2-metadata-extraction-service-1  | 	metric.reporters = []
simulation_2-metadata-extraction-service-1  | 	metrics.num.samples = 2
simulation_2-metadata-extraction-service-1  | 	metrics.recording.level = INFO
simulation_2-metadata-extraction-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-metadata-extraction-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-metadata-extraction-service-1  | 	receive.buffer.bytes = 65536
simulation_2-metadata-extraction-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-metadata-extraction-service-1  | 	reconnect.backoff.ms = 50
simulation_2-metadata-extraction-service-1  | 	request.timeout.ms = 30000
simulation_2-metadata-extraction-service-1  | 	retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.jaas.config = null
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.service.name = null
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-metadata-extraction-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-metadata-extraction-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-metadata-extraction-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-metadata-extraction-service-1  | 	security.protocol = PLAINTEXT
simulation_2-metadata-extraction-service-1  | 	security.providers = null
simulation_2-metadata-extraction-service-1  | 	send.buffer.bytes = 131072
simulation_2-metadata-extraction-service-1  | 	session.timeout.ms = 45000
simulation_2-metadata-extraction-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-metadata-extraction-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-metadata-extraction-service-1  | 	ssl.cipher.suites = null
simulation_2-metadata-extraction-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-metadata-extraction-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-metadata-extraction-service-1  | 	ssl.engine.factory.class = null
simulation_2-metadata-extraction-service-1  | 	ssl.key.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.key = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.location = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.type = JKS
simulation_2-metadata-extraction-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-metadata-extraction-service-1  | 	ssl.provider = null
simulation_2-metadata-extraction-service-1  | 	ssl.secure.random.implementation = null
simulation_2-metadata-extraction-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.certificates = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.location = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.type = JKS
simulation_2-metadata-extraction-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-metadata-extraction-service-1  | 
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:46 [main] o.a.k.c.admin.AdminClientConfig - AdminClientConfig values: 
simulation_2-blueprint-service-1  | 	auto.include.jmx.reporter = true
simulation_2-blueprint-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-blueprint-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-blueprint-service-1  | 	client.id = 
simulation_2-blueprint-service-1  | 	connections.max.idle.ms = 300000
simulation_2-blueprint-service-1  | 	default.api.timeout.ms = 60000
simulation_2-blueprint-service-1  | 	metadata.max.age.ms = 300000
simulation_2-blueprint-service-1  | 	metric.reporters = []
simulation_2-blueprint-service-1  | 	metrics.num.samples = 2
simulation_2-blueprint-service-1  | 	metrics.recording.level = INFO
simulation_2-blueprint-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-blueprint-service-1  | 	receive.buffer.bytes = 65536
simulation_2-blueprint-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-blueprint-service-1  | 	reconnect.backoff.ms = 50
simulation_2-blueprint-service-1  | 	request.timeout.ms = 30000
simulation_2-blueprint-service-1  | 	retries = 2147483647
simulation_2-blueprint-service-1  | 	retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.jaas.config = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-blueprint-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-blueprint-service-1  | 	sasl.kerberos.service.name = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.login.class = null
simulation_2-blueprint-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-blueprint-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-blueprint-service-1  | 	security.protocol = PLAINTEXT
simulation_2-blueprint-service-1  | 	security.providers = null
simulation_2-blueprint-service-1  | 	send.buffer.bytes = 131072
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-blueprint-service-1  | 	ssl.cipher.suites = null
simulation_2-blueprint-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-blueprint-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-blueprint-service-1  | 	ssl.engine.factory.class = null
simulation_2-blueprint-service-1  | 	ssl.key.password = null
simulation_2-blueprint-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-blueprint-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-blueprint-service-1  | 	ssl.keystore.key = null
simulation_2-blueprint-service-1  | 	ssl.keystore.location = null
simulation_2-blueprint-service-1  | 	ssl.keystore.password = null
simulation_2-blueprint-service-1  | 	ssl.keystore.type = JKS
simulation_2-blueprint-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-blueprint-service-1  | 	ssl.provider = null
simulation_2-blueprint-service-1  | 	ssl.secure.random.implementation = null
simulation_2-blueprint-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-blueprint-service-1  | 	ssl.truststore.certificates = null
simulation_2-blueprint-service-1  | 	ssl.truststore.location = null
simulation_2-blueprint-service-1  | 	ssl.truststore.password = null
simulation_2-blueprint-service-1  | 	ssl.truststore.type = JKS
simulation_2-blueprint-service-1  | 
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:46.611Z  INFO 1 --- [metadata-extraction-service] [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_METADATA-EXTRACTION-SERVICE/020eac73fef5:metadata-extraction-service:8300 - registration status: 204
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:46.850Z  INFO 1 --- [database-restoration-service] [| adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:46.857Z  INFO 1 --- [database-restoration-service] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:46.857Z  INFO 1 --- [database-restoration-service] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:46.857Z  INFO 1 --- [database-restoration-service] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:46.910Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:46.910Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:46.910Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472586910
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:46.917Z  INFO 1 --- [metadata-extraction-service] [           main] fkaConsumerFactory$ExtendedKafkaConsumer : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Subscribed to topic(s): restore-success
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:46.950Z  INFO 1 --- [database-restoration-service] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:46 [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:46 [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 60e845626d8a465a
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:46 [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706472586985
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:47.076Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Cluster ID: AuB6J3ZDSAyfYI6omDK5Jg
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:47.089Z  INFO 1 --- [metadata-extraction-service] [           main] a.m.MetadataExtractionServiceApplication : Started MetadataExtractionServiceApplication in 40.776 seconds (process running for 44.751)
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:47.165Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:47.211Z  INFO 1 --- [database-restoration-service] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:47.411Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:47.411Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:47.411Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:47.411Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:47.411Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:47.411Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:47.411Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:47 [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:47 [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:47 [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:47 [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:47 [main] o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:48 [main] c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:48 [main] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:48 [main] c.netflix.discovery.DiscoveryClient - Disable delta property : false
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:48 [main] c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:48 [main] c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:48 [main] c.netflix.discovery.DiscoveryClient - Application is null : false
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:48 [main] c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:48 [main] c.netflix.discovery.DiscoveryClient - Application version is -1: true
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:48 [main] c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:48.776Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:48.804Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:48.832Z  INFO 1 --- [database-restoration-service] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:48.869Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1706472588855 with initial instances count: 0
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:48.870Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:48.875Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] (Re-)joining group
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:48.902Z  INFO 1 --- [database-restoration-service] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application DATABASE-RESTORATION-SERVICE with eureka with status UP
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:48.903Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1706472588903, current=UP, previous=STARTING]
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:48.928Z  INFO 1 --- [database-restoration-service] [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_DATABASE-RESTORATION-SERVICE/59a1a9f2a13d:database-restoration-service:8200: registering service...
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:49.216Z  INFO 1 --- [database-restoration-service] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port 8200 (http) with context path ''
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:49.218Z  INFO 1 --- [database-restoration-service] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8200
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:49.232Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Request joining group due to: need to re-join with the given member-id: consumer-metadata-extraction-service-group-1-71f9ad05-2f73-42e3-aae0-5956c00b31c3
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:49.233Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:49.235Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] (Re-)joining group
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:49.429Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-metadata-extraction-service-group-1-71f9ad05-2f73-42e3-aae0-5956c00b31c3', protocol='range'}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:49.548Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Finished assignment for group at generation 1: {consumer-metadata-extraction-service-group-1-71f9ad05-2f73-42e3-aae0-5956c00b31c3=Assignment(partitions=[restore-success-0])}
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:49.680Z  INFO 1 --- [database-restoration-service] [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_DATABASE-RESTORATION-SERVICE/59a1a9f2a13d:database-restoration-service:8200 - registration status: 204
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:49.719Z  INFO 1 --- [database-restoration-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
simulation_2-database-restoration-service-1  | 	allow.auto.create.topics = true
simulation_2-database-restoration-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-database-restoration-service-1  | 	auto.include.jmx.reporter = true
simulation_2-database-restoration-service-1  | 	auto.offset.reset = latest
simulation_2-database-restoration-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-database-restoration-service-1  | 	check.crcs = true
simulation_2-database-restoration-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-database-restoration-service-1  | 	client.id = consumer-database-restoration-service-group-1
simulation_2-database-restoration-service-1  | 	client.rack = 
simulation_2-database-restoration-service-1  | 	connections.max.idle.ms = 540000
simulation_2-database-restoration-service-1  | 	default.api.timeout.ms = 60000
simulation_2-database-restoration-service-1  | 	enable.auto.commit = false
simulation_2-database-restoration-service-1  | 	exclude.internal.topics = true
simulation_2-database-restoration-service-1  | 	fetch.max.bytes = 52428800
simulation_2-database-restoration-service-1  | 	fetch.max.wait.ms = 500
simulation_2-database-restoration-service-1  | 	fetch.min.bytes = 1
simulation_2-database-restoration-service-1  | 	group.id = database-restoration-service-group
simulation_2-database-restoration-service-1  | 	group.instance.id = null
simulation_2-database-restoration-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-database-restoration-service-1  | 	interceptor.classes = []
simulation_2-database-restoration-service-1  | 	internal.leave.group.on.close = true
simulation_2-database-restoration-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-database-restoration-service-1  | 	isolation.level = read_uncommitted
simulation_2-database-restoration-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-database-restoration-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-database-restoration-service-1  | 	max.poll.interval.ms = 90000
simulation_2-database-restoration-service-1  | 	max.poll.records = 500
simulation_2-database-restoration-service-1  | 	metadata.max.age.ms = 300000
simulation_2-database-restoration-service-1  | 	metric.reporters = []
simulation_2-database-restoration-service-1  | 	metrics.num.samples = 2
simulation_2-database-restoration-service-1  | 	metrics.recording.level = INFO
simulation_2-database-restoration-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-database-restoration-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-database-restoration-service-1  | 	receive.buffer.bytes = 65536
simulation_2-database-restoration-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-database-restoration-service-1  | 	reconnect.backoff.ms = 50
simulation_2-database-restoration-service-1  | 	request.timeout.ms = 30000
simulation_2-database-restoration-service-1  | 	retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.jaas.config = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-database-restoration-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-database-restoration-service-1  | 	sasl.kerberos.service.name = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-database-restoration-service-1  | 	security.protocol = PLAINTEXT
simulation_2-database-restoration-service-1  | 	security.providers = null
simulation_2-database-restoration-service-1  | 	send.buffer.bytes = 131072
simulation_2-database-restoration-service-1  | 	session.timeout.ms = 45000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-database-restoration-service-1  | 	ssl.cipher.suites = null
simulation_2-database-restoration-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-database-restoration-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-database-restoration-service-1  | 	ssl.engine.factory.class = null
simulation_2-database-restoration-service-1  | 	ssl.key.password = null
simulation_2-database-restoration-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-database-restoration-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.key = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.location = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.password = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.type = JKS
simulation_2-database-restoration-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-database-restoration-service-1  | 	ssl.provider = null
simulation_2-database-restoration-service-1  | 	ssl.secure.random.implementation = null
simulation_2-database-restoration-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-database-restoration-service-1  | 	ssl.truststore.certificates = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.location = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.password = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.type = JKS
simulation_2-database-restoration-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-database-restoration-service-1  | 
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:49.766Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-metadata-extraction-service-group-1-71f9ad05-2f73-42e3-aae0-5956c00b31c3', protocol='range'}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:49.766Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Notifying assignor about the new Assignment(partitions=[restore-success-0])
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:49.771Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Adding newly assigned partitions: restore-success-0
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:49.815Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Found no committed offset for partition restore-success-0
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:49.833Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Found no committed offset for partition restore-success-0
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:49.857Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Resetting offset for partition restore-success-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:09:49.874Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : metadata-extraction-service-group: partitions assigned: [restore-success-0]
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:49.956Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:49.963Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:49.963Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472589956
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:49.969Z  INFO 1 --- [database-restoration-service] [           main] fkaConsumerFactory$ExtendedKafkaConsumer : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Subscribed to topic(s): created-blueprint
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.016Z  INFO 1 --- [database-restoration-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
simulation_2-database-restoration-service-1  | 	allow.auto.create.topics = true
simulation_2-database-restoration-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-database-restoration-service-1  | 	auto.include.jmx.reporter = true
simulation_2-database-restoration-service-1  | 	auto.offset.reset = latest
simulation_2-database-restoration-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-database-restoration-service-1  | 	check.crcs = true
simulation_2-database-restoration-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-database-restoration-service-1  | 	client.id = consumer-database-restoration-service-group-2
simulation_2-database-restoration-service-1  | 	client.rack = 
simulation_2-database-restoration-service-1  | 	connections.max.idle.ms = 540000
simulation_2-database-restoration-service-1  | 	default.api.timeout.ms = 60000
simulation_2-database-restoration-service-1  | 	enable.auto.commit = false
simulation_2-database-restoration-service-1  | 	exclude.internal.topics = true
simulation_2-database-restoration-service-1  | 	fetch.max.bytes = 52428800
simulation_2-database-restoration-service-1  | 	fetch.max.wait.ms = 500
simulation_2-database-restoration-service-1  | 	fetch.min.bytes = 1
simulation_2-database-restoration-service-1  | 	group.id = database-restoration-service-group
simulation_2-database-restoration-service-1  | 	group.instance.id = null
simulation_2-database-restoration-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-database-restoration-service-1  | 	interceptor.classes = []
simulation_2-database-restoration-service-1  | 	internal.leave.group.on.close = true
simulation_2-database-restoration-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-database-restoration-service-1  | 	isolation.level = read_uncommitted
simulation_2-database-restoration-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-database-restoration-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-database-restoration-service-1  | 	max.poll.interval.ms = 90000
simulation_2-database-restoration-service-1  | 	max.poll.records = 500
simulation_2-database-restoration-service-1  | 	metadata.max.age.ms = 300000
simulation_2-database-restoration-service-1  | 	metric.reporters = []
simulation_2-database-restoration-service-1  | 	metrics.num.samples = 2
simulation_2-database-restoration-service-1  | 	metrics.recording.level = INFO
simulation_2-database-restoration-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-database-restoration-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-database-restoration-service-1  | 	receive.buffer.bytes = 65536
simulation_2-database-restoration-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-database-restoration-service-1  | 	reconnect.backoff.ms = 50
simulation_2-database-restoration-service-1  | 	request.timeout.ms = 30000
simulation_2-database-restoration-service-1  | 	retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.jaas.config = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-database-restoration-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-database-restoration-service-1  | 	sasl.kerberos.service.name = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-database-restoration-service-1  | 	security.protocol = PLAINTEXT
simulation_2-database-restoration-service-1  | 	security.providers = null
simulation_2-database-restoration-service-1  | 	send.buffer.bytes = 131072
simulation_2-database-restoration-service-1  | 	session.timeout.ms = 45000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-database-restoration-service-1  | 	ssl.cipher.suites = null
simulation_2-database-restoration-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-database-restoration-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-database-restoration-service-1  | 	ssl.engine.factory.class = null
simulation_2-database-restoration-service-1  | 	ssl.key.password = null
simulation_2-database-restoration-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-database-restoration-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.key = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.location = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.password = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.type = JKS
simulation_2-database-restoration-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-database-restoration-service-1  | 	ssl.provider = null
simulation_2-database-restoration-service-1  | 	ssl.secure.random.implementation = null
simulation_2-database-restoration-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-database-restoration-service-1  | 	ssl.truststore.certificates = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.location = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.password = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.type = JKS
simulation_2-database-restoration-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-database-restoration-service-1  | 
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.054Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.054Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.054Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472590054
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.055Z  INFO 1 --- [database-restoration-service] [           main] fkaConsumerFactory$ExtendedKafkaConsumer : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Subscribed to topic(s): created-worksheet
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.091Z  INFO 1 --- [database-restoration-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
simulation_2-database-restoration-service-1  | 	allow.auto.create.topics = true
simulation_2-database-restoration-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-database-restoration-service-1  | 	auto.include.jmx.reporter = true
simulation_2-database-restoration-service-1  | 	auto.offset.reset = latest
simulation_2-database-restoration-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-database-restoration-service-1  | 	check.crcs = true
simulation_2-database-restoration-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-database-restoration-service-1  | 	client.id = consumer-database-restoration-service-group-3
simulation_2-database-restoration-service-1  | 	client.rack = 
simulation_2-database-restoration-service-1  | 	connections.max.idle.ms = 540000
simulation_2-database-restoration-service-1  | 	default.api.timeout.ms = 60000
simulation_2-database-restoration-service-1  | 	enable.auto.commit = false
simulation_2-database-restoration-service-1  | 	exclude.internal.topics = true
simulation_2-database-restoration-service-1  | 	fetch.max.bytes = 52428800
simulation_2-database-restoration-service-1  | 	fetch.max.wait.ms = 500
simulation_2-database-restoration-service-1  | 	fetch.min.bytes = 1
simulation_2-database-restoration-service-1  | 	group.id = database-restoration-service-group
simulation_2-database-restoration-service-1  | 	group.instance.id = null
simulation_2-database-restoration-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-database-restoration-service-1  | 	interceptor.classes = []
simulation_2-database-restoration-service-1  | 	internal.leave.group.on.close = true
simulation_2-database-restoration-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-database-restoration-service-1  | 	isolation.level = read_uncommitted
simulation_2-database-restoration-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-database-restoration-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-database-restoration-service-1  | 	max.poll.interval.ms = 90000
simulation_2-database-restoration-service-1  | 	max.poll.records = 500
simulation_2-database-restoration-service-1  | 	metadata.max.age.ms = 300000
simulation_2-database-restoration-service-1  | 	metric.reporters = []
simulation_2-database-restoration-service-1  | 	metrics.num.samples = 2
simulation_2-database-restoration-service-1  | 	metrics.recording.level = INFO
simulation_2-database-restoration-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-database-restoration-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-database-restoration-service-1  | 	receive.buffer.bytes = 65536
simulation_2-database-restoration-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-database-restoration-service-1  | 	reconnect.backoff.ms = 50
simulation_2-database-restoration-service-1  | 	request.timeout.ms = 30000
simulation_2-database-restoration-service-1  | 	retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.jaas.config = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-database-restoration-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-database-restoration-service-1  | 	sasl.kerberos.service.name = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-database-restoration-service-1  | 	security.protocol = PLAINTEXT
simulation_2-database-restoration-service-1  | 	security.providers = null
simulation_2-database-restoration-service-1  | 	send.buffer.bytes = 131072
simulation_2-database-restoration-service-1  | 	session.timeout.ms = 45000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-database-restoration-service-1  | 	ssl.cipher.suites = null
simulation_2-database-restoration-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-database-restoration-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-database-restoration-service-1  | 	ssl.engine.factory.class = null
simulation_2-database-restoration-service-1  | 	ssl.key.password = null
simulation_2-database-restoration-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-database-restoration-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.key = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.location = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.password = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.type = JKS
simulation_2-database-restoration-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-database-restoration-service-1  | 	ssl.provider = null
simulation_2-database-restoration-service-1  | 	ssl.secure.random.implementation = null
simulation_2-database-restoration-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-database-restoration-service-1  | 	ssl.truststore.certificates = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.location = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.password = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.type = JKS
simulation_2-database-restoration-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-database-restoration-service-1  | 
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.094Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.100Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.100Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472590094
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.104Z  INFO 1 --- [database-restoration-service] [           main] fkaConsumerFactory$ExtendedKafkaConsumer : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Subscribed to topic(s): metadata-failure
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.094Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Cluster ID: AuB6J3ZDSAyfYI6omDK5Jg
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.105Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Cluster ID: AuB6J3ZDSAyfYI6omDK5Jg
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.106Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.114Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.114Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.144Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.195Z  WARN 1 --- [database-restoration-service] [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Error while fetching metadata with correlation id 2 : {metadata-failure=LEADER_NOT_AVAILABLE}
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.196Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Cluster ID: AuB6J3ZDSAyfYI6omDK5Jg
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.198Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.208Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.213Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Request joining group due to: need to re-join with the given member-id: consumer-database-restoration-service-group-1-49aba82c-a97f-4825-87cf-d45b82b6f352
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.213Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.217Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.217Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Request joining group due to: need to re-join with the given member-id: consumer-database-restoration-service-group-3-75e5a3c2-b12b-484b-86e9-128561f0faba
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.221Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.225Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.241Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-database-restoration-service-group-1-49aba82c-a97f-4825-87cf-d45b82b6f352', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.241Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-database-restoration-service-group-3-75e5a3c2-b12b-484b-86e9-128561f0faba', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.260Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Request joining group due to: need to re-join with the given member-id: consumer-database-restoration-service-group-2-d58b0128-e68b-4a1f-8ec3-9ccce03f3df7
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.262Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.269Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.276Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=1, memberId='consumer-database-restoration-service-group-3-75e5a3c2-b12b-484b-86e9-128561f0faba', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.280Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.280Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.289Z  WARN 1 --- [database-restoration-service] [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Error while fetching metadata with correlation id 7 : {metadata-failure=LEADER_NOT_AVAILABLE}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] c.netflix.discovery.DiscoveryClient - The response status is 200
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.319Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Finished assignment for group at generation 1: {consumer-database-restoration-service-group-1-49aba82c-a97f-4825-87cf-d45b82b6f352=Assignment(partitions=[created-blueprint-0]), consumer-database-restoration-service-group-3-75e5a3c2-b12b-484b-86e9-128561f0faba=Assignment(partitions=[])}
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.333Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=1, memberId='consumer-database-restoration-service-group-1-49aba82c-a97f-4825-87cf-d45b82b6f352', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.334Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.335Z  INFO 1 --- [database-restoration-service] [           main] .d.DatabaseRestorationServiceApplication : Started DatabaseRestorationServiceApplication in 43.599 seconds (process running for 48.633)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.334Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.349Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-database-restoration-service-group-3-75e5a3c2-b12b-484b-86e9-128561f0faba', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.349Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-database-restoration-service-group-1-49aba82c-a97f-4825-87cf-d45b82b6f352', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.351Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-database-restoration-service-group-2-d58b0128-e68b-4a1f-8ec3-9ccce03f3df7', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.358Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Finished assignment for group at generation 2: {consumer-database-restoration-service-group-2-d58b0128-e68b-4a1f-8ec3-9ccce03f3df7=Assignment(partitions=[created-worksheet-0]), consumer-database-restoration-service-group-1-49aba82c-a97f-4825-87cf-d45b82b6f352=Assignment(partitions=[created-blueprint-0]), consumer-database-restoration-service-group-3-75e5a3c2-b12b-484b-86e9-128561f0faba=Assignment(partitions=[metadata-failure-0])}
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.371Z  INFO 1 --- [database-restoration-service] [n-service-group] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-database-restoration-service-group-1-49aba82c-a97f-4825-87cf-d45b82b6f352', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.372Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Notifying assignor about the new Assignment(partitions=[created-blueprint-0])
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.373Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-database-restoration-service-group-2-d58b0128-e68b-4a1f-8ec3-9ccce03f3df7', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.373Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Notifying assignor about the new Assignment(partitions=[created-worksheet-0])
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.375Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Adding newly assigned partitions: created-blueprint-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.375Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Adding newly assigned partitions: created-worksheet-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.383Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Found no committed offset for partition created-worksheet-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.387Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Found no committed offset for partition created-worksheet-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.398Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Found no committed offset for partition created-blueprint-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.405Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-database-restoration-service-group-3-75e5a3c2-b12b-484b-86e9-128561f0faba', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.405Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Notifying assignor about the new Assignment(partitions=[metadata-failure-0])
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.406Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Adding newly assigned partitions: metadata-failure-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.408Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Found no committed offset for partition created-blueprint-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.411Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Found no committed offset for partition metadata-failure-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.413Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Found no committed offset for partition metadata-failure-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.425Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Resetting offset for partition created-blueprint-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.426Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Resetting offset for partition metadata-failure-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.429Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Resetting offset for partition created-worksheet-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1706472590434 with initial instances count: 0
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.440Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : database-restoration-service-group: partitions assigned: [metadata-failure-0]
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.441Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : database-restoration-service-group: partitions assigned: [created-worksheet-0]
simulation_2-database-restoration-service-1  | 2024-01-28T20:09:50.445Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : database-restoration-service-group: partitions assigned: [created-blueprint-0]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.s.c.n.e.s.EurekaServiceRegistry - Registering application BLUEPRINT-SERVICE with eureka with status UP
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1706472590475, current=UP, previous=STARTING]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [DiscoveryClient-InstanceInfoReplicator-0] c.netflix.discovery.DiscoveryClient - DiscoveryClient_BLUEPRINT-SERVICE/fd044ef25269:blueprint-service:8100: registering service...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8100"]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [DiscoveryClient-InstanceInfoReplicator-0] c.netflix.discovery.DiscoveryClient - DiscoveryClient_BLUEPRINT-SERVICE/fd044ef25269:blueprint-service:8100 - registration status: 204
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8100 (http) with context path ''
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 8100
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
simulation_2-blueprint-service-1  | 	allow.auto.create.topics = true
simulation_2-blueprint-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-blueprint-service-1  | 	auto.include.jmx.reporter = true
simulation_2-blueprint-service-1  | 	auto.offset.reset = latest
simulation_2-blueprint-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-blueprint-service-1  | 	check.crcs = true
simulation_2-blueprint-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-blueprint-service-1  | 	client.id = consumer-blueprint-service-group-1
simulation_2-blueprint-service-1  | 	client.rack = 
simulation_2-blueprint-service-1  | 	connections.max.idle.ms = 540000
simulation_2-blueprint-service-1  | 	default.api.timeout.ms = 60000
simulation_2-blueprint-service-1  | 	enable.auto.commit = false
simulation_2-blueprint-service-1  | 	exclude.internal.topics = true
simulation_2-blueprint-service-1  | 	fetch.max.bytes = 52428800
simulation_2-blueprint-service-1  | 	fetch.max.wait.ms = 500
simulation_2-blueprint-service-1  | 	fetch.min.bytes = 1
simulation_2-blueprint-service-1  | 	group.id = blueprint-service-group
simulation_2-blueprint-service-1  | 	group.instance.id = null
simulation_2-blueprint-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-blueprint-service-1  | 	interceptor.classes = []
simulation_2-blueprint-service-1  | 	internal.leave.group.on.close = true
simulation_2-blueprint-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-blueprint-service-1  | 	isolation.level = read_uncommitted
simulation_2-blueprint-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-blueprint-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-blueprint-service-1  | 	max.poll.interval.ms = 90000
simulation_2-blueprint-service-1  | 	max.poll.records = 500
simulation_2-blueprint-service-1  | 	metadata.max.age.ms = 300000
simulation_2-blueprint-service-1  | 	metric.reporters = []
simulation_2-blueprint-service-1  | 	metrics.num.samples = 2
simulation_2-blueprint-service-1  | 	metrics.recording.level = INFO
simulation_2-blueprint-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-blueprint-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-blueprint-service-1  | 	receive.buffer.bytes = 65536
simulation_2-blueprint-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-blueprint-service-1  | 	reconnect.backoff.ms = 50
simulation_2-blueprint-service-1  | 	request.timeout.ms = 30000
simulation_2-blueprint-service-1  | 	retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.jaas.config = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-blueprint-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-blueprint-service-1  | 	sasl.kerberos.service.name = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.login.class = null
simulation_2-blueprint-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-blueprint-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-blueprint-service-1  | 	security.protocol = PLAINTEXT
simulation_2-blueprint-service-1  | 	security.providers = null
simulation_2-blueprint-service-1  | 	send.buffer.bytes = 131072
simulation_2-blueprint-service-1  | 	session.timeout.ms = 45000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-blueprint-service-1  | 	ssl.cipher.suites = null
simulation_2-blueprint-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-blueprint-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-blueprint-service-1  | 	ssl.engine.factory.class = null
simulation_2-blueprint-service-1  | 	ssl.key.password = null
simulation_2-blueprint-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-blueprint-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-blueprint-service-1  | 	ssl.keystore.key = null
simulation_2-blueprint-service-1  | 	ssl.keystore.location = null
simulation_2-blueprint-service-1  | 	ssl.keystore.password = null
simulation_2-blueprint-service-1  | 	ssl.keystore.type = JKS
simulation_2-blueprint-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-blueprint-service-1  | 	ssl.provider = null
simulation_2-blueprint-service-1  | 	ssl.secure.random.implementation = null
simulation_2-blueprint-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-blueprint-service-1  | 	ssl.truststore.certificates = null
simulation_2-blueprint-service-1  | 	ssl.truststore.location = null
simulation_2-blueprint-service-1  | 	ssl.truststore.password = null
simulation_2-blueprint-service-1  | 	ssl.truststore.type = JKS
simulation_2-blueprint-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-blueprint-service-1  | 
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 60e845626d8a465a
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706472590919
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.s.k.c.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Subscribed to topic(s): metadata-success
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
simulation_2-blueprint-service-1  | 	allow.auto.create.topics = true
simulation_2-blueprint-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-blueprint-service-1  | 	auto.include.jmx.reporter = true
simulation_2-blueprint-service-1  | 	auto.offset.reset = latest
simulation_2-blueprint-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-blueprint-service-1  | 	check.crcs = true
simulation_2-blueprint-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-blueprint-service-1  | 	client.id = consumer-blueprint-service-group-2
simulation_2-blueprint-service-1  | 	client.rack = 
simulation_2-blueprint-service-1  | 	connections.max.idle.ms = 540000
simulation_2-blueprint-service-1  | 	default.api.timeout.ms = 60000
simulation_2-blueprint-service-1  | 	enable.auto.commit = false
simulation_2-blueprint-service-1  | 	exclude.internal.topics = true
simulation_2-blueprint-service-1  | 	fetch.max.bytes = 52428800
simulation_2-blueprint-service-1  | 	fetch.max.wait.ms = 500
simulation_2-blueprint-service-1  | 	fetch.min.bytes = 1
simulation_2-blueprint-service-1  | 	group.id = blueprint-service-group
simulation_2-blueprint-service-1  | 	group.instance.id = null
simulation_2-blueprint-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-blueprint-service-1  | 	interceptor.classes = []
simulation_2-blueprint-service-1  | 	internal.leave.group.on.close = true
simulation_2-blueprint-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-blueprint-service-1  | 	isolation.level = read_uncommitted
simulation_2-blueprint-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-blueprint-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-blueprint-service-1  | 	max.poll.interval.ms = 90000
simulation_2-blueprint-service-1  | 	max.poll.records = 500
simulation_2-blueprint-service-1  | 	metadata.max.age.ms = 300000
simulation_2-blueprint-service-1  | 	metric.reporters = []
simulation_2-blueprint-service-1  | 	metrics.num.samples = 2
simulation_2-blueprint-service-1  | 	metrics.recording.level = INFO
simulation_2-blueprint-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-blueprint-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-blueprint-service-1  | 	receive.buffer.bytes = 65536
simulation_2-blueprint-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-blueprint-service-1  | 	reconnect.backoff.ms = 50
simulation_2-blueprint-service-1  | 	request.timeout.ms = 30000
simulation_2-blueprint-service-1  | 	retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.jaas.config = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-blueprint-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-blueprint-service-1  | 	sasl.kerberos.service.name = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.login.class = null
simulation_2-blueprint-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-blueprint-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-blueprint-service-1  | 	security.protocol = PLAINTEXT
simulation_2-blueprint-service-1  | 	security.providers = null
simulation_2-blueprint-service-1  | 	send.buffer.bytes = 131072
simulation_2-blueprint-service-1  | 	session.timeout.ms = 45000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-blueprint-service-1  | 	ssl.cipher.suites = null
simulation_2-blueprint-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-blueprint-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-blueprint-service-1  | 	ssl.engine.factory.class = null
simulation_2-blueprint-service-1  | 	ssl.key.password = null
simulation_2-blueprint-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-blueprint-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-blueprint-service-1  | 	ssl.keystore.key = null
simulation_2-blueprint-service-1  | 	ssl.keystore.location = null
simulation_2-blueprint-service-1  | 	ssl.keystore.password = null
simulation_2-blueprint-service-1  | 	ssl.keystore.type = JKS
simulation_2-blueprint-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-blueprint-service-1  | 	ssl.provider = null
simulation_2-blueprint-service-1  | 	ssl.secure.random.implementation = null
simulation_2-blueprint-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-blueprint-service-1  | 	ssl.truststore.certificates = null
simulation_2-blueprint-service-1  | 	ssl.truststore.location = null
simulation_2-blueprint-service-1  | 	ssl.truststore.password = null
simulation_2-blueprint-service-1  | 	ssl.truststore.type = JKS
simulation_2-blueprint-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-blueprint-service-1  | 
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 60e845626d8a465a
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706472590933
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.s.k.c.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Subscribed to topic(s): metadata-failure
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
simulation_2-blueprint-service-1  | 	allow.auto.create.topics = true
simulation_2-blueprint-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-blueprint-service-1  | 	auto.include.jmx.reporter = true
simulation_2-blueprint-service-1  | 	auto.offset.reset = latest
simulation_2-blueprint-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-blueprint-service-1  | 	check.crcs = true
simulation_2-blueprint-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-blueprint-service-1  | 	client.id = consumer-blueprint-service-group-3
simulation_2-blueprint-service-1  | 	client.rack = 
simulation_2-blueprint-service-1  | 	connections.max.idle.ms = 540000
simulation_2-blueprint-service-1  | 	default.api.timeout.ms = 60000
simulation_2-blueprint-service-1  | 	enable.auto.commit = false
simulation_2-blueprint-service-1  | 	exclude.internal.topics = true
simulation_2-blueprint-service-1  | 	fetch.max.bytes = 52428800
simulation_2-blueprint-service-1  | 	fetch.max.wait.ms = 500
simulation_2-blueprint-service-1  | 	fetch.min.bytes = 1
simulation_2-blueprint-service-1  | 	group.id = blueprint-service-group
simulation_2-blueprint-service-1  | 	group.instance.id = null
simulation_2-blueprint-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-blueprint-service-1  | 	interceptor.classes = []
simulation_2-blueprint-service-1  | 	internal.leave.group.on.close = true
simulation_2-blueprint-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-blueprint-service-1  | 	isolation.level = read_uncommitted
simulation_2-blueprint-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-blueprint-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-blueprint-service-1  | 	max.poll.interval.ms = 90000
simulation_2-blueprint-service-1  | 	max.poll.records = 500
simulation_2-blueprint-service-1  | 	metadata.max.age.ms = 300000
simulation_2-blueprint-service-1  | 	metric.reporters = []
simulation_2-blueprint-service-1  | 	metrics.num.samples = 2
simulation_2-blueprint-service-1  | 	metrics.recording.level = INFO
simulation_2-blueprint-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-blueprint-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-blueprint-service-1  | 	receive.buffer.bytes = 65536
simulation_2-blueprint-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-blueprint-service-1  | 	reconnect.backoff.ms = 50
simulation_2-blueprint-service-1  | 	request.timeout.ms = 30000
simulation_2-blueprint-service-1  | 	retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.jaas.config = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-blueprint-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-blueprint-service-1  | 	sasl.kerberos.service.name = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.login.class = null
simulation_2-blueprint-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-blueprint-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-blueprint-service-1  | 	security.protocol = PLAINTEXT
simulation_2-blueprint-service-1  | 	security.providers = null
simulation_2-blueprint-service-1  | 	send.buffer.bytes = 131072
simulation_2-blueprint-service-1  | 	session.timeout.ms = 45000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-blueprint-service-1  | 	ssl.cipher.suites = null
simulation_2-blueprint-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-blueprint-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-blueprint-service-1  | 	ssl.engine.factory.class = null
simulation_2-blueprint-service-1  | 	ssl.key.password = null
simulation_2-blueprint-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-blueprint-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-blueprint-service-1  | 	ssl.keystore.key = null
simulation_2-blueprint-service-1  | 	ssl.keystore.location = null
simulation_2-blueprint-service-1  | 	ssl.keystore.password = null
simulation_2-blueprint-service-1  | 	ssl.keystore.type = JKS
simulation_2-blueprint-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-blueprint-service-1  | 	ssl.provider = null
simulation_2-blueprint-service-1  | 	ssl.secure.random.implementation = null
simulation_2-blueprint-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-blueprint-service-1  | 	ssl.truststore.certificates = null
simulation_2-blueprint-service-1  | 	ssl.truststore.location = null
simulation_2-blueprint-service-1  | 	ssl.truststore.password = null
simulation_2-blueprint-service-1  | 	ssl.truststore.type = JKS
simulation_2-blueprint-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-blueprint-service-1  | 
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 60e845626d8a465a
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706472590955
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.s.k.c.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Subscribed to topic(s): restore-success
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
simulation_2-blueprint-service-1  | 	allow.auto.create.topics = true
simulation_2-blueprint-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-blueprint-service-1  | 	auto.include.jmx.reporter = true
simulation_2-blueprint-service-1  | 	auto.offset.reset = latest
simulation_2-blueprint-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-blueprint-service-1  | 	check.crcs = true
simulation_2-blueprint-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-blueprint-service-1  | 	client.id = consumer-blueprint-service-group-4
simulation_2-blueprint-service-1  | 	client.rack = 
simulation_2-blueprint-service-1  | 	connections.max.idle.ms = 540000
simulation_2-blueprint-service-1  | 	default.api.timeout.ms = 60000
simulation_2-blueprint-service-1  | 	enable.auto.commit = false
simulation_2-blueprint-service-1  | 	exclude.internal.topics = true
simulation_2-blueprint-service-1  | 	fetch.max.bytes = 52428800
simulation_2-blueprint-service-1  | 	fetch.max.wait.ms = 500
simulation_2-blueprint-service-1  | 	fetch.min.bytes = 1
simulation_2-blueprint-service-1  | 	group.id = blueprint-service-group
simulation_2-blueprint-service-1  | 	group.instance.id = null
simulation_2-blueprint-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-blueprint-service-1  | 	interceptor.classes = []
simulation_2-blueprint-service-1  | 	internal.leave.group.on.close = true
simulation_2-blueprint-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-blueprint-service-1  | 	isolation.level = read_uncommitted
simulation_2-blueprint-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-blueprint-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-blueprint-service-1  | 	max.poll.interval.ms = 90000
simulation_2-blueprint-service-1  | 	max.poll.records = 500
simulation_2-blueprint-service-1  | 	metadata.max.age.ms = 300000
simulation_2-blueprint-service-1  | 	metric.reporters = []
simulation_2-blueprint-service-1  | 	metrics.num.samples = 2
simulation_2-blueprint-service-1  | 	metrics.recording.level = INFO
simulation_2-blueprint-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-blueprint-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-blueprint-service-1  | 	receive.buffer.bytes = 65536
simulation_2-blueprint-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-blueprint-service-1  | 	reconnect.backoff.ms = 50
simulation_2-blueprint-service-1  | 	request.timeout.ms = 30000
simulation_2-blueprint-service-1  | 	retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.jaas.config = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-blueprint-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-blueprint-service-1  | 	sasl.kerberos.service.name = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.login.class = null
simulation_2-blueprint-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-blueprint-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-blueprint-service-1  | 	security.protocol = PLAINTEXT
simulation_2-blueprint-service-1  | 	security.providers = null
simulation_2-blueprint-service-1  | 	send.buffer.bytes = 131072
simulation_2-blueprint-service-1  | 	session.timeout.ms = 45000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-blueprint-service-1  | 	ssl.cipher.suites = null
simulation_2-blueprint-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-blueprint-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-blueprint-service-1  | 	ssl.engine.factory.class = null
simulation_2-blueprint-service-1  | 	ssl.key.password = null
simulation_2-blueprint-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-blueprint-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-blueprint-service-1  | 	ssl.keystore.key = null
simulation_2-blueprint-service-1  | 	ssl.keystore.location = null
simulation_2-blueprint-service-1  | 	ssl.keystore.password = null
simulation_2-blueprint-service-1  | 	ssl.keystore.type = JKS
simulation_2-blueprint-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-blueprint-service-1  | 	ssl.provider = null
simulation_2-blueprint-service-1  | 	ssl.secure.random.implementation = null
simulation_2-blueprint-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-blueprint-service-1  | 	ssl.truststore.certificates = null
simulation_2-blueprint-service-1  | 	ssl.truststore.location = null
simulation_2-blueprint-service-1  | 	ssl.truststore.password = null
simulation_2-blueprint-service-1  | 	ssl.truststore.type = JKS
simulation_2-blueprint-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-blueprint-service-1  | 
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 60e845626d8a465a
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706472590961
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [main] o.s.k.c.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Subscribed to topic(s): restore-failure
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Cluster ID: AuB6J3ZDSAyfYI6omDK5Jg
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Cluster ID: AuB6J3ZDSAyfYI6omDK5Jg
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:50 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Request joining group due to: need to re-join with the given member-id: consumer-blueprint-service-group-3-90cb8a32-1593-4d4d-8b35-2c71cf0dc170
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-blueprint-service-group-3-90cb8a32-1593-4d4d-8b35-2c71cf0dc170', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Cluster ID: AuB6J3ZDSAyfYI6omDK5Jg
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Request joining group due to: need to re-join with the given member-id: consumer-blueprint-service-group-2-af1a8aa2-9612-4bb7-ba53-d991095ea698
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Error while fetching metadata with correlation id 2 : {metadata-success=LEADER_NOT_AVAILABLE}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Cluster ID: AuB6J3ZDSAyfYI6omDK5Jg
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Finished assignment for group at generation 1: {consumer-blueprint-service-group-3-90cb8a32-1593-4d4d-8b35-2c71cf0dc170=Assignment(partitions=[restore-success-0])}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Request joining group due to: need to re-join with the given member-id: consumer-blueprint-service-group-4-2efa0e96-7df2-4093-9b68-a7eb3aa6557e
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Request joining group due to: need to re-join with the given member-id: consumer-blueprint-service-group-1-0b2110e3-7e49-4555-acd6-c2e9ff1b1b42
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=1, memberId='consumer-blueprint-service-group-3-90cb8a32-1593-4d4d-8b35-2c71cf0dc170', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-blueprint-service-group-1-0b2110e3-7e49-4555-acd6-c2e9ff1b1b42', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-blueprint-service-group-2-af1a8aa2-9612-4bb7-ba53-d991095ea698', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-blueprint-service-group-3-90cb8a32-1593-4d4d-8b35-2c71cf0dc170', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Finished assignment for group at generation 2: {consumer-blueprint-service-group-3-90cb8a32-1593-4d4d-8b35-2c71cf0dc170=Assignment(partitions=[restore-success-0]), consumer-blueprint-service-group-4-2efa0e96-7df2-4093-9b68-a7eb3aa6557e=Assignment(partitions=[restore-failure-0]), consumer-blueprint-service-group-1-0b2110e3-7e49-4555-acd6-c2e9ff1b1b42=Assignment(partitions=[metadata-success-0]), consumer-blueprint-service-group-2-af1a8aa2-9612-4bb7-ba53-d991095ea698=Assignment(partitions=[metadata-failure-0])}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-blueprint-service-group-4-2efa0e96-7df2-4093-9b68-a7eb3aa6557e', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-blueprint-service-group-1-0b2110e3-7e49-4555-acd6-c2e9ff1b1b42', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-blueprint-service-group-2-af1a8aa2-9612-4bb7-ba53-d991095ea698', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Notifying assignor about the new Assignment(partitions=[metadata-failure-0])
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Notifying assignor about the new Assignment(partitions=[metadata-success-0])
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-blueprint-service-group-3-90cb8a32-1593-4d4d-8b35-2c71cf0dc170', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Notifying assignor about the new Assignment(partitions=[restore-success-0])
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-blueprint-service-group-4-2efa0e96-7df2-4093-9b68-a7eb3aa6557e', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Notifying assignor about the new Assignment(partitions=[restore-failure-0])
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Adding newly assigned partitions: metadata-failure-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Adding newly assigned partitions: restore-success-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Adding newly assigned partitions: restore-failure-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Adding newly assigned partitions: metadata-success-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Found no committed offset for partition restore-success-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Found no committed offset for partition metadata-success-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Found no committed offset for partition restore-success-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Found no committed offset for partition metadata-success-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Found no committed offset for partition restore-failure-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Found no committed offset for partition restore-failure-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Resetting offset for partition restore-success-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Resetting offset for partition restore-failure-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Found no committed offset for partition metadata-failure-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Found no committed offset for partition metadata-failure-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - blueprint-service-group: partitions assigned: [restore-success-0]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Resetting offset for partition metadata-failure-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - blueprint-service-group: partitions assigned: [restore-failure-0]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - blueprint-service-group: partitions assigned: [metadata-failure-0]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [main] c.w.a.b.BlueprintServiceApplication - Started BlueprintServiceApplication in 45.632 seconds (process running for 49.652)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Resetting offset for partition metadata-success-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:51 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - blueprint-service-group: partitions assigned: [metadata-success-0]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:52 [http-nio-8100-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:52 [http-nio-8100-exec-1] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:09:52 [http-nio-8100-exec-1] o.s.web.servlet.DispatcherServlet - Completed initialization in 2 ms
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:40:00.030096591
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:15.911Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:15.917Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:15.917Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:15.917Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Application is null : false
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:15.918Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:15.918Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:15.918Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:16.011Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : The response status is 200
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:18.799Z  INFO 1 --- [database-restoration-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:18.801Z  INFO 1 --- [database-restoration-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:18.802Z  INFO 1 --- [database-restoration-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:18.802Z  INFO 1 --- [database-restoration-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Application is null : false
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:18.802Z  INFO 1 --- [database-restoration-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:18.802Z  INFO 1 --- [database-restoration-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:18.802Z  INFO 1 --- [database-restoration-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:18.900Z  INFO 1 --- [database-restoration-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : The response status is 200
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:20 [DiscoveryClient-CacheRefreshExecutor-0] c.netflix.discovery.DiscoveryClient - Disable delta property : false
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:20 [DiscoveryClient-CacheRefreshExecutor-0] c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:20 [DiscoveryClient-CacheRefreshExecutor-0] c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:20 [DiscoveryClient-CacheRefreshExecutor-0] c.netflix.discovery.DiscoveryClient - Application is null : false
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:20 [DiscoveryClient-CacheRefreshExecutor-0] c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:20 [DiscoveryClient-CacheRefreshExecutor-0] c.netflix.discovery.DiscoveryClient - Application version is -1: false
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:20 [DiscoveryClient-CacheRefreshExecutor-0] c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:20 [DiscoveryClient-CacheRefreshExecutor-0] c.netflix.discovery.DiscoveryClient - The response status is 200
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:40:30.001433132
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:34 [http-nio-8100-exec-10] c.w.a.logging.LoggingFilter - -----> Request: POST /api/v1/importing/start, headers=[user-agent:"curl/8.1.2", accept:"*/*", content-length:"3584", forwarded:"proto=http;host="localhost:8080";for="192.168.128.1:38568"", x-forwarded-for:"192.168.128.1", x-forwarded-proto:"http", x-forwarded-port:"8080", x-forwarded-host:"localhost:8080", host:"fd044ef25269:8100", Content-Type:"multipart/form-data;boundary=------------------------23d88ac49a36e5ad;charset=UTF-8"]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:35 [http-nio-8100-exec-10] c.w.a.logging.LoggingFilter - <----- Response (HTTP 202 Accepted): 26b0a4d6-1899-4165-840f-2b98dddca0ab
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:35 [ForkJoinPool.commonPool-worker-1] c.w.a.b.a.o.p.d.DumpRepositoryS3Adapter - Uploading Dump to S3... Blueprint : Blueprint(blueprintId=26b0a4d6-1899-4165-840f-2b98dddca0ab, dumpFile=org.springframework.web.multipart.support.StandardMultipartHttpServletRequest$StandardMultipartFile@8bc145d, blueprintSagaStatus=INITIALISED, restoreMode=SCRIPT, databaseType=POSTGRESQL, title=Employees, dumpStoreSuccess=false, description=This is just a sample dump of employees database made in a SCRIPT mode., createdDate=2024-01-28T20:10:35.081586968, originalDumpName=employeesdb_script.sql)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:35 [http-nio-8100-exec-1] c.w.a.logging.LoggingFilter - -----> Request: GET /api/v1/blueprints?blueprint_id=26b0a4d6-1899-4165-840f-2b98dddca0ab, headers=[user-agent:"curl/8.1.2", accept:"*/*", forwarded:"proto=http;host="localhost:8080";for="192.168.128.1:38578"", x-forwarded-for:"192.168.128.1", x-forwarded-proto:"http", x-forwarded-port:"8080", x-forwarded-host:"localhost:8080", host:"fd044ef25269:8100", content-length:"0"]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:35 [http-nio-8100-exec-1] c.w.a.logging.LoggingFilter - <----- Response (HTTP 200 OK):
simulation_2-blueprint-service-1  | {
simulation_2-blueprint-service-1  |   "blueprintId" : "26b0a4d6-1899-4165-840f-2b98dddca0ab",
simulation_2-blueprint-service-1  |   "blueprintSagaStatus" : "INITIALISED",
simulation_2-blueprint-service-1  |   "restoreMode" : "SCRIPT",
simulation_2-blueprint-service-1  |   "databaseType" : "POSTGRESQL",
simulation_2-blueprint-service-1  |   "title" : "Employees",
simulation_2-blueprint-service-1  |   "dumpStoreSuccess" : false,
simulation_2-blueprint-service-1  |   "description" : "This is just a sample dump of employees database made in a SCRIPT mode.",
simulation_2-blueprint-service-1  |   "createdDate" : "2024-01-28T20:10:35.081",
simulation_2-blueprint-service-1  |   "originalDumpName" : "employeesdb_script.sql"
simulation_2-blueprint-service-1  | }
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:10:35 [ForkJoinPool.commonPool-worker-1] s.a.a.h.a.internal.utils.ApacheUtils - NoSuchMethodException was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:35 [ForkJoinPool.commonPool-worker-1] c.w.a.s.impl.LoggingKafkaTemplate - Publishing to Kafka | Topic: created-blueprint | Value: BlueprintCreatedEvent(blueprintId=26b0a4d6-1899-4165-840f-2b98dddca0ab, restoreMode=SCRIPT)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:35 [ForkJoinPool.commonPool-worker-1] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
simulation_2-blueprint-service-1  | 	acks = -1
simulation_2-blueprint-service-1  | 	auto.include.jmx.reporter = true
simulation_2-blueprint-service-1  | 	batch.size = 16384
simulation_2-blueprint-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-blueprint-service-1  | 	buffer.memory = 33554432
simulation_2-blueprint-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-blueprint-service-1  | 	client.id = producer-1
simulation_2-blueprint-service-1  | 	compression.type = none
simulation_2-blueprint-service-1  | 	connections.max.idle.ms = 540000
simulation_2-blueprint-service-1  | 	delivery.timeout.ms = 120000
simulation_2-blueprint-service-1  | 	enable.idempotence = true
simulation_2-blueprint-service-1  | 	interceptor.classes = []
simulation_2-blueprint-service-1  | 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
simulation_2-blueprint-service-1  | 	linger.ms = 0
simulation_2-blueprint-service-1  | 	max.block.ms = 60000
simulation_2-blueprint-service-1  | 	max.in.flight.requests.per.connection = 5
simulation_2-blueprint-service-1  | 	max.request.size = 1048576
simulation_2-blueprint-service-1  | 	metadata.max.age.ms = 300000
simulation_2-blueprint-service-1  | 	metadata.max.idle.ms = 300000
simulation_2-blueprint-service-1  | 	metric.reporters = []
simulation_2-blueprint-service-1  | 	metrics.num.samples = 2
simulation_2-blueprint-service-1  | 	metrics.recording.level = INFO
simulation_2-blueprint-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-blueprint-service-1  | 	partitioner.adaptive.partitioning.enable = true
simulation_2-blueprint-service-1  | 	partitioner.availability.timeout.ms = 0
simulation_2-blueprint-service-1  | 	partitioner.class = null
simulation_2-blueprint-service-1  | 	partitioner.ignore.keys = false
simulation_2-blueprint-service-1  | 	receive.buffer.bytes = 32768
simulation_2-blueprint-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-blueprint-service-1  | 	reconnect.backoff.ms = 50
simulation_2-blueprint-service-1  | 	request.timeout.ms = 30000
simulation_2-blueprint-service-1  | 	retries = 2147483647
simulation_2-blueprint-service-1  | 	retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.jaas.config = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-blueprint-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-blueprint-service-1  | 	sasl.kerberos.service.name = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.login.class = null
simulation_2-blueprint-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-blueprint-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-blueprint-service-1  | 	security.protocol = PLAINTEXT
simulation_2-blueprint-service-1  | 	security.providers = null
simulation_2-blueprint-service-1  | 	send.buffer.bytes = 131072
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-blueprint-service-1  | 	ssl.cipher.suites = null
simulation_2-blueprint-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-blueprint-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-blueprint-service-1  | 	ssl.engine.factory.class = null
simulation_2-blueprint-service-1  | 	ssl.key.password = null
simulation_2-blueprint-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-blueprint-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-blueprint-service-1  | 	ssl.keystore.key = null
simulation_2-blueprint-service-1  | 	ssl.keystore.location = null
simulation_2-blueprint-service-1  | 	ssl.keystore.password = null
simulation_2-blueprint-service-1  | 	ssl.keystore.type = JKS
simulation_2-blueprint-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-blueprint-service-1  | 	ssl.provider = null
simulation_2-blueprint-service-1  | 	ssl.secure.random.implementation = null
simulation_2-blueprint-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-blueprint-service-1  | 	ssl.truststore.certificates = null
simulation_2-blueprint-service-1  | 	ssl.truststore.location = null
simulation_2-blueprint-service-1  | 	ssl.truststore.password = null
simulation_2-blueprint-service-1  | 	ssl.truststore.type = JKS
simulation_2-blueprint-service-1  | 	transaction.timeout.ms = 60000
simulation_2-blueprint-service-1  | 	transactional.id = null
simulation_2-blueprint-service-1  | 	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
simulation_2-blueprint-service-1  | 
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:35 [ForkJoinPool.commonPool-worker-1] o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:35 [ForkJoinPool.commonPool-worker-1] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:35 [ForkJoinPool.commonPool-worker-1] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 60e845626d8a465a
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:35 [ForkJoinPool.commonPool-worker-1] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706472635944
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:35 [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: AuB6J3ZDSAyfYI6omDK5Jg
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:36 [kafka-producer-network-thread | producer-1] o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId set to 0 with epoch 0
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.131Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] .a.d.a.i.m.BlueprintCreatedKafkaListener : Received BlueprintCreatedEvent(blueprintId=26b0a4d6-1899-4165-840f-2b98dddca0ab, restoreMode=SCRIPT)
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.133Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] .a.d.a.o.d.p.PostgresDropDatabaseAdapter : Dropping database 26b0a4d6-1899-4165-840f-2b98dddca0ab
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.279Z  INFO 1 --- [database-restoration-service] [       Thread-3] .a.d.a.o.d.p.PostgresDropDatabaseAdapter : NOTICE:  database "26b0a4d6-1899-4165-840f-2b98dddca0ab" does not exist, skipping
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.284Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] .a.d.a.o.d.p.PostgresDropDatabaseAdapter : Successfully dropped database 26b0a4d6-1899-4165-840f-2b98dddca0ab using command [dropdb, -h, postgres, -p, 5432, -U, postgres, --no-password, --if-exists, 26b0a4d6-1899-4165-840f-2b98dddca0ab]
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.285Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] .d.a.o.d.p.PostgresCreateDatabaseAdapter : Creating database 26b0a4d6-1899-4165-840f-2b98dddca0ab
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:36 [http-nio-8100-exec-2] c.w.a.logging.LoggingFilter - -----> Request: GET /api/v1/blueprints?blueprint_id=26b0a4d6-1899-4165-840f-2b98dddca0ab, headers=[user-agent:"curl/8.1.2", accept:"*/*", forwarded:"proto=http;host="localhost:8080";for="192.168.128.1:38590"", x-forwarded-for:"192.168.128.1", x-forwarded-proto:"http", x-forwarded-port:"8080", x-forwarded-host:"localhost:8080", host:"fd044ef25269:8100", content-length:"0"]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:36 [http-nio-8100-exec-2] c.w.a.logging.LoggingFilter - <----- Response (HTTP 200 OK):
simulation_2-blueprint-service-1  | {
simulation_2-blueprint-service-1  |   "blueprintId" : "26b0a4d6-1899-4165-840f-2b98dddca0ab",
simulation_2-blueprint-service-1  |   "blueprintSagaStatus" : "DUMP_STORE_SUCCESS",
simulation_2-blueprint-service-1  |   "restoreMode" : "SCRIPT",
simulation_2-blueprint-service-1  |   "databaseType" : "POSTGRESQL",
simulation_2-blueprint-service-1  |   "title" : "Employees",
simulation_2-blueprint-service-1  |   "dumpStoreSuccess" : true,
simulation_2-blueprint-service-1  |   "description" : "This is just a sample dump of employees database made in a SCRIPT mode.",
simulation_2-blueprint-service-1  |   "createdDate" : "2024-01-28T20:10:35.081",
simulation_2-blueprint-service-1  |   "originalDumpName" : "employeesdb_script.sql"
simulation_2-blueprint-service-1  | }
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.387Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] .d.a.o.d.p.PostgresCreateDatabaseAdapter : Successfully created database 26b0a4d6-1899-4165-840f-2b98dddca0ab using command [createdb, -h, postgres, -p, 5432, -U, postgres, --no-password, -T, template0, 26b0a4d6-1899-4165-840f-2b98dddca0ab]
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.387Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] d.a.o.d.p.PostgresRestoreDatabaseAdapter : Restoring database 26b0a4d6-1899-4165-840f-2b98dddca0ab from script
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.521Z  WARN 1 --- [database-restoration-service] [ntainer#2-0-C-1] s.a.a.h.a.internal.utils.ApacheUtils     : NoSuchMethodException was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.928Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.928Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- PostgreSQL database dump
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.928Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.928Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Dumped from database version 14.7 (Homebrew)
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.928Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Dumped by pg_dump version 14.7 (Homebrew)
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.928Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET statement_timeout = 0;
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.928Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.928Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET lock_timeout = 0;
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.928Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.928Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET idle_in_transaction_session_timeout = 0;
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.929Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.929Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET client_encoding = 'UTF8';
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.929Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.929Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET standard_conforming_strings = on;
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.929Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.929Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SELECT pg_catalog.set_config('search_path', '', false);
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.930Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :  set_config 
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.930Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ------------
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.930Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :  
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.930Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : (1 row)
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.930Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET check_function_bodies = false;
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.930Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.930Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET xmloption = content;
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.930Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.930Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET client_min_messages = warning;
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.930Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.930Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET row_security = off;
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.930Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.930Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET default_tablespace = '';
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.931Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.931Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET default_table_access_method = heap;
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.931Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.931Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.931Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Name: employees; Type: TABLE; Schema: public; Owner: postgres
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.932Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.932Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : CREATE TABLE public.employees (
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.932Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     id integer NOT NULL,
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.932Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     name character varying(255),
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.932Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     surname character varying(255),
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.932Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     date_of_birth date,
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.932Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     salary numeric(10,2),
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.932Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     phone_number character varying(15),
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.932Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     job character varying(255),
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.932Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     title character varying(255)
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.932Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : );
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.934Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : CREATE TABLE
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.934Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE public.employees OWNER TO postgres;
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.935Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.935Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.935Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Name: employees_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.935Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.935Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : CREATE SEQUENCE public.employees_id_seq
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.935Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     AS integer
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.935Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     START WITH 1
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.935Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     INCREMENT BY 1
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.935Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     NO MINVALUE
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.935Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     NO MAXVALUE
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.935Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     CACHE 1;
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.936Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : CREATE SEQUENCE
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.936Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE public.employees_id_seq OWNER TO postgres;
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.936Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.936Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.936Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Name: employees_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.936Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.936Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER SEQUENCE public.employees_id_seq OWNED BY public.employees.id;
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.936Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER SEQUENCE
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.936Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.936Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Name: employees id; Type: DEFAULT; Schema: public; Owner: postgres
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.936Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.937Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE ONLY public.employees ALTER COLUMN id SET DEFAULT nextval('public.employees_id_seq'::regclass);
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.937Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.937Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.937Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Data for Name: employees; Type: TABLE DATA; Schema: public; Owner: postgres
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.937Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.937Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : COPY public.employees (id, name, surname, date_of_birth, salary, phone_number, job, title) FROM stdin;
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.937Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : COPY 10
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.937Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.937Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Name: employees_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.938Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.938Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SELECT pg_catalog.setval('public.employees_id_seq', 10, true);
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.938Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :  setval 
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.938Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --------
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.938Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :      10
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.938Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : (1 row)
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.938Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.938Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Name: employees employees_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.938Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.938Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE ONLY public.employees
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.938Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     ADD CONSTRAINT employees_pkey PRIMARY KEY (id);
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.939Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.940Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.940Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- PostgreSQL database dump complete
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.940Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:36.942Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] d.a.o.d.p.PostgresRestoreDatabaseAdapter : Successfully restored database using command [psql, -h, postgres, -p, 5432, -U, postgres, -d, 26b0a4d6-1899-4165-840f-2b98dddca0ab, -v, ON_ERROR_STOP=1, --echo-all]
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:37.084Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] c.w.a.s.impl.LoggingKafkaTemplate        : Publishing to Kafka | Topic: restore-success | Value: DatabaseRestoredSuccessEvent(blueprintId=26b0a4d6-1899-4165-840f-2b98dddca0ab)
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:37.089Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
simulation_2-database-restoration-service-1  | 	acks = -1
simulation_2-database-restoration-service-1  | 	auto.include.jmx.reporter = true
simulation_2-database-restoration-service-1  | 	batch.size = 16384
simulation_2-database-restoration-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-database-restoration-service-1  | 	buffer.memory = 33554432
simulation_2-database-restoration-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-database-restoration-service-1  | 	client.id = producer-1
simulation_2-database-restoration-service-1  | 	compression.type = none
simulation_2-database-restoration-service-1  | 	connections.max.idle.ms = 540000
simulation_2-database-restoration-service-1  | 	delivery.timeout.ms = 120000
simulation_2-database-restoration-service-1  | 	enable.idempotence = true
simulation_2-database-restoration-service-1  | 	interceptor.classes = []
simulation_2-database-restoration-service-1  | 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
simulation_2-database-restoration-service-1  | 	linger.ms = 0
simulation_2-database-restoration-service-1  | 	max.block.ms = 60000
simulation_2-database-restoration-service-1  | 	max.in.flight.requests.per.connection = 5
simulation_2-database-restoration-service-1  | 	max.request.size = 1048576
simulation_2-database-restoration-service-1  | 	metadata.max.age.ms = 300000
simulation_2-database-restoration-service-1  | 	metadata.max.idle.ms = 300000
simulation_2-database-restoration-service-1  | 	metric.reporters = []
simulation_2-database-restoration-service-1  | 	metrics.num.samples = 2
simulation_2-database-restoration-service-1  | 	metrics.recording.level = INFO
simulation_2-database-restoration-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-database-restoration-service-1  | 	partitioner.adaptive.partitioning.enable = true
simulation_2-database-restoration-service-1  | 	partitioner.availability.timeout.ms = 0
simulation_2-database-restoration-service-1  | 	partitioner.class = null
simulation_2-database-restoration-service-1  | 	partitioner.ignore.keys = false
simulation_2-database-restoration-service-1  | 	receive.buffer.bytes = 32768
simulation_2-database-restoration-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-database-restoration-service-1  | 	reconnect.backoff.ms = 50
simulation_2-database-restoration-service-1  | 	request.timeout.ms = 30000
simulation_2-database-restoration-service-1  | 	retries = 2147483647
simulation_2-database-restoration-service-1  | 	retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.jaas.config = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-database-restoration-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-database-restoration-service-1  | 	sasl.kerberos.service.name = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-database-restoration-service-1  | 	security.protocol = PLAINTEXT
simulation_2-database-restoration-service-1  | 	security.providers = null
simulation_2-database-restoration-service-1  | 	send.buffer.bytes = 131072
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-database-restoration-service-1  | 	ssl.cipher.suites = null
simulation_2-database-restoration-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-database-restoration-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-database-restoration-service-1  | 	ssl.engine.factory.class = null
simulation_2-database-restoration-service-1  | 	ssl.key.password = null
simulation_2-database-restoration-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-database-restoration-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.key = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.location = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.password = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.type = JKS
simulation_2-database-restoration-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-database-restoration-service-1  | 	ssl.provider = null
simulation_2-database-restoration-service-1  | 	ssl.secure.random.implementation = null
simulation_2-database-restoration-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-database-restoration-service-1  | 	ssl.truststore.certificates = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.location = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.password = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.type = JKS
simulation_2-database-restoration-service-1  | 	transaction.timeout.ms = 60000
simulation_2-database-restoration-service-1  | 	transactional.id = null
simulation_2-database-restoration-service-1  | 	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
simulation_2-database-restoration-service-1  | 
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:37.096Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:37.105Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:37.105Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:37.105Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472637105
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:37.110Z  INFO 1 --- [database-restoration-service] [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: AuB6J3ZDSAyfYI6omDK5Jg
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:37.114Z  INFO 1 --- [database-restoration-service] [ad | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 1 with epoch 0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:37 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.w.a.b.a.i.m.DatabaseRestoredKafkaListener - Received DatabaseRestoredSuccessEvent(blueprintId=26b0a4d6-1899-4165-840f-2b98dddca0ab)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:37 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.w.a.b.d.s.BlueprintSagaStatusUpdater - Updated status to RESTORE_SUCCESS of blueprint: Blueprint(blueprintId=26b0a4d6-1899-4165-840f-2b98dddca0ab, dumpFile=null, blueprintSagaStatus=RESTORE_SUCCESS, restoreMode=SCRIPT, databaseType=POSTGRESQL, title=Employees, dumpStoreSuccess=true, description=This is just a sample dump of employees database made in a SCRIPT mode., createdDate=2024-01-28T20:10:35.081, originalDumpName=employeesdb_script.sql)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:37.184Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] .a.m.a.i.m.DatabaseRestoredKafkaListener : Received DatabaseRestoredSuccessEvent(blueprintId=26b0a4d6-1899-4165-840f-2b98dddca0ab)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:37.186Z ERROR 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] c.w.a.m.d.s.m.DatabaseRestoredService    : Error during metadata extraction for DatabaseRestoredSuccessEvent(blueprintId=26b0a4d6-1899-4165-840f-2b98dddca0ab)
simulation_2-metadata-extraction-service-1  | 
simulation_2-metadata-extraction-service-1  | java.lang.RuntimeException: Simulating exception – metadata extraction operation failed
simulation_2-metadata-extraction-service-1  | 	at com.wenox.anonymization.metadata_extraction_service.domain.model.DatabaseConnection.forPostgres(DatabaseConnection.java:21) ~[!/:simulation-case-1]
simulation_2-metadata-extraction-service-1  | 	at com.wenox.anonymization.metadata_extraction_service.domain.service.messaging.DatabaseRestoredService.handle(DatabaseRestoredService.java:26) ~[!/:simulation-case-1]
simulation_2-metadata-extraction-service-1  | 	at com.wenox.anonymization.metadata_extraction_service.adapters.inbound.messaging.DatabaseRestoredKafkaListener.onRestoreSuccess(DatabaseRestoredKafkaListener.java:23) ~[!/:simulation-case-1]
simulation_2-metadata-extraction-service-1  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
simulation_2-metadata-extraction-service-1  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
simulation_2-metadata-extraction-service-1  | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
simulation_2-metadata-extraction-service-1  | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-6.1.1.jar!/:6.1.1]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-6.1.1.jar!/:6.1.1]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2857) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2835) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$56(KafkaMessageListenerContainer.java:2753) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at io.micrometer.observation.Observation.observe(Observation.java:565) ~[micrometer-observation-1.12.0.jar!/:1.12.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2751) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2490) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2132) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1487) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1451) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1322) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
simulation_2-metadata-extraction-service-1  | 	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
simulation_2-metadata-extraction-service-1  | 
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:37.191Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] c.w.a.s.impl.LoggingKafkaTemplate        : Publishing to Kafka | Topic: metadata-failure | Value: MetadataExtractedFailureEvent(blueprintId=26b0a4d6-1899-4165-840f-2b98dddca0ab, errorMessage=Simulating exception – metadata extraction operation failed, exception=java.lang.RuntimeException: Simulating exception – metadata extraction operation failed)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:37.202Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
simulation_2-metadata-extraction-service-1  | 	acks = -1
simulation_2-metadata-extraction-service-1  | 	auto.include.jmx.reporter = true
simulation_2-metadata-extraction-service-1  | 	batch.size = 16384
simulation_2-metadata-extraction-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-metadata-extraction-service-1  | 	buffer.memory = 33554432
simulation_2-metadata-extraction-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-metadata-extraction-service-1  | 	client.id = producer-1
simulation_2-metadata-extraction-service-1  | 	compression.type = none
simulation_2-metadata-extraction-service-1  | 	connections.max.idle.ms = 540000
simulation_2-metadata-extraction-service-1  | 	delivery.timeout.ms = 120000
simulation_2-metadata-extraction-service-1  | 	enable.idempotence = true
simulation_2-metadata-extraction-service-1  | 	interceptor.classes = []
simulation_2-metadata-extraction-service-1  | 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
simulation_2-metadata-extraction-service-1  | 	linger.ms = 0
simulation_2-metadata-extraction-service-1  | 	max.block.ms = 60000
simulation_2-metadata-extraction-service-1  | 	max.in.flight.requests.per.connection = 5
simulation_2-metadata-extraction-service-1  | 	max.request.size = 1048576
simulation_2-metadata-extraction-service-1  | 	metadata.max.age.ms = 300000
simulation_2-metadata-extraction-service-1  | 	metadata.max.idle.ms = 300000
simulation_2-metadata-extraction-service-1  | 	metric.reporters = []
simulation_2-metadata-extraction-service-1  | 	metrics.num.samples = 2
simulation_2-metadata-extraction-service-1  | 	metrics.recording.level = INFO
simulation_2-metadata-extraction-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-metadata-extraction-service-1  | 	partitioner.adaptive.partitioning.enable = true
simulation_2-metadata-extraction-service-1  | 	partitioner.availability.timeout.ms = 0
simulation_2-metadata-extraction-service-1  | 	partitioner.class = null
simulation_2-metadata-extraction-service-1  | 	partitioner.ignore.keys = false
simulation_2-metadata-extraction-service-1  | 	receive.buffer.bytes = 32768
simulation_2-metadata-extraction-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-metadata-extraction-service-1  | 	reconnect.backoff.ms = 50
simulation_2-metadata-extraction-service-1  | 	request.timeout.ms = 30000
simulation_2-metadata-extraction-service-1  | 	retries = 2147483647
simulation_2-metadata-extraction-service-1  | 	retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.jaas.config = null
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.service.name = null
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-metadata-extraction-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-metadata-extraction-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-metadata-extraction-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-metadata-extraction-service-1  | 	security.protocol = PLAINTEXT
simulation_2-metadata-extraction-service-1  | 	security.providers = null
simulation_2-metadata-extraction-service-1  | 	send.buffer.bytes = 131072
simulation_2-metadata-extraction-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-metadata-extraction-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-metadata-extraction-service-1  | 	ssl.cipher.suites = null
simulation_2-metadata-extraction-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-metadata-extraction-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-metadata-extraction-service-1  | 	ssl.engine.factory.class = null
simulation_2-metadata-extraction-service-1  | 	ssl.key.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.key = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.location = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.type = JKS
simulation_2-metadata-extraction-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-metadata-extraction-service-1  | 	ssl.provider = null
simulation_2-metadata-extraction-service-1  | 	ssl.secure.random.implementation = null
simulation_2-metadata-extraction-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.certificates = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.location = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.type = JKS
simulation_2-metadata-extraction-service-1  | 	transaction.timeout.ms = 60000
simulation_2-metadata-extraction-service-1  | 	transactional.id = null
simulation_2-metadata-extraction-service-1  | 	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
simulation_2-metadata-extraction-service-1  | 
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:37.210Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:37.224Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:37.224Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:37.224Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472637223
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:37.236Z  INFO 1 --- [metadata-extraction-service] [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: AuB6J3ZDSAyfYI6omDK5Jg
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:10:37.237Z  INFO 1 --- [metadata-extraction-service] [ad | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 2 with epoch 0
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:37.273Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] .m.MetadataExtractedFailureKafkaListener : -----> Started compensating transaction MetadataExtractedFailureEvent(blueprintId=26b0a4d6-1899-4165-840f-2b98dddca0ab, errorMessage=Simulating exception – metadata extraction operation failed, exception=java.lang.Exception: Simulating exception – metadata extraction operation failed)
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:37.274Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] .a.d.a.o.d.p.PostgresDropDatabaseAdapter : Dropping database 26b0a4d6-1899-4165-840f-2b98dddca0ab
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:37 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] c.w.a.b.a.i.m.MetadataExtractedKafkaListener - Received MetadataExtractedFailureEvent(blueprintId=26b0a4d6-1899-4165-840f-2b98dddca0ab, errorMessage=Simulating exception – metadata extraction operation failed, exception=java.lang.Exception: Simulating exception – metadata extraction operation failed)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:37 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] c.w.a.b.a.o.p.d.DumpRepositoryS3Adapter - Deleting Dump from S3... Blueprint ID : 26b0a4d6-1899-4165-840f-2b98dddca0ab
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:37.313Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] .a.d.a.o.d.p.PostgresDropDatabaseAdapter : Successfully dropped database 26b0a4d6-1899-4165-840f-2b98dddca0ab using command [dropdb, -h, postgres, -p, 5432, -U, postgres, --no-password, --if-exists, 26b0a4d6-1899-4165-840f-2b98dddca0ab]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:37 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] c.w.a.b.d.s.BlueprintSagaStatusUpdater - Updated status to METADATA_EXTRACTION_FAILURE of blueprint: Blueprint(blueprintId=26b0a4d6-1899-4165-840f-2b98dddca0ab, dumpFile=null, blueprintSagaStatus=METADATA_EXTRACTION_FAILURE, restoreMode=SCRIPT, databaseType=POSTGRESQL, title=Employees, dumpStoreSuccess=true, description=This is just a sample dump of employees database made in a SCRIPT mode., createdDate=2024-01-28T20:10:35.081, originalDumpName=employeesdb_script.sql)
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:37.357Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] c.w.a.s.impl.LoggingKafkaTemplate        : Publishing to Kafka | Topic: restore-failure | Value: MetadataExtractedFailureEvent(blueprintId=26b0a4d6-1899-4165-840f-2b98dddca0ab, errorMessage=Simulating exception – metadata extraction operation failed, exception=java.lang.Exception: Simulating exception – metadata extraction operation failed)
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:37.365Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] .m.MetadataExtractedFailureKafkaListener : <----- Finished compensating transaction MetadataExtractedFailureEvent(blueprintId=26b0a4d6-1899-4165-840f-2b98dddca0ab, errorMessage=Simulating exception – metadata extraction operation failed, exception=java.lang.Exception: Simulating exception – metadata extraction operation failed)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:37 [http-nio-8100-exec-4] c.w.a.logging.LoggingFilter - -----> Request: GET /api/v1/blueprints?blueprint_id=26b0a4d6-1899-4165-840f-2b98dddca0ab, headers=[user-agent:"curl/8.1.2", accept:"*/*", forwarded:"proto=http;host="localhost:8080";for="192.168.128.1:38594"", x-forwarded-for:"192.168.128.1", x-forwarded-proto:"http", x-forwarded-port:"8080", x-forwarded-host:"localhost:8080", host:"fd044ef25269:8100", content-length:"0"]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:10:37 [http-nio-8100-exec-4] c.w.a.logging.LoggingFilter - <----- Response (HTTP 200 OK):
simulation_2-blueprint-service-1  | {
simulation_2-blueprint-service-1  |   "blueprintId" : "26b0a4d6-1899-4165-840f-2b98dddca0ab",
simulation_2-blueprint-service-1  |   "blueprintSagaStatus" : "METADATA_EXTRACTION_FAILURE",
simulation_2-blueprint-service-1  |   "restoreMode" : "SCRIPT",
simulation_2-blueprint-service-1  |   "databaseType" : "POSTGRESQL",
simulation_2-blueprint-service-1  |   "title" : "Employees",
simulation_2-blueprint-service-1  |   "dumpStoreSuccess" : true,
simulation_2-blueprint-service-1  |   "description" : "This is just a sample dump of employees database made in a SCRIPT mode.",
simulation_2-blueprint-service-1  |   "createdDate" : "2024-01-28T20:10:35.081",
simulation_2-blueprint-service-1  |   "originalDumpName" : "employeesdb_script.sql"
simulation_2-blueprint-service-1  | }
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:10:37 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.w.a.s.config.KafkaDeadLetterConfig - Publishing to dead letter - Source Topic: restore-failure, Partition: 0, Offset: 0, Exception: Exception details
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:47.717Z  INFO 1 --- [database-restoration-service] [nio-8200-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:47.718Z  INFO 1 --- [database-restoration-service] [nio-8200-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:47.722Z  INFO 1 --- [database-restoration-service] [nio-8200-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 4 ms
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:47.743Z  INFO 1 --- [database-restoration-service] [nio-8200-exec-1] c.w.anonymization.logging.LoggingFilter  : -----> Request: GET /api/v1/restorations?blueprint_id=26b0a4d6-1899-4165-840f-2b98dddca0ab, headers=[user-agent:"curl/8.1.2", accept:"*/*", forwarded:"proto=http;host="localhost:8080";for="192.168.128.1:40940"", x-forwarded-for:"192.168.128.1", x-forwarded-proto:"http", x-forwarded-port:"8080", x-forwarded-host:"localhost:8080", host:"59a1a9f2a13d:8200", content-length:"0"]
simulation_2-database-restoration-service-1  | 2024-01-28T20:10:47.805Z  INFO 1 --- [database-restoration-service] [nio-8200-exec-1] c.w.anonymization.logging.LoggingFilter  : <----- Response (HTTP 200 OK):
simulation_2-database-restoration-service-1  | {
simulation_2-database-restoration-service-1  |   "blueprintId" : "26b0a4d6-1899-4165-840f-2b98dddca0ab",
simulation_2-database-restoration-service-1  |   "runnerIp" : "localhost",
simulation_2-database-restoration-service-1  |   "active" : false
simulation_2-database-restoration-service-1  | }
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:11:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:11:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:41:00.024180799
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:11:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:11:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:41:30.010563382
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:12:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:12:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:42:00.010990549
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:12:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:12:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:42:30.006765007
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:13:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:13:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:43:00.005130799
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:13:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:13:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:43:30.006129549
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:14:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:14:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:44:00.015186007
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:14:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:14:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:44:30.016023007
simulation_2-blueprint-service-1  | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
simulation_2-blueprint-service-1  | 20:15:03,158 |-WARN in net.logstash.logback.appender.LogstashTcpSocketAppender[LOGSTASH] - Log destination logstash/<unresolved>:5001: connection failed. java.net.ConnectException: Connection refused
simulation_2-blueprint-service-1  | 	at java.net.ConnectException: Connection refused
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)
simulation_2-blueprint-service-1  | 	at 	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
simulation_2-blueprint-service-1  | 	at 	at java.base/java.net.Socket.connect(Socket.java:633)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.appender.AbstractLogstashTcpSocketAppender$TcpSendingEventHandler.openSocket(AbstractLogstashTcpSocketAppender.java:765)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.appender.AbstractLogstashTcpSocketAppender$TcpSendingEventHandler.onStart(AbstractLogstashTcpSocketAppender.java:691)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.appender.AsyncDisruptorAppender$EventClearingEventHandler.onStart(AsyncDisruptorAppender.java:382)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.encoder.com.lmax.disruptor.BatchEventProcessor.notifyStart(BatchEventProcessor.java:224)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.encoder.com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:120)
simulation_2-blueprint-service-1  | 	at 	at java.base/java.lang.Thread.run(Thread.java:833)
simulation_2-blueprint-service-1  | 20:15:03,181 |-WARN in net.logstash.logback.appender.LogstashTcpSocketAppender[LOGSTASH] - Log destination logstash/<unresolved>:5001: Waiting 29911ms before attempting reconnection.
simulation_2-blueprint-service-1  | 
simulation_2-blueprint-service-1  |   .   ____          _            __ _ _
simulation_2-blueprint-service-1  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
simulation_2-blueprint-service-1  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
simulation_2-blueprint-service-1  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
simulation_2-blueprint-service-1  |   '  |____| .__|_| |_|_| |_\__, | / / / /
simulation_2-blueprint-service-1  |  =========|_|==============|___/=/_/_/_/
simulation_2-blueprint-service-1  |  :: Spring Boot ::                (v3.2.0)
simulation_2-blueprint-service-1  | 
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:03 [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.1.Final
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:04 [main] c.w.a.b.BlueprintServiceApplication - Starting BlueprintServiceApplication v0.0.1-SNAPSHOT using Java 17.0.2 with PID 1 (/app.jar started by root in /)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:04 [main] c.w.a.b.BlueprintServiceApplication - No active profile set, falling back to 1 default profile: "default"
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:09 [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:10 [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 614 ms. Found 1 MongoDB repository interface.
simulation_2-database-restoration-service-1  | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
simulation_2-database-restoration-service-1  | 
simulation_2-database-restoration-service-1  |   .   ____          _            __ _ _
simulation_2-database-restoration-service-1  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
simulation_2-database-restoration-service-1  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
simulation_2-database-restoration-service-1  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
simulation_2-database-restoration-service-1  |   '  |____| .__|_| |_|_| |_\__, | / / / /
simulation_2-database-restoration-service-1  |  =========|_|==============|___/=/_/_/_/
simulation_2-database-restoration-service-1  |  :: Spring Boot ::                (v3.2.0)
simulation_2-database-restoration-service-1  | 
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:00.587Z  INFO 1 --- [database-restoration-service] [           main] .d.DatabaseRestorationServiceApplication : Starting DatabaseRestorationServiceApplication v0.0.1-SNAPSHOT using Java 17.0.2 with PID 1 (/app.jar started by root in /)
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:00.640Z  INFO 1 --- [database-restoration-service] [           main] .d.DatabaseRestorationServiceApplication : No active profile set, falling back to 1 default profile: "default"
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:09.116Z  INFO 1 --- [database-restoration-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:09.532Z  INFO 1 --- [database-restoration-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 394 ms. Found 0 Reactive MongoDB repository interfaces.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:09.559Z  INFO 1 --- [database-restoration-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:09.645Z  INFO 1 --- [database-restoration-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 85 ms. Found 2 MongoDB repository interfaces.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:11.669Z  INFO 1 --- [database-restoration-service] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=2d0e14d5-d1a0-3417-a8bd-63dbf509f98d
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.383Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$RetryInterceptorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$RetryInterceptorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [lbRestClientPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.418Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration' of type [org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.446Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration' of type [org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.483Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.502Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.523Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$579/0x000000080103a4b0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.529Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.568Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'spring.cloud.loadbalancer-org.springframework.cloud.client.loadbalancer.LoadBalancerClientsProperties' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerClientsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.627Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'default.org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.629Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'default.org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.635Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'default.org.springframework.cloud.netflix.eureka.loadbalancer.LoadBalancerEurekaAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.638Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerClientFactory' of type [org.springframework.cloud.loadbalancer.support.LoadBalancerClientFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.661Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'blockingLoadBalancerClient' of type [org.springframework.cloud.loadbalancer.blocking.client.BlockingLoadBalancerClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.747Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerServiceInstanceCookieTransformer' of type [org.springframework.cloud.loadbalancer.core.LoadBalancerServiceInstanceCookieTransformer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.772Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'xForwarderHeadersTransformer' of type [org.springframework.cloud.loadbalancer.blocking.XForwardedHeadersTransformer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.782Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.802Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerRequestFactory' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerRequestFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.826Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration$BlockingLoadBalancerRetryConfig' of type [org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration$BlockingLoadBalancerRetryConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.848Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancedRetryFactory' of type [org.springframework.cloud.loadbalancer.blocking.retry.BlockingLoadBalancedRetryFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:12.879Z  WARN 1 --- [database-restoration-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerInterceptor' of type [org.springframework.cloud.client.loadbalancer.RetryLoadBalancerInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:12 [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:12 [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 82 ms. Found 0 Reactive MongoDB repository interfaces.
simulation_2-metadata-extraction-service-1  | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
simulation_2-metadata-extraction-service-1  | 
simulation_2-metadata-extraction-service-1  |   .   ____          _            __ _ _
simulation_2-metadata-extraction-service-1  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
simulation_2-metadata-extraction-service-1  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
simulation_2-metadata-extraction-service-1  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
simulation_2-metadata-extraction-service-1  |   '  |____| .__|_| |_|_| |_\__, | / / / /
simulation_2-metadata-extraction-service-1  |  =========|_|==============|___/=/_/_/_/
simulation_2-metadata-extraction-service-1  |  :: Spring Boot ::                (v3.2.0)
simulation_2-metadata-extraction-service-1  | 
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:14:59.077Z  INFO 1 --- [metadata-extraction-service] [           main] a.m.MetadataExtractionServiceApplication : Starting MetadataExtractionServiceApplication vsimulation-case-1 using Java 17.0.2 with PID 1 (/app.jar started by root in /)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:14:59.111Z  INFO 1 --- [metadata-extraction-service] [           main] a.m.MetadataExtractionServiceApplication : No active profile set, falling back to 1 default profile: "default"
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:07.034Z  INFO 1 --- [metadata-extraction-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Reactive MongoDB repositories in DEFAULT mode.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:07.414Z  INFO 1 --- [metadata-extraction-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 367 ms. Found 0 Reactive MongoDB repository interfaces.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:07.432Z  INFO 1 --- [metadata-extraction-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:07.495Z  INFO 1 --- [metadata-extraction-service] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 63 ms. Found 1 MongoDB repository interface.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:08.961Z  INFO 1 --- [metadata-extraction-service] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=6df4e22d-46ea-3356-8046-7693b04c62fa
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:09.778Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$RetryInterceptorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$RetryInterceptorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [lbRestClientPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:09.795Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration' of type [org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:09.811Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration' of type [org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:09.901Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:09.924Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:09.924Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$579/0x0000000801021770] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:09.925Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:09.951Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'spring.cloud.loadbalancer-org.springframework.cloud.client.loadbalancer.LoadBalancerClientsProperties' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerClientsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:09.976Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'default.org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:09.977Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'default.org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:10.008Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'default.org.springframework.cloud.netflix.eureka.loadbalancer.LoadBalancerEurekaAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:10.053Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerClientFactory' of type [org.springframework.cloud.loadbalancer.support.LoadBalancerClientFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:10.111Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'blockingLoadBalancerClient' of type [org.springframework.cloud.loadbalancer.blocking.client.BlockingLoadBalancerClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:10.251Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerServiceInstanceCookieTransformer' of type [org.springframework.cloud.loadbalancer.core.LoadBalancerServiceInstanceCookieTransformer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:10.252Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'xForwarderHeadersTransformer' of type [org.springframework.cloud.loadbalancer.blocking.XForwardedHeadersTransformer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:10.271Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:10.304Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerRequestFactory' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerRequestFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:10.324Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration$BlockingLoadBalancerRetryConfig' of type [org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration$BlockingLoadBalancerRetryConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:10.353Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancedRetryFactory' of type [org.springframework.cloud.loadbalancer.blocking.retry.BlockingLoadBalancedRetryFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:10.395Z  WARN 1 --- [metadata-extraction-service] [           main] trationDelegate$BeanPostProcessorChecker : Bean 'loadBalancerInterceptor' of type [org.springframework.cloud.client.loadbalancer.RetryLoadBalancerInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:11.493Z  INFO 1 --- [metadata-extraction-service] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port 8300 (http)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:11.519Z  INFO 1 --- [metadata-extraction-service] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:11.519Z  INFO 1 --- [metadata-extraction-service] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.16]
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:11.733Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:11.742Z  INFO 1 --- [metadata-extraction-service] [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 12183 ms
simulation_2-metadata-extraction-service-1  | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:14.014Z  INFO 1 --- [database-restoration-service] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port 8200 (http)
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:14.045Z  INFO 1 --- [database-restoration-service] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:14.045Z  INFO 1 --- [database-restoration-service] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/10.1.16]
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:14.208Z  INFO 1 --- [database-restoration-service] [           main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:14.210Z  INFO 1 --- [database-restoration-service] [           main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 12943 ms
simulation_2-database-restoration-service-1  | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:15.058Z  INFO 1 --- [metadata-extraction-service] [           main] org.mongodb.driver.client                : MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.11.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "aarch64", "version": "5.15.49-linuxkit"}, "platform": "Java/Oracle Corporation/17.0.2+8-86"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='METADATA_USER', source='METADATA_DB', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@6d421fe], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@3c17bd0b, com.mongodb.Jep395RecordCodecProvider@36dafa24, com.mongodb.KotlinCodecProvider@2b098563]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@c758a2d], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:15.139Z  INFO 1 --- [metadata-extraction-service] [}-mongodb:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=143668667}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:15 [main] o.s.cloud.context.scope.GenericScope - BeanFactory id=d36cf96f-b91b-364c-92cc-e2cf13fd9573
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:15 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$RetryInterceptorAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration$RetryInterceptorAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). The currently created BeanPostProcessor [lbRestClientPostProcessor] is declared through a non-static factory method on that class; consider declaring it as static instead.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:15 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration' of type [org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:15 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration' of type [org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration' of type [org.springframework.cloud.commons.config.CommonsConfigAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerClientsDefaultsMappingsProvider' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerDefaultMappingsProviderAutoConfiguration$$Lambda$679/0x000000080108dd40] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'defaultsBindHandlerAdvisor' of type [org.springframework.cloud.commons.config.DefaultsBindHandlerAdvisor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'spring.cloud.loadbalancer-org.springframework.cloud.client.loadbalancer.LoadBalancerClientsProperties' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerClientsProperties] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'default.org.springframework.cloud.loadbalancer.config.LoadBalancerAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'default.org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'default.org.springframework.cloud.netflix.eureka.loadbalancer.LoadBalancerEurekaAutoConfiguration.LoadBalancerClientSpecification' of type [org.springframework.cloud.loadbalancer.annotation.LoadBalancerClientSpecification] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerClientFactory' of type [org.springframework.cloud.loadbalancer.support.LoadBalancerClientFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'blockingLoadBalancerClient' of type [org.springframework.cloud.loadbalancer.blocking.client.BlockingLoadBalancerClient] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerServiceInstanceCookieTransformer' of type [org.springframework.cloud.loadbalancer.core.LoadBalancerServiceInstanceCookieTransformer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'xForwarderHeadersTransformer' of type [org.springframework.cloud.loadbalancer.blocking.XForwardedHeadersTransformer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerAutoConfiguration] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerRequestFactory' of type [org.springframework.cloud.client.loadbalancer.LoadBalancerRequestFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration$BlockingLoadBalancerRetryConfig' of type [org.springframework.cloud.loadbalancer.config.BlockingLoadBalancerClientAutoConfiguration$BlockingLoadBalancerRetryConfig$$SpringCGLIB$$0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancedRetryFactory' of type [org.springframework.cloud.loadbalancer.blocking.retry.BlockingLoadBalancedRetryFactory] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:16 [main] o.s.c.s.PostProcessorRegistrationDelegate$BeanPostProcessorChecker - Bean 'loadBalancerInterceptor' of type [org.springframework.cloud.client.loadbalancer.RetryLoadBalancerInterceptor] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying). Is this bean getting eagerly injected into a currently created BeanPostProcessor [lbRestClientPostProcessor]? Check the corresponding BeanPostProcessor declaration and its dependencies.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:17.443Z  INFO 1 --- [database-restoration-service] [           main] org.mongodb.driver.client                : MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.11.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "aarch64", "version": "5.15.49-linuxkit"}, "platform": "Java/Oracle Corporation/17.0.2+8-86"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='RESTORATIONS_USER', source='RESTORATIONS_DB', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=NettyTransportSettings{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@770cae59, socketChannelClass=null, allocator=null, sslContext=null}, streamFactoryFactory=null, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@76b5a559], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@4bdb04c8, com.mongodb.Jep395RecordCodecProvider@2e8b24a1, com.mongodb.KotlinCodecProvider@3ce7394f]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@6723cce7], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:17 [main] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat initialized with port 8100 (http)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:17 [main] o.a.coyote.http11.Http11NioProtocol - Initializing ProtocolHandler ["http-nio-8100"]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:17 [main] o.a.catalina.core.StandardService - Starting service [Tomcat]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:17 [main] o.a.catalina.core.StandardEngine - Starting Servlet engine: [Apache Tomcat/10.1.16]
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:18.033Z  INFO 1 --- [database-restoration-service] [}-mongodb:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=369849584}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:18 [main] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring embedded WebApplicationContext
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:18 [main] o.s.b.w.s.c.ServletWebServerApplicationContext - Root WebApplicationContext: initialization completed in 13400 ms
simulation_2-blueprint-service-1  | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.808Z  INFO 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaRetryConfig          : Retrying in Kafka Consumer is disabled, backoff will not be used...
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.884Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: dead-letter
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.930Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: created-blueprint
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.934Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: anonymization-execution
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.934Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: anonymization-execution-success
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.935Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: anonymization-execution-failure
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.935Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: restore-success
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.935Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: restore-failure
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.935Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: operations
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.936Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: load-success
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.936Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: load-failure
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.936Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: extraction-success
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.937Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: extraction-failure
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.938Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-anonymize-success
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.939Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-anonymize-failure
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.940Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-script-success
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.943Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-script-failure
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:19.943Z  WARN 1 --- [metadata-extraction-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: created-worksheet
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:20.488Z  INFO 1 --- [metadata-extraction-service] [           main] org.mongodb.driver.client                : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.11.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "aarch64", "version": "5.15.49-linuxkit"}, "platform": "Java/Oracle Corporation/17.0.2+8-86"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='METADATA_USER', source='METADATA_DB', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=null, streamFactoryFactory=null, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@6d421fe], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@3c17bd0b, com.mongodb.Jep395RecordCodecProvider@36dafa24, com.mongodb.KotlinCodecProvider@2b098563]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@c758a2d], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:20.770Z  INFO 1 --- [metadata-extraction-service] [}-mongodb:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=47344250}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:20 [main] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.11.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "aarch64", "version": "5.15.49-linuxkit"}, "platform": "Java/Oracle Corporation/17.0.2+8-86"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='BLUEPRINTS_USER', source='BLUEPRINTS_DB', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=NettyTransportSettings{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@56f72909, socketChannelClass=null, allocator=null, sslContext=null}, streamFactoryFactory=null, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@48af5f38], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@71285693, com.mongodb.Jep395RecordCodecProvider@3199a202, com.mongodb.KotlinCodecProvider@7286827b]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@abc7005], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:21 [cluster-ClusterId{value='65b6b5d814af47786f1f37da', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=433194001}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:22.240Z  INFO 1 --- [metadata-extraction-service] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:22.367Z  WARN 1 --- [metadata-extraction-service] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:22.397Z  INFO 1 --- [metadata-extraction-service] [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 2 endpoint(s) beneath base path '/actuator'
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:22.872Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
simulation_2-metadata-extraction-service-1  | 	auto.include.jmx.reporter = true
simulation_2-metadata-extraction-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-metadata-extraction-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-metadata-extraction-service-1  | 	client.id = 
simulation_2-metadata-extraction-service-1  | 	connections.max.idle.ms = 300000
simulation_2-metadata-extraction-service-1  | 	default.api.timeout.ms = 60000
simulation_2-metadata-extraction-service-1  | 	metadata.max.age.ms = 300000
simulation_2-metadata-extraction-service-1  | 	metric.reporters = []
simulation_2-metadata-extraction-service-1  | 	metrics.num.samples = 2
simulation_2-metadata-extraction-service-1  | 	metrics.recording.level = INFO
simulation_2-metadata-extraction-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-metadata-extraction-service-1  | 	receive.buffer.bytes = 65536
simulation_2-metadata-extraction-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-metadata-extraction-service-1  | 	reconnect.backoff.ms = 50
simulation_2-metadata-extraction-service-1  | 	request.timeout.ms = 30000
simulation_2-metadata-extraction-service-1  | 	retries = 2147483647
simulation_2-metadata-extraction-service-1  | 	retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.jaas.config = null
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.service.name = null
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-metadata-extraction-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-metadata-extraction-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-metadata-extraction-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-metadata-extraction-service-1  | 	security.protocol = PLAINTEXT
simulation_2-metadata-extraction-service-1  | 	security.providers = null
simulation_2-metadata-extraction-service-1  | 	send.buffer.bytes = 131072
simulation_2-metadata-extraction-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-metadata-extraction-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-metadata-extraction-service-1  | 	ssl.cipher.suites = null
simulation_2-metadata-extraction-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-metadata-extraction-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-metadata-extraction-service-1  | 	ssl.engine.factory.class = null
simulation_2-metadata-extraction-service-1  | 	ssl.key.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.key = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.location = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.type = JKS
simulation_2-metadata-extraction-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-metadata-extraction-service-1  | 	ssl.provider = null
simulation_2-metadata-extraction-service-1  | 	ssl.secure.random.implementation = null
simulation_2-metadata-extraction-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.certificates = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.location = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.type = JKS
simulation_2-metadata-extraction-service-1  | 
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:23.611Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:23.623Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:23.623Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472923610
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.518Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: dead-letter
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.536Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: created-blueprint
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.536Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: anonymization-execution
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.537Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: anonymization-execution-success
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.537Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: anonymization-execution-failure
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.538Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: restore-success
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.539Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: restore-failure
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.540Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: operations
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.540Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: load-success
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.541Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: load-failure
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.542Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: extraction-success
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.543Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: extraction-failure
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.543Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-anonymize-success
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.545Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-anonymize-failure
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.546Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-script-success
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.546Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: transformation-script-failure
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:25.546Z  WARN 1 --- [database-restoration-service] [           main] c.w.a.s.config.KafkaTopicConfig          : Creating topic: created-worksheet
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:26.002Z  INFO 1 --- [database-restoration-service] [}-mongodb:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=33008000}
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:26.049Z  INFO 1 --- [database-restoration-service] [           main] org.mongodb.driver.client                : MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.11.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "aarch64", "version": "5.15.49-linuxkit"}, "platform": "Java/Oracle Corporation/17.0.2+8-86"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='RESTORATIONS_USER', source='RESTORATIONS_DB', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=NettyTransportSettings{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@440d2d64, socketChannelClass=null, allocator=null, sslContext=null}, streamFactoryFactory=null, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@76b5a559], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@4bdb04c8, com.mongodb.Jep395RecordCodecProvider@2e8b24a1, com.mongodb.KotlinCodecProvider@3ce7394f]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@6723cce7], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:26.330Z  INFO 1 --- [metadata-extraction-service] [| adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:26.340Z  INFO 1 --- [metadata-extraction-service] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:26.340Z  INFO 1 --- [metadata-extraction-service] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:26.340Z  INFO 1 --- [metadata-extraction-service] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:26.432Z  INFO 1 --- [metadata-extraction-service] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:26.663Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:26.702Z  INFO 1 --- [metadata-extraction-service] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:26.858Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:26.858Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:26.865Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:26.866Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:26.866Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:26.866Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:26.866Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:27.315Z  INFO 1 --- [database-restoration-service] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:27.516Z  WARN 1 --- [database-restoration-service] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:27.548Z  INFO 1 --- [database-restoration-service] [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 2 endpoint(s) beneath base path '/actuator'
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:28.704Z  INFO 1 --- [database-restoration-service] [           main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
simulation_2-database-restoration-service-1  | 	auto.include.jmx.reporter = true
simulation_2-database-restoration-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-database-restoration-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-database-restoration-service-1  | 	client.id = 
simulation_2-database-restoration-service-1  | 	connections.max.idle.ms = 300000
simulation_2-database-restoration-service-1  | 	default.api.timeout.ms = 60000
simulation_2-database-restoration-service-1  | 	metadata.max.age.ms = 300000
simulation_2-database-restoration-service-1  | 	metric.reporters = []
simulation_2-database-restoration-service-1  | 	metrics.num.samples = 2
simulation_2-database-restoration-service-1  | 	metrics.recording.level = INFO
simulation_2-database-restoration-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-database-restoration-service-1  | 	receive.buffer.bytes = 65536
simulation_2-database-restoration-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-database-restoration-service-1  | 	reconnect.backoff.ms = 50
simulation_2-database-restoration-service-1  | 	request.timeout.ms = 30000
simulation_2-database-restoration-service-1  | 	retries = 2147483647
simulation_2-database-restoration-service-1  | 	retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.jaas.config = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-database-restoration-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-database-restoration-service-1  | 	sasl.kerberos.service.name = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-database-restoration-service-1  | 	security.protocol = PLAINTEXT
simulation_2-database-restoration-service-1  | 	security.providers = null
simulation_2-database-restoration-service-1  | 	send.buffer.bytes = 131072
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-database-restoration-service-1  | 	ssl.cipher.suites = null
simulation_2-database-restoration-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-database-restoration-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-database-restoration-service-1  | 	ssl.engine.factory.class = null
simulation_2-database-restoration-service-1  | 	ssl.key.password = null
simulation_2-database-restoration-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-database-restoration-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.key = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.location = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.password = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.type = JKS
simulation_2-database-restoration-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-database-restoration-service-1  | 	ssl.provider = null
simulation_2-database-restoration-service-1  | 	ssl.secure.random.implementation = null
simulation_2-database-restoration-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-database-restoration-service-1  | 	ssl.truststore.certificates = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.location = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.password = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.type = JKS
simulation_2-database-restoration-service-1  | 
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:28.983Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:28.997Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:28.998Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472928982
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:29.397Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:29.424Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:29.444Z  INFO 1 --- [metadata-extraction-service] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:29.468Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1706472929467 with initial instances count: 0
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:29.528Z  INFO 1 --- [metadata-extraction-service] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application METADATA-EXTRACTION-SERVICE with eureka with status UP
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:29.541Z  INFO 1 --- [metadata-extraction-service] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1706472929541, current=UP, previous=STARTING]
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:29.550Z  INFO 1 --- [metadata-extraction-service] [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_METADATA-EXTRACTION-SERVICE/0724ad71d3af:metadata-extraction-service:8300: registering service...
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:29.768Z  INFO 1 --- [metadata-extraction-service] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port 8300 (http) with context path ''
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:29.786Z  INFO 1 --- [metadata-extraction-service] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8300
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:29.833Z  INFO 1 --- [metadata-extraction-service] [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_METADATA-EXTRACTION-SERVICE/0724ad71d3af:metadata-extraction-service:8300 - registration status: 204
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: dead-letter
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: created-blueprint
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: anonymization-execution
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: anonymization-execution-success
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: anonymization-execution-failure
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: restore-success
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: restore-failure
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: operations
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: load-success
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: load-failure
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: extraction-success
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: extraction-failure
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: transformation-anonymize-success
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: transformation-anonymize-failure
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: transformation-script-success
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: transformation-script-failure
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:29 [main] c.w.a.s.config.KafkaTopicConfig - Creating topic: created-worksheet
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:29.946Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
simulation_2-metadata-extraction-service-1  | 	allow.auto.create.topics = true
simulation_2-metadata-extraction-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-metadata-extraction-service-1  | 	auto.include.jmx.reporter = true
simulation_2-metadata-extraction-service-1  | 	auto.offset.reset = latest
simulation_2-metadata-extraction-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-metadata-extraction-service-1  | 	check.crcs = true
simulation_2-metadata-extraction-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-metadata-extraction-service-1  | 	client.id = consumer-metadata-extraction-service-group-1
simulation_2-metadata-extraction-service-1  | 	client.rack = 
simulation_2-metadata-extraction-service-1  | 	connections.max.idle.ms = 540000
simulation_2-metadata-extraction-service-1  | 	default.api.timeout.ms = 60000
simulation_2-metadata-extraction-service-1  | 	enable.auto.commit = false
simulation_2-metadata-extraction-service-1  | 	exclude.internal.topics = true
simulation_2-metadata-extraction-service-1  | 	fetch.max.bytes = 52428800
simulation_2-metadata-extraction-service-1  | 	fetch.max.wait.ms = 500
simulation_2-metadata-extraction-service-1  | 	fetch.min.bytes = 1
simulation_2-metadata-extraction-service-1  | 	group.id = metadata-extraction-service-group
simulation_2-metadata-extraction-service-1  | 	group.instance.id = null
simulation_2-metadata-extraction-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-metadata-extraction-service-1  | 	interceptor.classes = []
simulation_2-metadata-extraction-service-1  | 	internal.leave.group.on.close = true
simulation_2-metadata-extraction-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-metadata-extraction-service-1  | 	isolation.level = read_uncommitted
simulation_2-metadata-extraction-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-metadata-extraction-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-metadata-extraction-service-1  | 	max.poll.interval.ms = 90000
simulation_2-metadata-extraction-service-1  | 	max.poll.records = 500
simulation_2-metadata-extraction-service-1  | 	metadata.max.age.ms = 300000
simulation_2-metadata-extraction-service-1  | 	metric.reporters = []
simulation_2-metadata-extraction-service-1  | 	metrics.num.samples = 2
simulation_2-metadata-extraction-service-1  | 	metrics.recording.level = INFO
simulation_2-metadata-extraction-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-metadata-extraction-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-metadata-extraction-service-1  | 	receive.buffer.bytes = 65536
simulation_2-metadata-extraction-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-metadata-extraction-service-1  | 	reconnect.backoff.ms = 50
simulation_2-metadata-extraction-service-1  | 	request.timeout.ms = 30000
simulation_2-metadata-extraction-service-1  | 	retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.jaas.config = null
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.service.name = null
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-metadata-extraction-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-metadata-extraction-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-metadata-extraction-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-metadata-extraction-service-1  | 	security.protocol = PLAINTEXT
simulation_2-metadata-extraction-service-1  | 	security.providers = null
simulation_2-metadata-extraction-service-1  | 	send.buffer.bytes = 131072
simulation_2-metadata-extraction-service-1  | 	session.timeout.ms = 45000
simulation_2-metadata-extraction-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-metadata-extraction-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-metadata-extraction-service-1  | 	ssl.cipher.suites = null
simulation_2-metadata-extraction-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-metadata-extraction-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-metadata-extraction-service-1  | 	ssl.engine.factory.class = null
simulation_2-metadata-extraction-service-1  | 	ssl.key.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.key = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.location = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.type = JKS
simulation_2-metadata-extraction-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-metadata-extraction-service-1  | 	ssl.provider = null
simulation_2-metadata-extraction-service-1  | 	ssl.secure.random.implementation = null
simulation_2-metadata-extraction-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.certificates = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.location = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.type = JKS
simulation_2-metadata-extraction-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-metadata-extraction-service-1  | 
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:30.192Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:30.192Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:30.192Z  INFO 1 --- [metadata-extraction-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472930192
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:30.195Z  INFO 1 --- [metadata-extraction-service] [           main] fkaConsumerFactory$ExtendedKafkaConsumer : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Subscribed to topic(s): restore-success
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:30.440Z  INFO 1 --- [database-restoration-service] [| adminclient-1] o.a.kafka.common.utils.AppInfoParser     : App info kafka.admin.client for adminclient-1 unregistered
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:30.455Z  INFO 1 --- [database-restoration-service] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics scheduler closed
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:30.469Z  INFO 1 --- [database-restoration-service] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Closing reporter org.apache.kafka.common.metrics.JmxReporter
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:30.470Z  INFO 1 --- [database-restoration-service] [| adminclient-1] o.apache.kafka.common.metrics.Metrics    : Metrics reporters closed
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:30.487Z  INFO 1 --- [metadata-extraction-service] [           main] a.m.MetadataExtractionServiceApplication : Started MetadataExtractionServiceApplication in 34.309 seconds (process running for 38.583)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:30.488Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Cluster ID: SfQo8OGTSxO1CfeFL1N09Q
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:30.583Z  INFO 1 --- [database-restoration-service] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:30.884Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:30.997Z  INFO 1 --- [database-restoration-service] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:31 [cluster-ClusterId{value='65b6b5e214af47786f1f37db', description='null'}-mongodb:27017] org.mongodb.driver.cluster - Monitor thread successfully connected to server with description ServerDescription{address=mongodb:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=17, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=132075500}
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:31.244Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:31.245Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:31.245Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:31.245Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:31.245Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:31.245Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:31.245Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:31 [main] org.mongodb.driver.client - MongoClient with metadata {"driver": {"name": "mongo-java-driver|reactive-streams|spring-boot", "version": "4.11.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "aarch64", "version": "5.15.49-linuxkit"}, "platform": "Java/Oracle Corporation/17.0.2+8-86"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=MongoCredential{mechanism=null, userName='BLUEPRINTS_USER', source='BLUEPRINTS_DB', password=<hidden>, mechanismProperties=<hidden>}, transportSettings=NettyTransportSettings{eventLoopGroup=io.netty.channel.nio.NioEventLoopGroup@520eb9f8, socketChannelClass=null, allocator=null, sslContext=null}, streamFactoryFactory=null, commandListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsCommandListener@48af5f38], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, CollectionCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.client.model.mql.ExpressionCodecProvider@71285693, com.mongodb.Jep395RecordCodecProvider@3199a202, com.mongodb.KotlinCodecProvider@7286827b]}, loggerSettings=LoggerSettings{maxDocumentLength=1000}, clusterSettings={hosts=[mongodb:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='15 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, proxySettings=ProxySettings{host=null, port=null, username=null, password=null}}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[io.micrometer.core.instrument.binder.mongodb.MongoMetricsConnectionPoolListener@abc7005], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, dnsClient=null, inetAddressResolver=null, contextProvider=null}
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.225Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.266Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.288Z  INFO 1 --- [database-restoration-service] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.306Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1706472932305 with initial instances count: 2
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.375Z  INFO 1 --- [database-restoration-service] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application DATABASE-RESTORATION-SERVICE with eureka with status UP
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.375Z  INFO 1 --- [database-restoration-service] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1706472932375, current=UP, previous=STARTING]
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.386Z  INFO 1 --- [database-restoration-service] [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_DATABASE-RESTORATION-SERVICE/07ebd9405d2c:database-restoration-service:8200: registering service...
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.616Z  INFO 1 --- [database-restoration-service] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port 8200 (http) with context path ''
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.617Z  INFO 1 --- [database-restoration-service] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8200
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.662Z  INFO 1 --- [database-restoration-service] [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_DATABASE-RESTORATION-SERVICE/07ebd9405d2c:database-restoration-service:8200 - registration status: 204
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:32.702Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:32.707Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] (Re-)joining group
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.778Z  INFO 1 --- [database-restoration-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
simulation_2-database-restoration-service-1  | 	allow.auto.create.topics = true
simulation_2-database-restoration-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-database-restoration-service-1  | 	auto.include.jmx.reporter = true
simulation_2-database-restoration-service-1  | 	auto.offset.reset = latest
simulation_2-database-restoration-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-database-restoration-service-1  | 	check.crcs = true
simulation_2-database-restoration-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-database-restoration-service-1  | 	client.id = consumer-database-restoration-service-group-1
simulation_2-database-restoration-service-1  | 	client.rack = 
simulation_2-database-restoration-service-1  | 	connections.max.idle.ms = 540000
simulation_2-database-restoration-service-1  | 	default.api.timeout.ms = 60000
simulation_2-database-restoration-service-1  | 	enable.auto.commit = false
simulation_2-database-restoration-service-1  | 	exclude.internal.topics = true
simulation_2-database-restoration-service-1  | 	fetch.max.bytes = 52428800
simulation_2-database-restoration-service-1  | 	fetch.max.wait.ms = 500
simulation_2-database-restoration-service-1  | 	fetch.min.bytes = 1
simulation_2-database-restoration-service-1  | 	group.id = database-restoration-service-group
simulation_2-database-restoration-service-1  | 	group.instance.id = null
simulation_2-database-restoration-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-database-restoration-service-1  | 	interceptor.classes = []
simulation_2-database-restoration-service-1  | 	internal.leave.group.on.close = true
simulation_2-database-restoration-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-database-restoration-service-1  | 	isolation.level = read_uncommitted
simulation_2-database-restoration-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-database-restoration-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-database-restoration-service-1  | 	max.poll.interval.ms = 90000
simulation_2-database-restoration-service-1  | 	max.poll.records = 500
simulation_2-database-restoration-service-1  | 	metadata.max.age.ms = 300000
simulation_2-database-restoration-service-1  | 	metric.reporters = []
simulation_2-database-restoration-service-1  | 	metrics.num.samples = 2
simulation_2-database-restoration-service-1  | 	metrics.recording.level = INFO
simulation_2-database-restoration-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-database-restoration-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-database-restoration-service-1  | 	receive.buffer.bytes = 65536
simulation_2-database-restoration-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-database-restoration-service-1  | 	reconnect.backoff.ms = 50
simulation_2-database-restoration-service-1  | 	request.timeout.ms = 30000
simulation_2-database-restoration-service-1  | 	retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.jaas.config = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-database-restoration-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-database-restoration-service-1  | 	sasl.kerberos.service.name = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-database-restoration-service-1  | 	security.protocol = PLAINTEXT
simulation_2-database-restoration-service-1  | 	security.providers = null
simulation_2-database-restoration-service-1  | 	send.buffer.bytes = 131072
simulation_2-database-restoration-service-1  | 	session.timeout.ms = 45000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-database-restoration-service-1  | 	ssl.cipher.suites = null
simulation_2-database-restoration-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-database-restoration-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-database-restoration-service-1  | 	ssl.engine.factory.class = null
simulation_2-database-restoration-service-1  | 	ssl.key.password = null
simulation_2-database-restoration-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-database-restoration-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.key = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.location = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.password = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.type = JKS
simulation_2-database-restoration-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-database-restoration-service-1  | 	ssl.provider = null
simulation_2-database-restoration-service-1  | 	ssl.secure.random.implementation = null
simulation_2-database-restoration-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-database-restoration-service-1  | 	ssl.truststore.certificates = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.location = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.password = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.type = JKS
simulation_2-database-restoration-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-database-restoration-service-1  | 
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:32.815Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Request joining group due to: need to re-join with the given member-id: consumer-metadata-extraction-service-group-1-ade2b27b-bf88-4f03-9a19-f37802954ca4
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:32.816Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:32.817Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:32 [main] o.s.c.n.e.c.DiscoveryClientOptionalArgsConfiguration - Eureka HTTP Client uses RestTemplate.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:32.838Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-metadata-extraction-service-group-1-ade2b27b-bf88-4f03-9a19-f37802954ca4', protocol='range'}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:32.848Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Finished assignment for group at generation 1: {consumer-metadata-extraction-service-group-1-ade2b27b-bf88-4f03-9a19-f37802954ca4=Assignment(partitions=[restore-success-0])}
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:32 [main] o.s.c.l.c.LoadBalancerCacheAutoConfiguration$LoadBalancerCaffeineWarnLogger - Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:32 [main] o.s.b.a.e.web.EndpointLinksResolver - Exposing 17 endpoint(s) beneath base path '/actuator'
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.900Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.900Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.900Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472932900
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.901Z  INFO 1 --- [database-restoration-service] [           main] fkaConsumerFactory$ExtendedKafkaConsumer : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Subscribed to topic(s): created-blueprint
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:32.920Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-metadata-extraction-service-group-1-ade2b27b-bf88-4f03-9a19-f37802954ca4', protocol='range'}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:32.922Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Notifying assignor about the new Assignment(partitions=[restore-success-0])
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:32.927Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Adding newly assigned partitions: restore-success-0
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:32.939Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Found no committed offset for partition restore-success-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.941Z  INFO 1 --- [database-restoration-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
simulation_2-database-restoration-service-1  | 	allow.auto.create.topics = true
simulation_2-database-restoration-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-database-restoration-service-1  | 	auto.include.jmx.reporter = true
simulation_2-database-restoration-service-1  | 	auto.offset.reset = latest
simulation_2-database-restoration-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-database-restoration-service-1  | 	check.crcs = true
simulation_2-database-restoration-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-database-restoration-service-1  | 	client.id = consumer-database-restoration-service-group-2
simulation_2-database-restoration-service-1  | 	client.rack = 
simulation_2-database-restoration-service-1  | 	connections.max.idle.ms = 540000
simulation_2-database-restoration-service-1  | 	default.api.timeout.ms = 60000
simulation_2-database-restoration-service-1  | 	enable.auto.commit = false
simulation_2-database-restoration-service-1  | 	exclude.internal.topics = true
simulation_2-database-restoration-service-1  | 	fetch.max.bytes = 52428800
simulation_2-database-restoration-service-1  | 	fetch.max.wait.ms = 500
simulation_2-database-restoration-service-1  | 	fetch.min.bytes = 1
simulation_2-database-restoration-service-1  | 	group.id = database-restoration-service-group
simulation_2-database-restoration-service-1  | 	group.instance.id = null
simulation_2-database-restoration-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-database-restoration-service-1  | 	interceptor.classes = []
simulation_2-database-restoration-service-1  | 	internal.leave.group.on.close = true
simulation_2-database-restoration-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-database-restoration-service-1  | 	isolation.level = read_uncommitted
simulation_2-database-restoration-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-database-restoration-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-database-restoration-service-1  | 	max.poll.interval.ms = 90000
simulation_2-database-restoration-service-1  | 	max.poll.records = 500
simulation_2-database-restoration-service-1  | 	metadata.max.age.ms = 300000
simulation_2-database-restoration-service-1  | 	metric.reporters = []
simulation_2-database-restoration-service-1  | 	metrics.num.samples = 2
simulation_2-database-restoration-service-1  | 	metrics.recording.level = INFO
simulation_2-database-restoration-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-database-restoration-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-database-restoration-service-1  | 	receive.buffer.bytes = 65536
simulation_2-database-restoration-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-database-restoration-service-1  | 	reconnect.backoff.ms = 50
simulation_2-database-restoration-service-1  | 	request.timeout.ms = 30000
simulation_2-database-restoration-service-1  | 	retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.jaas.config = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-database-restoration-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-database-restoration-service-1  | 	sasl.kerberos.service.name = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-database-restoration-service-1  | 	security.protocol = PLAINTEXT
simulation_2-database-restoration-service-1  | 	security.providers = null
simulation_2-database-restoration-service-1  | 	send.buffer.bytes = 131072
simulation_2-database-restoration-service-1  | 	session.timeout.ms = 45000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-database-restoration-service-1  | 	ssl.cipher.suites = null
simulation_2-database-restoration-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-database-restoration-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-database-restoration-service-1  | 	ssl.engine.factory.class = null
simulation_2-database-restoration-service-1  | 	ssl.key.password = null
simulation_2-database-restoration-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-database-restoration-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.key = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.location = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.password = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.type = JKS
simulation_2-database-restoration-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-database-restoration-service-1  | 	ssl.provider = null
simulation_2-database-restoration-service-1  | 	ssl.secure.random.implementation = null
simulation_2-database-restoration-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-database-restoration-service-1  | 	ssl.truststore.certificates = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.location = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.password = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.type = JKS
simulation_2-database-restoration-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-database-restoration-service-1  | 
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.944Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.944Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.944Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472932944
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.945Z  INFO 1 --- [database-restoration-service] [           main] fkaConsumerFactory$ExtendedKafkaConsumer : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Subscribed to topic(s): created-worksheet
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:32.946Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Found no committed offset for partition restore-success-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.986Z  INFO 1 --- [database-restoration-service] [           main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
simulation_2-database-restoration-service-1  | 	allow.auto.create.topics = true
simulation_2-database-restoration-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-database-restoration-service-1  | 	auto.include.jmx.reporter = true
simulation_2-database-restoration-service-1  | 	auto.offset.reset = latest
simulation_2-database-restoration-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-database-restoration-service-1  | 	check.crcs = true
simulation_2-database-restoration-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-database-restoration-service-1  | 	client.id = consumer-database-restoration-service-group-3
simulation_2-database-restoration-service-1  | 	client.rack = 
simulation_2-database-restoration-service-1  | 	connections.max.idle.ms = 540000
simulation_2-database-restoration-service-1  | 	default.api.timeout.ms = 60000
simulation_2-database-restoration-service-1  | 	enable.auto.commit = false
simulation_2-database-restoration-service-1  | 	exclude.internal.topics = true
simulation_2-database-restoration-service-1  | 	fetch.max.bytes = 52428800
simulation_2-database-restoration-service-1  | 	fetch.max.wait.ms = 500
simulation_2-database-restoration-service-1  | 	fetch.min.bytes = 1
simulation_2-database-restoration-service-1  | 	group.id = database-restoration-service-group
simulation_2-database-restoration-service-1  | 	group.instance.id = null
simulation_2-database-restoration-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-database-restoration-service-1  | 	interceptor.classes = []
simulation_2-database-restoration-service-1  | 	internal.leave.group.on.close = true
simulation_2-database-restoration-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-database-restoration-service-1  | 	isolation.level = read_uncommitted
simulation_2-database-restoration-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-database-restoration-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-database-restoration-service-1  | 	max.poll.interval.ms = 90000
simulation_2-database-restoration-service-1  | 	max.poll.records = 500
simulation_2-database-restoration-service-1  | 	metadata.max.age.ms = 300000
simulation_2-database-restoration-service-1  | 	metric.reporters = []
simulation_2-database-restoration-service-1  | 	metrics.num.samples = 2
simulation_2-database-restoration-service-1  | 	metrics.recording.level = INFO
simulation_2-database-restoration-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-database-restoration-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-database-restoration-service-1  | 	receive.buffer.bytes = 65536
simulation_2-database-restoration-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-database-restoration-service-1  | 	reconnect.backoff.ms = 50
simulation_2-database-restoration-service-1  | 	request.timeout.ms = 30000
simulation_2-database-restoration-service-1  | 	retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.jaas.config = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-database-restoration-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-database-restoration-service-1  | 	sasl.kerberos.service.name = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-database-restoration-service-1  | 	security.protocol = PLAINTEXT
simulation_2-database-restoration-service-1  | 	security.providers = null
simulation_2-database-restoration-service-1  | 	send.buffer.bytes = 131072
simulation_2-database-restoration-service-1  | 	session.timeout.ms = 45000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-database-restoration-service-1  | 	ssl.cipher.suites = null
simulation_2-database-restoration-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-database-restoration-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-database-restoration-service-1  | 	ssl.engine.factory.class = null
simulation_2-database-restoration-service-1  | 	ssl.key.password = null
simulation_2-database-restoration-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-database-restoration-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.key = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.location = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.password = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.type = JKS
simulation_2-database-restoration-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-database-restoration-service-1  | 	ssl.provider = null
simulation_2-database-restoration-service-1  | 	ssl.secure.random.implementation = null
simulation_2-database-restoration-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-database-restoration-service-1  | 	ssl.truststore.certificates = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.location = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.password = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.type = JKS
simulation_2-database-restoration-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-database-restoration-service-1  | 
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.988Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.988Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.988Z  INFO 1 --- [database-restoration-service] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472932988
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:32.990Z  INFO 1 --- [database-restoration-service] [           main] fkaConsumerFactory$ExtendedKafkaConsumer : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Subscribed to topic(s): metadata-failure
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.006Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Cluster ID: SfQo8OGTSxO1CfeFL1N09Q
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.009Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Cluster ID: SfQo8OGTSxO1CfeFL1N09Q
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.009Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.037Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.097Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | 20:15:33,097 |-WARN in net.logstash.logback.appender.LogstashTcpSocketAppender[LOGSTASH] - Log destination logstash/<unresolved>:5001: connection failed. java.net.ConnectException: Connection refused
simulation_2-blueprint-service-1  | 	at java.net.ConnectException: Connection refused
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
simulation_2-blueprint-service-1  | 	at 	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597)
simulation_2-blueprint-service-1  | 	at 	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
simulation_2-blueprint-service-1  | 	at 	at java.base/java.net.Socket.connect(Socket.java:633)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.appender.AbstractLogstashTcpSocketAppender$TcpSendingEventHandler.openSocket(AbstractLogstashTcpSocketAppender.java:765)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.appender.AbstractLogstashTcpSocketAppender$TcpSendingEventHandler.onStart(AbstractLogstashTcpSocketAppender.java:691)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.appender.AsyncDisruptorAppender$EventClearingEventHandler.onStart(AsyncDisruptorAppender.java:382)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.encoder.com.lmax.disruptor.BatchEventProcessor.notifyStart(BatchEventProcessor.java:224)
simulation_2-blueprint-service-1  | 	at 	at net.logstash.logback.encoder.com.lmax.disruptor.BatchEventProcessor.run(BatchEventProcessor.java:120)
simulation_2-blueprint-service-1  | 	at 	at java.base/java.lang.Thread.run(Thread.java:833)
simulation_2-blueprint-service-1  | 20:15:33,098 |-WARN in net.logstash.logback.appender.LogstashTcpSocketAppender[LOGSTASH] - Log destination logstash/<unresolved>:5001: Waiting 29997ms before attempting reconnection.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.108Z  WARN 1 --- [database-restoration-service] [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Error while fetching metadata with correlation id 2 : {metadata-failure=LEADER_NOT_AVAILABLE}
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.109Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Cluster ID: SfQo8OGTSxO1CfeFL1N09Q
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.109Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.116Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.136Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Request joining group due to: need to re-join with the given member-id: consumer-database-restoration-service-group-2-75b3748a-35e6-475c-99ae-6a0aee9ed18d
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.137Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.137Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.137Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:33.142Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-metadata-extraction-service-group-1, groupId=metadata-extraction-service-group] Resetting offset for partition restore-success-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.143Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-database-restoration-service-group-2-75b3748a-35e6-475c-99ae-6a0aee9ed18d', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.148Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Finished assignment for group at generation 1: {consumer-database-restoration-service-group-2-75b3748a-35e6-475c-99ae-6a0aee9ed18d=Assignment(partitions=[created-worksheet-0])}
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.157Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Request joining group due to: need to re-join with the given member-id: consumer-database-restoration-service-group-3-b087a1e3-8545-4557-8f97-601d7977e35c
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.157Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.157Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.172Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=1, memberId='consumer-database-restoration-service-group-2-75b3748a-35e6-475c-99ae-6a0aee9ed18d', protocol='range'}
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:33.191Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : metadata-extraction-service-group: partitions assigned: [restore-success-0]
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.182Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Request joining group due to: need to re-join with the given member-id: consumer-database-restoration-service-group-1-60d53fb1-3657-4254-b83f-b5648a0114c1
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.199Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.202Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.203Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.203Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:33 [main] o.a.k.c.admin.AdminClientConfig - AdminClientConfig values: 
simulation_2-blueprint-service-1  | 	auto.include.jmx.reporter = true
simulation_2-blueprint-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-blueprint-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-blueprint-service-1  | 	client.id = 
simulation_2-blueprint-service-1  | 	connections.max.idle.ms = 300000
simulation_2-blueprint-service-1  | 	default.api.timeout.ms = 60000
simulation_2-blueprint-service-1  | 	metadata.max.age.ms = 300000
simulation_2-blueprint-service-1  | 	metric.reporters = []
simulation_2-blueprint-service-1  | 	metrics.num.samples = 2
simulation_2-blueprint-service-1  | 	metrics.recording.level = INFO
simulation_2-blueprint-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-blueprint-service-1  | 	receive.buffer.bytes = 65536
simulation_2-blueprint-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-blueprint-service-1  | 	reconnect.backoff.ms = 50
simulation_2-blueprint-service-1  | 	request.timeout.ms = 30000
simulation_2-blueprint-service-1  | 	retries = 2147483647
simulation_2-blueprint-service-1  | 	retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.jaas.config = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-blueprint-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-blueprint-service-1  | 	sasl.kerberos.service.name = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.login.class = null
simulation_2-blueprint-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-blueprint-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-blueprint-service-1  | 	security.protocol = PLAINTEXT
simulation_2-blueprint-service-1  | 	security.providers = null
simulation_2-blueprint-service-1  | 	send.buffer.bytes = 131072
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-blueprint-service-1  | 	ssl.cipher.suites = null
simulation_2-blueprint-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-blueprint-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-blueprint-service-1  | 	ssl.engine.factory.class = null
simulation_2-blueprint-service-1  | 	ssl.key.password = null
simulation_2-blueprint-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-blueprint-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-blueprint-service-1  | 	ssl.keystore.key = null
simulation_2-blueprint-service-1  | 	ssl.keystore.location = null
simulation_2-blueprint-service-1  | 	ssl.keystore.password = null
simulation_2-blueprint-service-1  | 	ssl.keystore.type = JKS
simulation_2-blueprint-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-blueprint-service-1  | 	ssl.provider = null
simulation_2-blueprint-service-1  | 	ssl.secure.random.implementation = null
simulation_2-blueprint-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-blueprint-service-1  | 	ssl.truststore.certificates = null
simulation_2-blueprint-service-1  | 	ssl.truststore.location = null
simulation_2-blueprint-service-1  | 	ssl.truststore.password = null
simulation_2-blueprint-service-1  | 	ssl.truststore.type = JKS
simulation_2-blueprint-service-1  | 
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.218Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-database-restoration-service-group-1-60d53fb1-3657-4254-b83f-b5648a0114c1', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.243Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-database-restoration-service-group-2-75b3748a-35e6-475c-99ae-6a0aee9ed18d', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.246Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-database-restoration-service-group-3-b087a1e3-8545-4557-8f97-601d7977e35c', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.252Z  INFO 1 --- [database-restoration-service] [           main] .d.DatabaseRestorationServiceApplication : Started DatabaseRestorationServiceApplication in 37.305 seconds (process running for 41.834)
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.260Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Finished assignment for group at generation 2: {consumer-database-restoration-service-group-1-60d53fb1-3657-4254-b83f-b5648a0114c1=Assignment(partitions=[created-blueprint-0]), consumer-database-restoration-service-group-2-75b3748a-35e6-475c-99ae-6a0aee9ed18d=Assignment(partitions=[created-worksheet-0]), consumer-database-restoration-service-group-3-b087a1e3-8545-4557-8f97-601d7977e35c=Assignment(partitions=[metadata-failure-0])}
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.277Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-database-restoration-service-group-1-60d53fb1-3657-4254-b83f-b5648a0114c1', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.277Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-database-restoration-service-group-2-75b3748a-35e6-475c-99ae-6a0aee9ed18d', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.277Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Notifying assignor about the new Assignment(partitions=[created-blueprint-0])
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.278Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Notifying assignor about the new Assignment(partitions=[created-worksheet-0])
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.280Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Adding newly assigned partitions: created-blueprint-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.280Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-database-restoration-service-group-3-b087a1e3-8545-4557-8f97-601d7977e35c', protocol='range'}
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.281Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Notifying assignor about the new Assignment(partitions=[metadata-failure-0])
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.281Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Adding newly assigned partitions: metadata-failure-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.284Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Found no committed offset for partition metadata-failure-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.285Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Adding newly assigned partitions: created-worksheet-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.289Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Found no committed offset for partition created-worksheet-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.290Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Found no committed offset for partition created-blueprint-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.290Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Found no committed offset for partition created-worksheet-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.290Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Found no committed offset for partition created-blueprint-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.292Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Found no committed offset for partition metadata-failure-0
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.297Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-database-restoration-service-group-2, groupId=database-restoration-service-group] Resetting offset for partition created-worksheet-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.305Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-database-restoration-service-group-3, groupId=database-restoration-service-group] Resetting offset for partition metadata-failure-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.322Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-database-restoration-service-group-1, groupId=database-restoration-service-group] Resetting offset for partition created-blueprint-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.332Z  INFO 1 --- [database-restoration-service] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : database-restoration-service-group: partitions assigned: [created-worksheet-0]
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.361Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : database-restoration-service-group: partitions assigned: [created-blueprint-0]
simulation_2-database-restoration-service-1  | 2024-01-28T20:15:33.365Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : database-restoration-service-group: partitions assigned: [metadata-failure-0]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:33 [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:33 [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 60e845626d8a465a
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:33 [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706472933641
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.admin.client for adminclient-1 unregistered
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [kafka-admin-client-thread | adminclient-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] o.s.c.n.eureka.InstanceInfoFactory - Setting initial instance status as: STARTING
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] c.netflix.discovery.DiscoveryClient - Initializing Eureka in region us-east-1
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] c.n.d.s.r.aws.ConfigClusterResolver - Resolving eureka endpoints via configuration
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] c.netflix.discovery.DiscoveryClient - Disable delta property : false
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] c.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] c.netflix.discovery.DiscoveryClient - Force full registry fetch : false
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] c.netflix.discovery.DiscoveryClient - Application is null : false
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] c.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] c.netflix.discovery.DiscoveryClient - Application version is -1: true
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] c.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] c.netflix.discovery.DiscoveryClient - The response status is 200
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] c.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] c.n.discovery.InstanceInfoReplicator - InstanceInfoReplicator onDemand update allowed rate per min is 4
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] c.netflix.discovery.DiscoveryClient - Discovery Client initialized at timestamp 1706472934722 with initial instances count: 2
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] o.s.c.n.e.s.EurekaServiceRegistry - Registering application BLUEPRINT-SERVICE with eureka with status UP
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] c.netflix.discovery.DiscoveryClient - Saw local status change event StatusChangeEvent [timestamp=1706472934754, current=UP, previous=STARTING]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [DiscoveryClient-InstanceInfoReplicator-0] c.netflix.discovery.DiscoveryClient - DiscoveryClient_BLUEPRINT-SERVICE/fe10a847b0fe:blueprint-service:8100: registering service...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] o.a.coyote.http11.Http11NioProtocol - Starting ProtocolHandler ["http-nio-8100"]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [DiscoveryClient-InstanceInfoReplicator-0] c.netflix.discovery.DiscoveryClient - DiscoveryClient_BLUEPRINT-SERVICE/fe10a847b0fe:blueprint-service:8100 - registration status: 204
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] o.s.b.w.e.tomcat.TomcatWebServer - Tomcat started on port 8100 (http) with context path ''
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:34 [main] o.s.c.n.e.s.EurekaAutoServiceRegistration - Updating port to 8100
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
simulation_2-blueprint-service-1  | 	allow.auto.create.topics = true
simulation_2-blueprint-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-blueprint-service-1  | 	auto.include.jmx.reporter = true
simulation_2-blueprint-service-1  | 	auto.offset.reset = latest
simulation_2-blueprint-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-blueprint-service-1  | 	check.crcs = true
simulation_2-blueprint-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-blueprint-service-1  | 	client.id = consumer-blueprint-service-group-1
simulation_2-blueprint-service-1  | 	client.rack = 
simulation_2-blueprint-service-1  | 	connections.max.idle.ms = 540000
simulation_2-blueprint-service-1  | 	default.api.timeout.ms = 60000
simulation_2-blueprint-service-1  | 	enable.auto.commit = false
simulation_2-blueprint-service-1  | 	exclude.internal.topics = true
simulation_2-blueprint-service-1  | 	fetch.max.bytes = 52428800
simulation_2-blueprint-service-1  | 	fetch.max.wait.ms = 500
simulation_2-blueprint-service-1  | 	fetch.min.bytes = 1
simulation_2-blueprint-service-1  | 	group.id = blueprint-service-group
simulation_2-blueprint-service-1  | 	group.instance.id = null
simulation_2-blueprint-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-blueprint-service-1  | 	interceptor.classes = []
simulation_2-blueprint-service-1  | 	internal.leave.group.on.close = true
simulation_2-blueprint-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-blueprint-service-1  | 	isolation.level = read_uncommitted
simulation_2-blueprint-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-blueprint-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-blueprint-service-1  | 	max.poll.interval.ms = 90000
simulation_2-blueprint-service-1  | 	max.poll.records = 500
simulation_2-blueprint-service-1  | 	metadata.max.age.ms = 300000
simulation_2-blueprint-service-1  | 	metric.reporters = []
simulation_2-blueprint-service-1  | 	metrics.num.samples = 2
simulation_2-blueprint-service-1  | 	metrics.recording.level = INFO
simulation_2-blueprint-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-blueprint-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-blueprint-service-1  | 	receive.buffer.bytes = 65536
simulation_2-blueprint-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-blueprint-service-1  | 	reconnect.backoff.ms = 50
simulation_2-blueprint-service-1  | 	request.timeout.ms = 30000
simulation_2-blueprint-service-1  | 	retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.jaas.config = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-blueprint-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-blueprint-service-1  | 	sasl.kerberos.service.name = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.login.class = null
simulation_2-blueprint-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-blueprint-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-blueprint-service-1  | 	security.protocol = PLAINTEXT
simulation_2-blueprint-service-1  | 	security.providers = null
simulation_2-blueprint-service-1  | 	send.buffer.bytes = 131072
simulation_2-blueprint-service-1  | 	session.timeout.ms = 45000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-blueprint-service-1  | 	ssl.cipher.suites = null
simulation_2-blueprint-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-blueprint-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-blueprint-service-1  | 	ssl.engine.factory.class = null
simulation_2-blueprint-service-1  | 	ssl.key.password = null
simulation_2-blueprint-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-blueprint-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-blueprint-service-1  | 	ssl.keystore.key = null
simulation_2-blueprint-service-1  | 	ssl.keystore.location = null
simulation_2-blueprint-service-1  | 	ssl.keystore.password = null
simulation_2-blueprint-service-1  | 	ssl.keystore.type = JKS
simulation_2-blueprint-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-blueprint-service-1  | 	ssl.provider = null
simulation_2-blueprint-service-1  | 	ssl.secure.random.implementation = null
simulation_2-blueprint-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-blueprint-service-1  | 	ssl.truststore.certificates = null
simulation_2-blueprint-service-1  | 	ssl.truststore.location = null
simulation_2-blueprint-service-1  | 	ssl.truststore.password = null
simulation_2-blueprint-service-1  | 	ssl.truststore.type = JKS
simulation_2-blueprint-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-blueprint-service-1  | 
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 60e845626d8a465a
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706472935100
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.s.k.c.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Subscribed to topic(s): metadata-success
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
simulation_2-blueprint-service-1  | 	allow.auto.create.topics = true
simulation_2-blueprint-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-blueprint-service-1  | 	auto.include.jmx.reporter = true
simulation_2-blueprint-service-1  | 	auto.offset.reset = latest
simulation_2-blueprint-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-blueprint-service-1  | 	check.crcs = true
simulation_2-blueprint-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-blueprint-service-1  | 	client.id = consumer-blueprint-service-group-2
simulation_2-blueprint-service-1  | 	client.rack = 
simulation_2-blueprint-service-1  | 	connections.max.idle.ms = 540000
simulation_2-blueprint-service-1  | 	default.api.timeout.ms = 60000
simulation_2-blueprint-service-1  | 	enable.auto.commit = false
simulation_2-blueprint-service-1  | 	exclude.internal.topics = true
simulation_2-blueprint-service-1  | 	fetch.max.bytes = 52428800
simulation_2-blueprint-service-1  | 	fetch.max.wait.ms = 500
simulation_2-blueprint-service-1  | 	fetch.min.bytes = 1
simulation_2-blueprint-service-1  | 	group.id = blueprint-service-group
simulation_2-blueprint-service-1  | 	group.instance.id = null
simulation_2-blueprint-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-blueprint-service-1  | 	interceptor.classes = []
simulation_2-blueprint-service-1  | 	internal.leave.group.on.close = true
simulation_2-blueprint-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-blueprint-service-1  | 	isolation.level = read_uncommitted
simulation_2-blueprint-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-blueprint-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-blueprint-service-1  | 	max.poll.interval.ms = 90000
simulation_2-blueprint-service-1  | 	max.poll.records = 500
simulation_2-blueprint-service-1  | 	metadata.max.age.ms = 300000
simulation_2-blueprint-service-1  | 	metric.reporters = []
simulation_2-blueprint-service-1  | 	metrics.num.samples = 2
simulation_2-blueprint-service-1  | 	metrics.recording.level = INFO
simulation_2-blueprint-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-blueprint-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-blueprint-service-1  | 	receive.buffer.bytes = 65536
simulation_2-blueprint-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-blueprint-service-1  | 	reconnect.backoff.ms = 50
simulation_2-blueprint-service-1  | 	request.timeout.ms = 30000
simulation_2-blueprint-service-1  | 	retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.jaas.config = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-blueprint-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-blueprint-service-1  | 	sasl.kerberos.service.name = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.login.class = null
simulation_2-blueprint-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-blueprint-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-blueprint-service-1  | 	security.protocol = PLAINTEXT
simulation_2-blueprint-service-1  | 	security.providers = null
simulation_2-blueprint-service-1  | 	send.buffer.bytes = 131072
simulation_2-blueprint-service-1  | 	session.timeout.ms = 45000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-blueprint-service-1  | 	ssl.cipher.suites = null
simulation_2-blueprint-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-blueprint-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-blueprint-service-1  | 	ssl.engine.factory.class = null
simulation_2-blueprint-service-1  | 	ssl.key.password = null
simulation_2-blueprint-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-blueprint-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-blueprint-service-1  | 	ssl.keystore.key = null
simulation_2-blueprint-service-1  | 	ssl.keystore.location = null
simulation_2-blueprint-service-1  | 	ssl.keystore.password = null
simulation_2-blueprint-service-1  | 	ssl.keystore.type = JKS
simulation_2-blueprint-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-blueprint-service-1  | 	ssl.provider = null
simulation_2-blueprint-service-1  | 	ssl.secure.random.implementation = null
simulation_2-blueprint-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-blueprint-service-1  | 	ssl.truststore.certificates = null
simulation_2-blueprint-service-1  | 	ssl.truststore.location = null
simulation_2-blueprint-service-1  | 	ssl.truststore.password = null
simulation_2-blueprint-service-1  | 	ssl.truststore.type = JKS
simulation_2-blueprint-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-blueprint-service-1  | 
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 60e845626d8a465a
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706472935155
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Error while fetching metadata with correlation id 2 : {metadata-success=LEADER_NOT_AVAILABLE}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Cluster ID: SfQo8OGTSxO1CfeFL1N09Q
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.s.k.c.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Subscribed to topic(s): metadata-failure
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
simulation_2-blueprint-service-1  | 	allow.auto.create.topics = true
simulation_2-blueprint-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-blueprint-service-1  | 	auto.include.jmx.reporter = true
simulation_2-blueprint-service-1  | 	auto.offset.reset = latest
simulation_2-blueprint-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-blueprint-service-1  | 	check.crcs = true
simulation_2-blueprint-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-blueprint-service-1  | 	client.id = consumer-blueprint-service-group-3
simulation_2-blueprint-service-1  | 	client.rack = 
simulation_2-blueprint-service-1  | 	connections.max.idle.ms = 540000
simulation_2-blueprint-service-1  | 	default.api.timeout.ms = 60000
simulation_2-blueprint-service-1  | 	enable.auto.commit = false
simulation_2-blueprint-service-1  | 	exclude.internal.topics = true
simulation_2-blueprint-service-1  | 	fetch.max.bytes = 52428800
simulation_2-blueprint-service-1  | 	fetch.max.wait.ms = 500
simulation_2-blueprint-service-1  | 	fetch.min.bytes = 1
simulation_2-blueprint-service-1  | 	group.id = blueprint-service-group
simulation_2-blueprint-service-1  | 	group.instance.id = null
simulation_2-blueprint-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-blueprint-service-1  | 	interceptor.classes = []
simulation_2-blueprint-service-1  | 	internal.leave.group.on.close = true
simulation_2-blueprint-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-blueprint-service-1  | 	isolation.level = read_uncommitted
simulation_2-blueprint-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-blueprint-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-blueprint-service-1  | 	max.poll.interval.ms = 90000
simulation_2-blueprint-service-1  | 	max.poll.records = 500
simulation_2-blueprint-service-1  | 	metadata.max.age.ms = 300000
simulation_2-blueprint-service-1  | 	metric.reporters = []
simulation_2-blueprint-service-1  | 	metrics.num.samples = 2
simulation_2-blueprint-service-1  | 	metrics.recording.level = INFO
simulation_2-blueprint-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-blueprint-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-blueprint-service-1  | 	receive.buffer.bytes = 65536
simulation_2-blueprint-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-blueprint-service-1  | 	reconnect.backoff.ms = 50
simulation_2-blueprint-service-1  | 	request.timeout.ms = 30000
simulation_2-blueprint-service-1  | 	retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.jaas.config = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-blueprint-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-blueprint-service-1  | 	sasl.kerberos.service.name = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.login.class = null
simulation_2-blueprint-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-blueprint-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-blueprint-service-1  | 	security.protocol = PLAINTEXT
simulation_2-blueprint-service-1  | 	security.providers = null
simulation_2-blueprint-service-1  | 	send.buffer.bytes = 131072
simulation_2-blueprint-service-1  | 	session.timeout.ms = 45000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-blueprint-service-1  | 	ssl.cipher.suites = null
simulation_2-blueprint-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-blueprint-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-blueprint-service-1  | 	ssl.engine.factory.class = null
simulation_2-blueprint-service-1  | 	ssl.key.password = null
simulation_2-blueprint-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-blueprint-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-blueprint-service-1  | 	ssl.keystore.key = null
simulation_2-blueprint-service-1  | 	ssl.keystore.location = null
simulation_2-blueprint-service-1  | 	ssl.keystore.password = null
simulation_2-blueprint-service-1  | 	ssl.keystore.type = JKS
simulation_2-blueprint-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-blueprint-service-1  | 	ssl.provider = null
simulation_2-blueprint-service-1  | 	ssl.secure.random.implementation = null
simulation_2-blueprint-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-blueprint-service-1  | 	ssl.truststore.certificates = null
simulation_2-blueprint-service-1  | 	ssl.truststore.location = null
simulation_2-blueprint-service-1  | 	ssl.truststore.password = null
simulation_2-blueprint-service-1  | 	ssl.truststore.type = JKS
simulation_2-blueprint-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-blueprint-service-1  | 
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 60e845626d8a465a
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706472935184
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.s.k.c.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Subscribed to topic(s): restore-success
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Cluster ID: SfQo8OGTSxO1CfeFL1N09Q
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
simulation_2-blueprint-service-1  | 	allow.auto.create.topics = true
simulation_2-blueprint-service-1  | 	auto.commit.interval.ms = 5000
simulation_2-blueprint-service-1  | 	auto.include.jmx.reporter = true
simulation_2-blueprint-service-1  | 	auto.offset.reset = latest
simulation_2-blueprint-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-blueprint-service-1  | 	check.crcs = true
simulation_2-blueprint-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-blueprint-service-1  | 	client.id = consumer-blueprint-service-group-4
simulation_2-blueprint-service-1  | 	client.rack = 
simulation_2-blueprint-service-1  | 	connections.max.idle.ms = 540000
simulation_2-blueprint-service-1  | 	default.api.timeout.ms = 60000
simulation_2-blueprint-service-1  | 	enable.auto.commit = false
simulation_2-blueprint-service-1  | 	exclude.internal.topics = true
simulation_2-blueprint-service-1  | 	fetch.max.bytes = 52428800
simulation_2-blueprint-service-1  | 	fetch.max.wait.ms = 500
simulation_2-blueprint-service-1  | 	fetch.min.bytes = 1
simulation_2-blueprint-service-1  | 	group.id = blueprint-service-group
simulation_2-blueprint-service-1  | 	group.instance.id = null
simulation_2-blueprint-service-1  | 	heartbeat.interval.ms = 3000
simulation_2-blueprint-service-1  | 	interceptor.classes = []
simulation_2-blueprint-service-1  | 	internal.leave.group.on.close = true
simulation_2-blueprint-service-1  | 	internal.throw.on.fetch.stable.offset.unsupported = false
simulation_2-blueprint-service-1  | 	isolation.level = read_uncommitted
simulation_2-blueprint-service-1  | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
simulation_2-blueprint-service-1  | 	max.partition.fetch.bytes = 1048576
simulation_2-blueprint-service-1  | 	max.poll.interval.ms = 90000
simulation_2-blueprint-service-1  | 	max.poll.records = 500
simulation_2-blueprint-service-1  | 	metadata.max.age.ms = 300000
simulation_2-blueprint-service-1  | 	metric.reporters = []
simulation_2-blueprint-service-1  | 	metrics.num.samples = 2
simulation_2-blueprint-service-1  | 	metrics.recording.level = INFO
simulation_2-blueprint-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-blueprint-service-1  | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
simulation_2-blueprint-service-1  | 	receive.buffer.bytes = 65536
simulation_2-blueprint-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-blueprint-service-1  | 	reconnect.backoff.ms = 50
simulation_2-blueprint-service-1  | 	request.timeout.ms = 30000
simulation_2-blueprint-service-1  | 	retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.jaas.config = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-blueprint-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-blueprint-service-1  | 	sasl.kerberos.service.name = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.login.class = null
simulation_2-blueprint-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-blueprint-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-blueprint-service-1  | 	security.protocol = PLAINTEXT
simulation_2-blueprint-service-1  | 	security.providers = null
simulation_2-blueprint-service-1  | 	send.buffer.bytes = 131072
simulation_2-blueprint-service-1  | 	session.timeout.ms = 45000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-blueprint-service-1  | 	ssl.cipher.suites = null
simulation_2-blueprint-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-blueprint-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-blueprint-service-1  | 	ssl.engine.factory.class = null
simulation_2-blueprint-service-1  | 	ssl.key.password = null
simulation_2-blueprint-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-blueprint-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-blueprint-service-1  | 	ssl.keystore.key = null
simulation_2-blueprint-service-1  | 	ssl.keystore.location = null
simulation_2-blueprint-service-1  | 	ssl.keystore.password = null
simulation_2-blueprint-service-1  | 	ssl.keystore.type = JKS
simulation_2-blueprint-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-blueprint-service-1  | 	ssl.provider = null
simulation_2-blueprint-service-1  | 	ssl.secure.random.implementation = null
simulation_2-blueprint-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-blueprint-service-1  | 	ssl.truststore.certificates = null
simulation_2-blueprint-service-1  | 	ssl.truststore.location = null
simulation_2-blueprint-service-1  | 	ssl.truststore.password = null
simulation_2-blueprint-service-1  | 	ssl.truststore.type = JKS
simulation_2-blueprint-service-1  | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
simulation_2-blueprint-service-1  | 
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 60e845626d8a465a
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706472935235
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] o.s.k.c.DefaultKafkaConsumerFactory$ExtendedKafkaConsumer - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Subscribed to topic(s): restore-failure
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Request joining group due to: need to re-join with the given member-id: consumer-blueprint-service-group-2-4a10a2a9-bfbd-443a-8e8d-7c6ee4be2788
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Request joining group due to: need to re-join with the given member-id: consumer-blueprint-service-group-1-1d1fe99c-3944-45a9-84bd-ef9a3767b1ac
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-blueprint-service-group-2-4a10a2a9-bfbd-443a-8e8d-7c6ee4be2788', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Finished assignment for group at generation 1: {consumer-blueprint-service-group-2-4a10a2a9-bfbd-443a-8e8d-7c6ee4be2788=Assignment(partitions=[metadata-failure-0])}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Cluster ID: SfQo8OGTSxO1CfeFL1N09Q
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=1, memberId='consumer-blueprint-service-group-2-4a10a2a9-bfbd-443a-8e8d-7c6ee4be2788', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Request joining group due to: rebalance failed due to 'The group is rebalancing, so a rejoin is needed.' (RebalanceInProgressException)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-blueprint-service-group-2-4a10a2a9-bfbd-443a-8e8d-7c6ee4be2788', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Finished assignment for group at generation 2: {consumer-blueprint-service-group-1-1d1fe99c-3944-45a9-84bd-ef9a3767b1ac=Assignment(partitions=[metadata-success-0]), consumer-blueprint-service-group-2-4a10a2a9-bfbd-443a-8e8d-7c6ee4be2788=Assignment(partitions=[metadata-failure-0])}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-blueprint-service-group-2-4a10a2a9-bfbd-443a-8e8d-7c6ee4be2788', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Notifying assignor about the new Assignment(partitions=[metadata-failure-0])
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Adding newly assigned partitions: metadata-failure-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Found no committed offset for partition metadata-failure-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Found no committed offset for partition metadata-failure-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Resetting offset for partition metadata-failure-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - blueprint-service-group: partitions assigned: [metadata-failure-0]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Successfully joined group with generation Generation{generationId=2, memberId='consumer-blueprint-service-group-1-1d1fe99c-3944-45a9-84bd-ef9a3767b1ac', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Successfully synced group in generation Generation{generationId=2, memberId='consumer-blueprint-service-group-1-1d1fe99c-3944-45a9-84bd-ef9a3767b1ac', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Request joining group due to: need to re-join with the given member-id: consumer-blueprint-service-group-3-26ff1394-0165-420c-af59-7472f06644fe
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Notifying assignor about the new Assignment(partitions=[metadata-success-0])
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Adding newly assigned partitions: metadata-success-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Found no committed offset for partition metadata-success-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Found no committed offset for partition metadata-success-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Resetting offset for partition metadata-success-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Cluster ID: SfQo8OGTSxO1CfeFL1N09Q
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Discovered group coordinator kafka:9093 (id: 2147482646 rack: null)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - blueprint-service-group: partitions assigned: [metadata-success-0]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Request joining group due to: need to re-join with the given member-id: consumer-blueprint-service-group-4-eb225dcc-4c8a-4a10-91a6-3dde61054917
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:35 [main] c.w.a.b.BlueprintServiceApplication - Started BlueprintServiceApplication in 38.052 seconds (process running for 43.318)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:37 [http-nio-8100-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] - Initializing Spring DispatcherServlet 'dispatcherServlet'
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:37 [http-nio-8100-exec-1] o.s.web.servlet.DispatcherServlet - Initializing Servlet 'dispatcherServlet'
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:37 [http-nio-8100-exec-1] o.s.web.servlet.DispatcherServlet - Completed initialization in 6 ms
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Request joining group due to: group is already rebalancing
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Revoke previously assigned partitions metadata-failure-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - blueprint-service-group: partitions revoked: [metadata-failure-0]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Request joining group due to: group is already rebalancing
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Revoke previously assigned partitions metadata-success-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - blueprint-service-group: partitions revoked: [metadata-success-0]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] (Re-)joining group
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Successfully joined group with generation Generation{generationId=3, memberId='consumer-blueprint-service-group-4-eb225dcc-4c8a-4a10-91a6-3dde61054917', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Successfully joined group with generation Generation{generationId=3, memberId='consumer-blueprint-service-group-2-4a10a2a9-bfbd-443a-8e8d-7c6ee4be2788', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Successfully joined group with generation Generation{generationId=3, memberId='consumer-blueprint-service-group-3-26ff1394-0165-420c-af59-7472f06644fe', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Successfully joined group with generation Generation{generationId=3, memberId='consumer-blueprint-service-group-1-1d1fe99c-3944-45a9-84bd-ef9a3767b1ac', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Finished assignment for group at generation 3: {consumer-blueprint-service-group-1-1d1fe99c-3944-45a9-84bd-ef9a3767b1ac=Assignment(partitions=[metadata-success-0]), consumer-blueprint-service-group-2-4a10a2a9-bfbd-443a-8e8d-7c6ee4be2788=Assignment(partitions=[metadata-failure-0]), consumer-blueprint-service-group-3-26ff1394-0165-420c-af59-7472f06644fe=Assignment(partitions=[restore-success-0]), consumer-blueprint-service-group-4-eb225dcc-4c8a-4a10-91a6-3dde61054917=Assignment(partitions=[restore-failure-0])}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Successfully synced group in generation Generation{generationId=3, memberId='consumer-blueprint-service-group-4-eb225dcc-4c8a-4a10-91a6-3dde61054917', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Notifying assignor about the new Assignment(partitions=[restore-failure-0])
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Adding newly assigned partitions: restore-failure-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Successfully synced group in generation Generation{generationId=3, memberId='consumer-blueprint-service-group-1-1d1fe99c-3944-45a9-84bd-ef9a3767b1ac', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Notifying assignor about the new Assignment(partitions=[metadata-success-0])
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Adding newly assigned partitions: metadata-success-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Successfully synced group in generation Generation{generationId=3, memberId='consumer-blueprint-service-group-3-26ff1394-0165-420c-af59-7472f06644fe', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Notifying assignor about the new Assignment(partitions=[restore-success-0])
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Adding newly assigned partitions: restore-success-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Found no committed offset for partition restore-failure-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Found no committed offset for partition restore-success-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Found no committed offset for partition restore-failure-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Found no committed offset for partition restore-success-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-1, groupId=blueprint-service-group] Setting offset for partition metadata-success-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - blueprint-service-group: partitions assigned: [metadata-success-0]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-blueprint-service-group-4, groupId=blueprint-service-group] Resetting offset for partition restore-failure-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Successfully synced group in generation Generation{generationId=3, memberId='consumer-blueprint-service-group-2-4a10a2a9-bfbd-443a-8e8d-7c6ee4be2788', protocol='range'}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Notifying assignor about the new Assignment(partitions=[metadata-failure-0])
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Adding newly assigned partitions: metadata-failure-0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-blueprint-service-group-3, groupId=blueprint-service-group] Resetting offset for partition restore-success-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-blueprint-service-group-2, groupId=blueprint-service-group] Setting offset for partition metadata-failure-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9093 (id: 1001 rack: null)], epoch=0}}
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - blueprint-service-group: partitions assigned: [metadata-failure-0]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - blueprint-service-group: partitions assigned: [restore-success-0]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:15:38 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - blueprint-service-group: partitions assigned: [restore-failure-0]
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:59.421Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:59.422Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:59.423Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:59.423Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Application is null : false
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:59.423Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:59.423Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:59.423Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:15:59.454Z  INFO 1 --- [metadata-extraction-service] [freshExecutor-0] com.netflix.discovery.DiscoveryClient    : The response status is 200
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:46:00.038659966
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:23 [http-nio-8100-exec-1] c.w.a.logging.LoggingFilter - -----> Request: POST /api/v1/importing/start, headers=[user-agent:"curl/8.1.2", accept:"*/*", content-length:"3584", forwarded:"proto=http;host="localhost:8080";for="192.168.128.1:42774"", x-forwarded-for:"192.168.128.1", x-forwarded-proto:"http", x-forwarded-port:"8080", x-forwarded-host:"localhost:8080", host:"fe10a847b0fe:8100", Content-Type:"multipart/form-data;boundary=------------------------5cfd3ca95dac8c59;charset=UTF-8"]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:23 [http-nio-8100-exec-1] c.w.a.logging.LoggingFilter - <----- Response (HTTP 202 Accepted): f462d216-8745-45d8-82d6-ebd180677d94
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:23 [ForkJoinPool.commonPool-worker-1] c.w.a.b.a.o.p.d.DumpRepositoryS3Adapter - Uploading Dump to S3... Blueprint : Blueprint(blueprintId=f462d216-8745-45d8-82d6-ebd180677d94, dumpFile=org.springframework.web.multipart.support.StandardMultipartHttpServletRequest$StandardMultipartFile@6f7344d0, blueprintSagaStatus=INITIALISED, restoreMode=SCRIPT, databaseType=POSTGRESQL, title=Employees, dumpStoreSuccess=false, description=This is just a sample dump of employees database made in a SCRIPT mode., createdDate=2024-01-28T20:16:23.433429713, originalDumpName=employeesdb_script.sql)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:23 [http-nio-8100-exec-2] c.w.a.logging.LoggingFilter - -----> Request: GET /api/v1/blueprints?blueprint_id=f462d216-8745-45d8-82d6-ebd180677d94, headers=[user-agent:"curl/8.1.2", accept:"*/*", forwarded:"proto=http;host="localhost:8080";for="192.168.128.1:42784"", x-forwarded-for:"192.168.128.1", x-forwarded-proto:"http", x-forwarded-port:"8080", x-forwarded-host:"localhost:8080", host:"fe10a847b0fe:8100", content-length:"0"]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:23 [http-nio-8100-exec-2] c.w.a.logging.LoggingFilter - <----- Response (HTTP 200 OK):
simulation_2-blueprint-service-1  | {
simulation_2-blueprint-service-1  |   "blueprintId" : "f462d216-8745-45d8-82d6-ebd180677d94",
simulation_2-blueprint-service-1  |   "blueprintSagaStatus" : "INITIALISED",
simulation_2-blueprint-service-1  |   "restoreMode" : "SCRIPT",
simulation_2-blueprint-service-1  |   "databaseType" : "POSTGRESQL",
simulation_2-blueprint-service-1  |   "title" : "Employees",
simulation_2-blueprint-service-1  |   "dumpStoreSuccess" : false,
simulation_2-blueprint-service-1  |   "description" : "This is just a sample dump of employees database made in a SCRIPT mode.",
simulation_2-blueprint-service-1  |   "createdDate" : "2024-01-28T20:16:23.433",
simulation_2-blueprint-service-1  |   "originalDumpName" : "employeesdb_script.sql"
simulation_2-blueprint-service-1  | }
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:16:23 [ForkJoinPool.commonPool-worker-1] s.a.a.h.a.internal.utils.ApacheUtils - NoSuchMethodException was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:24 [ForkJoinPool.commonPool-worker-1] c.w.a.s.impl.LoggingKafkaTemplate - Publishing to Kafka | Topic: created-blueprint | Value: BlueprintCreatedEvent(blueprintId=f462d216-8745-45d8-82d6-ebd180677d94, restoreMode=SCRIPT)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:24 [ForkJoinPool.commonPool-worker-1] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
simulation_2-blueprint-service-1  | 	acks = -1
simulation_2-blueprint-service-1  | 	auto.include.jmx.reporter = true
simulation_2-blueprint-service-1  | 	batch.size = 16384
simulation_2-blueprint-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-blueprint-service-1  | 	buffer.memory = 33554432
simulation_2-blueprint-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-blueprint-service-1  | 	client.id = producer-1
simulation_2-blueprint-service-1  | 	compression.type = none
simulation_2-blueprint-service-1  | 	connections.max.idle.ms = 540000
simulation_2-blueprint-service-1  | 	delivery.timeout.ms = 120000
simulation_2-blueprint-service-1  | 	enable.idempotence = true
simulation_2-blueprint-service-1  | 	interceptor.classes = []
simulation_2-blueprint-service-1  | 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
simulation_2-blueprint-service-1  | 	linger.ms = 0
simulation_2-blueprint-service-1  | 	max.block.ms = 60000
simulation_2-blueprint-service-1  | 	max.in.flight.requests.per.connection = 5
simulation_2-blueprint-service-1  | 	max.request.size = 1048576
simulation_2-blueprint-service-1  | 	metadata.max.age.ms = 300000
simulation_2-blueprint-service-1  | 	metadata.max.idle.ms = 300000
simulation_2-blueprint-service-1  | 	metric.reporters = []
simulation_2-blueprint-service-1  | 	metrics.num.samples = 2
simulation_2-blueprint-service-1  | 	metrics.recording.level = INFO
simulation_2-blueprint-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-blueprint-service-1  | 	partitioner.adaptive.partitioning.enable = true
simulation_2-blueprint-service-1  | 	partitioner.availability.timeout.ms = 0
simulation_2-blueprint-service-1  | 	partitioner.class = null
simulation_2-blueprint-service-1  | 	partitioner.ignore.keys = false
simulation_2-blueprint-service-1  | 	receive.buffer.bytes = 32768
simulation_2-blueprint-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-blueprint-service-1  | 	reconnect.backoff.ms = 50
simulation_2-blueprint-service-1  | 	request.timeout.ms = 30000
simulation_2-blueprint-service-1  | 	retries = 2147483647
simulation_2-blueprint-service-1  | 	retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.jaas.config = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-blueprint-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-blueprint-service-1  | 	sasl.kerberos.service.name = null
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-blueprint-service-1  | 	sasl.login.class = null
simulation_2-blueprint-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-blueprint-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-blueprint-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-blueprint-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-blueprint-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-blueprint-service-1  | 	security.protocol = PLAINTEXT
simulation_2-blueprint-service-1  | 	security.providers = null
simulation_2-blueprint-service-1  | 	send.buffer.bytes = 131072
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-blueprint-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-blueprint-service-1  | 	ssl.cipher.suites = null
simulation_2-blueprint-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-blueprint-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-blueprint-service-1  | 	ssl.engine.factory.class = null
simulation_2-blueprint-service-1  | 	ssl.key.password = null
simulation_2-blueprint-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-blueprint-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-blueprint-service-1  | 	ssl.keystore.key = null
simulation_2-blueprint-service-1  | 	ssl.keystore.location = null
simulation_2-blueprint-service-1  | 	ssl.keystore.password = null
simulation_2-blueprint-service-1  | 	ssl.keystore.type = JKS
simulation_2-blueprint-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-blueprint-service-1  | 	ssl.provider = null
simulation_2-blueprint-service-1  | 	ssl.secure.random.implementation = null
simulation_2-blueprint-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-blueprint-service-1  | 	ssl.truststore.certificates = null
simulation_2-blueprint-service-1  | 	ssl.truststore.location = null
simulation_2-blueprint-service-1  | 	ssl.truststore.password = null
simulation_2-blueprint-service-1  | 	ssl.truststore.type = JKS
simulation_2-blueprint-service-1  | 	transaction.timeout.ms = 60000
simulation_2-blueprint-service-1  | 	transactional.id = null
simulation_2-blueprint-service-1  | 	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
simulation_2-blueprint-service-1  | 
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:24 [ForkJoinPool.commonPool-worker-1] o.a.k.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:24 [ForkJoinPool.commonPool-worker-1] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.6.0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:24 [ForkJoinPool.commonPool-worker-1] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: 60e845626d8a465a
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:24 [ForkJoinPool.commonPool-worker-1] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1706472984236
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:24 [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: SfQo8OGTSxO1CfeFL1N09Q
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:24 [kafka-producer-network-thread | producer-1] o.a.k.c.p.i.TransactionManager - [Producer clientId=producer-1] ProducerId set to 0 with epoch 0
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:24.364Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] .a.d.a.i.m.BlueprintCreatedKafkaListener : Received BlueprintCreatedEvent(blueprintId=f462d216-8745-45d8-82d6-ebd180677d94, restoreMode=SCRIPT)
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:24.366Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] .a.d.a.o.d.p.PostgresDropDatabaseAdapter : Dropping database f462d216-8745-45d8-82d6-ebd180677d94
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:24.449Z  INFO 1 --- [database-restoration-service] [       Thread-3] .a.d.a.o.d.p.PostgresDropDatabaseAdapter : NOTICE:  database "f462d216-8745-45d8-82d6-ebd180677d94" does not exist, skipping
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:24.451Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] .a.d.a.o.d.p.PostgresDropDatabaseAdapter : Successfully dropped database f462d216-8745-45d8-82d6-ebd180677d94 using command [dropdb, -h, postgres, -p, 5432, -U, postgres, --no-password, --if-exists, f462d216-8745-45d8-82d6-ebd180677d94]
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:24.451Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] .d.a.o.d.p.PostgresCreateDatabaseAdapter : Creating database f462d216-8745-45d8-82d6-ebd180677d94
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:24.547Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] .d.a.o.d.p.PostgresCreateDatabaseAdapter : Successfully created database f462d216-8745-45d8-82d6-ebd180677d94 using command [createdb, -h, postgres, -p, 5432, -U, postgres, --no-password, -T, template0, f462d216-8745-45d8-82d6-ebd180677d94]
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:24.547Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] d.a.o.d.p.PostgresRestoreDatabaseAdapter : Restoring database f462d216-8745-45d8-82d6-ebd180677d94 from script
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:24.683Z  WARN 1 --- [database-restoration-service] [ntainer#2-0-C-1] s.a.a.h.a.internal.utils.ApacheUtils     : NoSuchMethodException was thrown when disabling normalizeUri. This indicates you are using an old version (< 4.5.8) of Apache http client. It is recommended to use http client version >= 4.5.9 to avoid the breaking change introduced in apache client 4.5.7 and the latency in exception handling. See https://github.com/aws/aws-sdk-java/issues/1919 for more information
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:24 [http-nio-8100-exec-3] c.w.a.logging.LoggingFilter - -----> Request: GET /api/v1/blueprints?blueprint_id=f462d216-8745-45d8-82d6-ebd180677d94, headers=[user-agent:"curl/8.1.2", accept:"*/*", forwarded:"proto=http;host="localhost:8080";for="192.168.128.1:42788"", x-forwarded-for:"192.168.128.1", x-forwarded-proto:"http", x-forwarded-port:"8080", x-forwarded-host:"localhost:8080", host:"fe10a847b0fe:8100", content-length:"0"]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:24 [http-nio-8100-exec-3] c.w.a.logging.LoggingFilter - <----- Response (HTTP 200 OK):
simulation_2-blueprint-service-1  | {
simulation_2-blueprint-service-1  |   "blueprintId" : "f462d216-8745-45d8-82d6-ebd180677d94",
simulation_2-blueprint-service-1  |   "blueprintSagaStatus" : "DUMP_STORE_SUCCESS",
simulation_2-blueprint-service-1  |   "restoreMode" : "SCRIPT",
simulation_2-blueprint-service-1  |   "databaseType" : "POSTGRESQL",
simulation_2-blueprint-service-1  |   "title" : "Employees",
simulation_2-blueprint-service-1  |   "dumpStoreSuccess" : true,
simulation_2-blueprint-service-1  |   "description" : "This is just a sample dump of employees database made in a SCRIPT mode.",
simulation_2-blueprint-service-1  |   "createdDate" : "2024-01-28T20:16:23.433",
simulation_2-blueprint-service-1  |   "originalDumpName" : "employeesdb_script.sql"
simulation_2-blueprint-service-1  | }
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.108Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.108Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- PostgreSQL database dump
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.108Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.108Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Dumped from database version 14.7 (Homebrew)
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.108Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Dumped by pg_dump version 14.7 (Homebrew)
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.108Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET statement_timeout = 0;
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.108Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.108Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET lock_timeout = 0;
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.108Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.108Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET idle_in_transaction_session_timeout = 0;
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.108Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.108Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET client_encoding = 'UTF8';
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.109Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.110Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET standard_conforming_strings = on;
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.110Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.110Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SELECT pg_catalog.set_config('search_path', '', false);
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.111Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :  set_config 
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.111Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ------------
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.111Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :  
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.111Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : (1 row)
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.111Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET check_function_bodies = false;
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.111Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.111Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET xmloption = content;
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.112Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.112Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET client_min_messages = warning;
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.112Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.112Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET row_security = off;
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.112Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.112Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET default_tablespace = '';
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.112Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.112Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET default_table_access_method = heap;
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.113Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SET
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.113Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.113Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Name: employees; Type: TABLE; Schema: public; Owner: postgres
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.113Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.114Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : CREATE TABLE public.employees (
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.114Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     id integer NOT NULL,
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.114Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     name character varying(255),
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.114Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     surname character varying(255),
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.114Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     date_of_birth date,
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.114Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     salary numeric(10,2),
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.114Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     phone_number character varying(15),
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.114Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     job character varying(255),
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.114Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     title character varying(255)
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.114Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : );
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.118Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : CREATE TABLE
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.119Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE public.employees OWNER TO postgres;
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.119Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.119Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.119Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Name: employees_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.119Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.119Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : CREATE SEQUENCE public.employees_id_seq
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.119Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     AS integer
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.119Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     START WITH 1
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.119Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     INCREMENT BY 1
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.119Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     NO MINVALUE
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.120Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     NO MAXVALUE
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.120Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     CACHE 1;
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.120Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : CREATE SEQUENCE
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.120Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE public.employees_id_seq OWNER TO postgres;
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.120Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.120Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.120Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Name: employees_id_seq; Type: SEQUENCE OWNED BY; Schema: public; Owner: postgres
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.120Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.120Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER SEQUENCE public.employees_id_seq OWNED BY public.employees.id;
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.120Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER SEQUENCE
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.120Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.120Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Name: employees id; Type: DEFAULT; Schema: public; Owner: postgres
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.120Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.120Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE ONLY public.employees ALTER COLUMN id SET DEFAULT nextval('public.employees_id_seq'::regclass);
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.121Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.121Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.121Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Data for Name: employees; Type: TABLE DATA; Schema: public; Owner: postgres
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.121Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.121Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : COPY public.employees (id, name, surname, date_of_birth, salary, phone_number, job, title) FROM stdin;
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.123Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : COPY 10
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.123Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.123Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Name: employees_id_seq; Type: SEQUENCE SET; Schema: public; Owner: postgres
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.123Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.123Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : SELECT pg_catalog.setval('public.employees_id_seq', 10, true);
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.124Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :  setval 
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.124Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --------
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.124Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :      10
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.124Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : (1 row)
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.124Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.124Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- Name: employees employees_pkey; Type: CONSTRAINT; Schema: public; Owner: postgres
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.124Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.124Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE ONLY public.employees
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.124Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter :     ADD CONSTRAINT employees_pkey PRIMARY KEY (id);
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.125Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : ALTER TABLE
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.125Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.125Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : -- PostgreSQL database dump complete
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.125Z  INFO 1 --- [database-restoration-service] [       Thread-6] d.a.o.d.p.PostgresRestoreDatabaseAdapter : --
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.127Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] d.a.o.d.p.PostgresRestoreDatabaseAdapter : Successfully restored database using command [psql, -h, postgres, -p, 5432, -U, postgres, -d, f462d216-8745-45d8-82d6-ebd180677d94, -v, ON_ERROR_STOP=1, --echo-all]
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.260Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] c.w.a.s.impl.LoggingKafkaTemplate        : Publishing to Kafka | Topic: restore-success | Value: DatabaseRestoredSuccessEvent(blueprintId=f462d216-8745-45d8-82d6-ebd180677d94)
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.265Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
simulation_2-database-restoration-service-1  | 	acks = -1
simulation_2-database-restoration-service-1  | 	auto.include.jmx.reporter = true
simulation_2-database-restoration-service-1  | 	batch.size = 16384
simulation_2-database-restoration-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-database-restoration-service-1  | 	buffer.memory = 33554432
simulation_2-database-restoration-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-database-restoration-service-1  | 	client.id = producer-1
simulation_2-database-restoration-service-1  | 	compression.type = none
simulation_2-database-restoration-service-1  | 	connections.max.idle.ms = 540000
simulation_2-database-restoration-service-1  | 	delivery.timeout.ms = 120000
simulation_2-database-restoration-service-1  | 	enable.idempotence = true
simulation_2-database-restoration-service-1  | 	interceptor.classes = []
simulation_2-database-restoration-service-1  | 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
simulation_2-database-restoration-service-1  | 	linger.ms = 0
simulation_2-database-restoration-service-1  | 	max.block.ms = 60000
simulation_2-database-restoration-service-1  | 	max.in.flight.requests.per.connection = 5
simulation_2-database-restoration-service-1  | 	max.request.size = 1048576
simulation_2-database-restoration-service-1  | 	metadata.max.age.ms = 300000
simulation_2-database-restoration-service-1  | 	metadata.max.idle.ms = 300000
simulation_2-database-restoration-service-1  | 	metric.reporters = []
simulation_2-database-restoration-service-1  | 	metrics.num.samples = 2
simulation_2-database-restoration-service-1  | 	metrics.recording.level = INFO
simulation_2-database-restoration-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-database-restoration-service-1  | 	partitioner.adaptive.partitioning.enable = true
simulation_2-database-restoration-service-1  | 	partitioner.availability.timeout.ms = 0
simulation_2-database-restoration-service-1  | 	partitioner.class = null
simulation_2-database-restoration-service-1  | 	partitioner.ignore.keys = false
simulation_2-database-restoration-service-1  | 	receive.buffer.bytes = 32768
simulation_2-database-restoration-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-database-restoration-service-1  | 	reconnect.backoff.ms = 50
simulation_2-database-restoration-service-1  | 	request.timeout.ms = 30000
simulation_2-database-restoration-service-1  | 	retries = 2147483647
simulation_2-database-restoration-service-1  | 	retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.jaas.config = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-database-restoration-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-database-restoration-service-1  | 	sasl.kerberos.service.name = null
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.class = null
simulation_2-database-restoration-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-database-restoration-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-database-restoration-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-database-restoration-service-1  | 	security.protocol = PLAINTEXT
simulation_2-database-restoration-service-1  | 	security.providers = null
simulation_2-database-restoration-service-1  | 	send.buffer.bytes = 131072
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-database-restoration-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-database-restoration-service-1  | 	ssl.cipher.suites = null
simulation_2-database-restoration-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-database-restoration-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-database-restoration-service-1  | 	ssl.engine.factory.class = null
simulation_2-database-restoration-service-1  | 	ssl.key.password = null
simulation_2-database-restoration-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-database-restoration-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.key = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.location = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.password = null
simulation_2-database-restoration-service-1  | 	ssl.keystore.type = JKS
simulation_2-database-restoration-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-database-restoration-service-1  | 	ssl.provider = null
simulation_2-database-restoration-service-1  | 	ssl.secure.random.implementation = null
simulation_2-database-restoration-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-database-restoration-service-1  | 	ssl.truststore.certificates = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.location = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.password = null
simulation_2-database-restoration-service-1  | 	ssl.truststore.type = JKS
simulation_2-database-restoration-service-1  | 	transaction.timeout.ms = 60000
simulation_2-database-restoration-service-1  | 	transactional.id = null
simulation_2-database-restoration-service-1  | 	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
simulation_2-database-restoration-service-1  | 
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.272Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.281Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.282Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.282Z  INFO 1 --- [database-restoration-service] [ntainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472985281
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.287Z  INFO 1 --- [database-restoration-service] [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: SfQo8OGTSxO1CfeFL1N09Q
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.289Z  INFO 1 --- [database-restoration-service] [ad | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 1 with epoch 0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:25 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.w.a.b.a.i.m.DatabaseRestoredKafkaListener - Received DatabaseRestoredSuccessEvent(blueprintId=f462d216-8745-45d8-82d6-ebd180677d94)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:25 [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.w.a.b.d.s.BlueprintSagaStatusUpdater - Updated status to RESTORE_SUCCESS of blueprint: Blueprint(blueprintId=f462d216-8745-45d8-82d6-ebd180677d94, dumpFile=null, blueprintSagaStatus=RESTORE_SUCCESS, restoreMode=SCRIPT, databaseType=POSTGRESQL, title=Employees, dumpStoreSuccess=true, description=This is just a sample dump of employees database made in a SCRIPT mode., createdDate=2024-01-28T20:16:23.433, originalDumpName=employeesdb_script.sql)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:16:25.360Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] .a.m.a.i.m.DatabaseRestoredKafkaListener : Received DatabaseRestoredSuccessEvent(blueprintId=f462d216-8745-45d8-82d6-ebd180677d94)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:16:25.361Z ERROR 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] c.w.a.m.d.s.m.DatabaseRestoredService    : Error during metadata extraction for DatabaseRestoredSuccessEvent(blueprintId=f462d216-8745-45d8-82d6-ebd180677d94)
simulation_2-metadata-extraction-service-1  | 
simulation_2-metadata-extraction-service-1  | java.lang.RuntimeException: Simulating exception – metadata extraction operation failed
simulation_2-metadata-extraction-service-1  | 	at com.wenox.anonymization.metadata_extraction_service.domain.model.DatabaseConnection.forPostgres(DatabaseConnection.java:21) ~[!/:simulation-case-1]
simulation_2-metadata-extraction-service-1  | 	at com.wenox.anonymization.metadata_extraction_service.domain.service.messaging.DatabaseRestoredService.handle(DatabaseRestoredService.java:26) ~[!/:simulation-case-1]
simulation_2-metadata-extraction-service-1  | 	at com.wenox.anonymization.metadata_extraction_service.adapters.inbound.messaging.DatabaseRestoredKafkaListener.onRestoreSuccess(DatabaseRestoredKafkaListener.java:23) ~[!/:simulation-case-1]
simulation_2-metadata-extraction-service-1  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:na]
simulation_2-metadata-extraction-service-1  | 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[na:na]
simulation_2-metadata-extraction-service-1  | 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:na]
simulation_2-metadata-extraction-service-1  | 	at java.base/java.lang.reflect.Method.invoke(Method.java:568) ~[na:na]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:169) ~[spring-messaging-6.1.1.jar!/:6.1.1]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:119) ~[spring-messaging-6.1.1.jar!/:6.1.1]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:375) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2857) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2835) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.lambda$doInvokeRecordListener$56(KafkaMessageListenerContainer.java:2753) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at io.micrometer.observation.Observation.observe(Observation.java:565) ~[micrometer-observation-1.12.0.jar!/:1.12.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2751) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2604) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2490) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:2132) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1487) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1451) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1322) ~[spring-kafka-3.1.0.jar!/:3.1.0]
simulation_2-metadata-extraction-service-1  | 	at java.base/java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1804) ~[na:na]
simulation_2-metadata-extraction-service-1  | 	at java.base/java.lang.Thread.run(Thread.java:833) ~[na:na]
simulation_2-metadata-extraction-service-1  | 
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:16:25.365Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] c.w.a.s.impl.LoggingKafkaTemplate        : Publishing to Kafka | Topic: metadata-failure | Value: MetadataExtractedFailureEvent(blueprintId=f462d216-8745-45d8-82d6-ebd180677d94, errorMessage=Simulating exception – metadata extraction operation failed, exception=java.lang.RuntimeException: Simulating exception – metadata extraction operation failed)
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:16:25.374Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
simulation_2-metadata-extraction-service-1  | 	acks = -1
simulation_2-metadata-extraction-service-1  | 	auto.include.jmx.reporter = true
simulation_2-metadata-extraction-service-1  | 	batch.size = 16384
simulation_2-metadata-extraction-service-1  | 	bootstrap.servers = [kafka:9093]
simulation_2-metadata-extraction-service-1  | 	buffer.memory = 33554432
simulation_2-metadata-extraction-service-1  | 	client.dns.lookup = use_all_dns_ips
simulation_2-metadata-extraction-service-1  | 	client.id = producer-1
simulation_2-metadata-extraction-service-1  | 	compression.type = none
simulation_2-metadata-extraction-service-1  | 	connections.max.idle.ms = 540000
simulation_2-metadata-extraction-service-1  | 	delivery.timeout.ms = 120000
simulation_2-metadata-extraction-service-1  | 	enable.idempotence = true
simulation_2-metadata-extraction-service-1  | 	interceptor.classes = []
simulation_2-metadata-extraction-service-1  | 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
simulation_2-metadata-extraction-service-1  | 	linger.ms = 0
simulation_2-metadata-extraction-service-1  | 	max.block.ms = 60000
simulation_2-metadata-extraction-service-1  | 	max.in.flight.requests.per.connection = 5
simulation_2-metadata-extraction-service-1  | 	max.request.size = 1048576
simulation_2-metadata-extraction-service-1  | 	metadata.max.age.ms = 300000
simulation_2-metadata-extraction-service-1  | 	metadata.max.idle.ms = 300000
simulation_2-metadata-extraction-service-1  | 	metric.reporters = []
simulation_2-metadata-extraction-service-1  | 	metrics.num.samples = 2
simulation_2-metadata-extraction-service-1  | 	metrics.recording.level = INFO
simulation_2-metadata-extraction-service-1  | 	metrics.sample.window.ms = 30000
simulation_2-metadata-extraction-service-1  | 	partitioner.adaptive.partitioning.enable = true
simulation_2-metadata-extraction-service-1  | 	partitioner.availability.timeout.ms = 0
simulation_2-metadata-extraction-service-1  | 	partitioner.class = null
simulation_2-metadata-extraction-service-1  | 	partitioner.ignore.keys = false
simulation_2-metadata-extraction-service-1  | 	receive.buffer.bytes = 32768
simulation_2-metadata-extraction-service-1  | 	reconnect.backoff.max.ms = 1000
simulation_2-metadata-extraction-service-1  | 	reconnect.backoff.ms = 50
simulation_2-metadata-extraction-service-1  | 	request.timeout.ms = 30000
simulation_2-metadata-extraction-service-1  | 	retries = 2147483647
simulation_2-metadata-extraction-service-1  | 	retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.client.callback.handler.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.jaas.config = null
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.min.time.before.relogin = 60000
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.service.name = null
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.ticket.renew.jitter = 0.05
simulation_2-metadata-extraction-service-1  | 	sasl.kerberos.ticket.renew.window.factor = 0.8
simulation_2-metadata-extraction-service-1  | 	sasl.login.callback.handler.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.class = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.connect.timeout.ms = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.read.timeout.ms = null
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.buffer.seconds = 300
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.min.period.seconds = 60
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.window.factor = 0.8
simulation_2-metadata-extraction-service-1  | 	sasl.login.refresh.window.jitter = 0.05
simulation_2-metadata-extraction-service-1  | 	sasl.login.retry.backoff.max.ms = 10000
simulation_2-metadata-extraction-service-1  | 	sasl.login.retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.mechanism = GSSAPI
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.clock.skew.seconds = 30
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.expected.audience = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.expected.issuer = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.jwks.endpoint.url = null
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.scope.claim.name = scope
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.sub.claim.name = sub
simulation_2-metadata-extraction-service-1  | 	sasl.oauthbearer.token.endpoint.url = null
simulation_2-metadata-extraction-service-1  | 	security.protocol = PLAINTEXT
simulation_2-metadata-extraction-service-1  | 	security.providers = null
simulation_2-metadata-extraction-service-1  | 	send.buffer.bytes = 131072
simulation_2-metadata-extraction-service-1  | 	socket.connection.setup.timeout.max.ms = 30000
simulation_2-metadata-extraction-service-1  | 	socket.connection.setup.timeout.ms = 10000
simulation_2-metadata-extraction-service-1  | 	ssl.cipher.suites = null
simulation_2-metadata-extraction-service-1  | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
simulation_2-metadata-extraction-service-1  | 	ssl.endpoint.identification.algorithm = https
simulation_2-metadata-extraction-service-1  | 	ssl.engine.factory.class = null
simulation_2-metadata-extraction-service-1  | 	ssl.key.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.keymanager.algorithm = SunX509
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.certificate.chain = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.key = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.location = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.keystore.type = JKS
simulation_2-metadata-extraction-service-1  | 	ssl.protocol = TLSv1.3
simulation_2-metadata-extraction-service-1  | 	ssl.provider = null
simulation_2-metadata-extraction-service-1  | 	ssl.secure.random.implementation = null
simulation_2-metadata-extraction-service-1  | 	ssl.trustmanager.algorithm = PKIX
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.certificates = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.location = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.password = null
simulation_2-metadata-extraction-service-1  | 	ssl.truststore.type = JKS
simulation_2-metadata-extraction-service-1  | 	transaction.timeout.ms = 60000
simulation_2-metadata-extraction-service-1  | 	transactional.id = null
simulation_2-metadata-extraction-service-1  | 	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer
simulation_2-metadata-extraction-service-1  | 
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:16:25.387Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Instantiated an idempotent producer.
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:16:25.399Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 3.6.0
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:16:25.399Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 60e845626d8a465a
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:16:25.399Z  INFO 1 --- [metadata-extraction-service] [ntainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1706472985399
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:16:25.416Z  INFO 1 --- [metadata-extraction-service] [ad | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: SfQo8OGTSxO1CfeFL1N09Q
simulation_2-metadata-extraction-service-1  | 2024-01-28T20:16:25.420Z  INFO 1 --- [metadata-extraction-service] [ad | producer-1] o.a.k.c.p.internals.TransactionManager   : [Producer clientId=producer-1] ProducerId set to 2 with epoch 0
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:25 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] c.w.a.b.a.i.m.MetadataExtractedKafkaListener - Received MetadataExtractedFailureEvent(blueprintId=f462d216-8745-45d8-82d6-ebd180677d94, errorMessage=Simulating exception – metadata extraction operation failed, exception=java.lang.Exception: Simulating exception – metadata extraction operation failed)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:25 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] c.w.a.b.a.o.p.d.DumpRepositoryS3Adapter - Deleting Dump from S3... Blueprint ID : f462d216-8745-45d8-82d6-ebd180677d94
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.466Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] .m.MetadataExtractedFailureKafkaListener : -----> Started compensating transaction MetadataExtractedFailureEvent(blueprintId=f462d216-8745-45d8-82d6-ebd180677d94, errorMessage=Simulating exception – metadata extraction operation failed, exception=java.lang.Exception: Simulating exception – metadata extraction operation failed)
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.467Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] .a.d.a.o.d.p.PostgresDropDatabaseAdapter : Dropping database f462d216-8745-45d8-82d6-ebd180677d94
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.513Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] .a.d.a.o.d.p.PostgresDropDatabaseAdapter : Successfully dropped database f462d216-8745-45d8-82d6-ebd180677d94 using command [dropdb, -h, postgres, -p, 5432, -U, postgres, --no-password, --if-exists, f462d216-8745-45d8-82d6-ebd180677d94]
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.540Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] c.w.a.s.impl.LoggingKafkaTemplate        : Publishing to Kafka | Topic: restore-failure | Value: MetadataExtractedFailureEvent(blueprintId=f462d216-8745-45d8-82d6-ebd180677d94, errorMessage=Simulating exception – metadata extraction operation failed, exception=java.lang.Exception: Simulating exception – metadata extraction operation failed)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:25 [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] c.w.a.b.d.s.BlueprintSagaStatusUpdater - Updated status to METADATA_EXTRACTION_FAILURE of blueprint: Blueprint(blueprintId=f462d216-8745-45d8-82d6-ebd180677d94, dumpFile=null, blueprintSagaStatus=METADATA_EXTRACTION_FAILURE, restoreMode=SCRIPT, databaseType=POSTGRESQL, title=Employees, dumpStoreSuccess=true, description=This is just a sample dump of employees database made in a SCRIPT mode., createdDate=2024-01-28T20:16:23.433, originalDumpName=employeesdb_script.sql)
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:25.548Z  INFO 1 --- [database-restoration-service] [ntainer#1-0-C-1] .m.MetadataExtractedFailureKafkaListener : <----- Finished compensating transaction MetadataExtractedFailureEvent(blueprintId=f462d216-8745-45d8-82d6-ebd180677d94, errorMessage=Simulating exception – metadata extraction operation failed, exception=java.lang.Exception: Simulating exception – metadata extraction operation failed)
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:25 [http-nio-8100-exec-4] c.w.a.logging.LoggingFilter - -----> Request: GET /api/v1/blueprints?blueprint_id=f462d216-8745-45d8-82d6-ebd180677d94, headers=[user-agent:"curl/8.1.2", accept:"*/*", forwarded:"proto=http;host="localhost:8080";for="192.168.128.1:42804"", x-forwarded-for:"192.168.128.1", x-forwarded-proto:"http", x-forwarded-port:"8080", x-forwarded-host:"localhost:8080", host:"fe10a847b0fe:8100", content-length:"0"]
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:25 [http-nio-8100-exec-4] c.w.a.logging.LoggingFilter - <----- Response (HTTP 200 OK):
simulation_2-blueprint-service-1  | {
simulation_2-blueprint-service-1  |   "blueprintId" : "f462d216-8745-45d8-82d6-ebd180677d94",
simulation_2-blueprint-service-1  |   "blueprintSagaStatus" : "METADATA_EXTRACTION_FAILURE",
simulation_2-blueprint-service-1  |   "restoreMode" : "SCRIPT",
simulation_2-blueprint-service-1  |   "databaseType" : "POSTGRESQL",
simulation_2-blueprint-service-1  |   "title" : "Employees",
simulation_2-blueprint-service-1  |   "dumpStoreSuccess" : true,
simulation_2-blueprint-service-1  |   "description" : "This is just a sample dump of employees database made in a SCRIPT mode.",
simulation_2-blueprint-service-1  |   "createdDate" : "2024-01-28T20:16:23.433",
simulation_2-blueprint-service-1  |   "originalDumpName" : "employeesdb_script.sql"
simulation_2-blueprint-service-1  | }
simulation_2-blueprint-service-1  | [31mWARN [0;39m 2024-01-28 20:16:26 [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] c.w.a.s.config.KafkaDeadLetterConfig - Publishing to dead letter - Source Topic: restore-failure, Partition: 0, Offset: 0, Exception: Exception details
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:16:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:46:30.017234716
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:36.106Z  INFO 1 --- [database-restoration-service] [nio-8200-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:36.107Z  INFO 1 --- [database-restoration-service] [nio-8200-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:36.111Z  INFO 1 --- [database-restoration-service] [nio-8200-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 4 ms
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:36.148Z  INFO 1 --- [database-restoration-service] [nio-8200-exec-1] c.w.anonymization.logging.LoggingFilter  : -----> Request: GET /api/v1/restorations?blueprint_id=f462d216-8745-45d8-82d6-ebd180677d94, headers=[user-agent:"curl/8.1.2", accept:"*/*", forwarded:"proto=http;host="localhost:8080";for="192.168.128.1:58140"", x-forwarded-for:"192.168.128.1", x-forwarded-proto:"http", x-forwarded-port:"8080", x-forwarded-host:"localhost:8080", host:"07ebd9405d2c:8200", content-length:"0"]
simulation_2-database-restoration-service-1  | 2024-01-28T20:16:36.227Z  INFO 1 --- [database-restoration-service] [nio-8200-exec-1] c.w.anonymization.logging.LoggingFilter  : <----- Response (HTTP 200 OK):
simulation_2-database-restoration-service-1  | {
simulation_2-database-restoration-service-1  |   "blueprintId" : "f462d216-8745-45d8-82d6-ebd180677d94",
simulation_2-database-restoration-service-1  |   "runnerIp" : "localhost",
simulation_2-database-restoration-service-1  |   "active" : false
simulation_2-database-restoration-service-1  | }
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:17:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:17:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:47:00.019357216
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:17:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:17:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:47:30.006173257
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:18:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:18:00 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:48:00.040261299
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:18:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation started...
simulation_2-blueprint-service-1  | [34mINFO [0;39m 2024-01-28 20:18:30 [scheduling-1] c.w.a.b.d.s.StaleBlueprintReconciliationService - Stale blueprints reconciliation ended. Reconciled blueprints : [] before time : 2024-01-28T19:48:30.008825466
